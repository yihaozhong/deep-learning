{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6\n",
    "\n",
    "Yihao Zhong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model interpretability and explainability are important because they enable trust, transparency, and account for robustness for downstream users. Interpretable models allow downstream users to understand how predictions are made, facilitating debugging, improvement, and also compliance with regulations (equality, non-descriminatic etc). Explainability helps detect biases, uncover insights, and enhance user acceptance. Without interpretability, the decision-making process remains a \"black box,\" hindering trust and limiting the model's practical applicability in domains that require clear explanations, such as healthcare and finance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autofeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autofeat import FeatureSelector, AutoFeatRegressor\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features:  10\n"
     ]
    }
   ],
   "source": [
    "# Load the diabetes dataset and get the featues and target\n",
    "X, y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "print(\"Original number of features: \", X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[featsel] Scaling data..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 13:37:15,434 INFO: [featsel] Feature selection run 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 13:37:16,154 INFO: [featsel] Feature selection run 2/5\n",
      "2024-04-27 13:37:16,188 INFO: [featsel] Feature selection run 3/5\n",
      "2024-04-27 13:37:16,220 INFO: [featsel] Feature selection run 4/5\n",
      "2024-04-27 13:37:16,251 INFO: [featsel] Feature selection run 5/5\n",
      "2024-04-27 13:37:16,284 INFO: [featsel] 7 features after 5 feature selection runs\n",
      "/Users/zhongyihao/anaconda3/envs/trading/lib/python3.12/site-packages/autofeat/featsel.py:270: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  if np.max(np.abs(correlations[c].ravel()[:i])) < 0.9:\n",
      "2024-04-27 13:37:16,286 INFO: [featsel] 7 features after correlation filtering\n",
      "2024-04-27 13:37:16,295 INFO: [featsel] 6 features after noise filtering\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New number of features:  6\n"
     ]
    }
   ],
   "source": [
    "fsel = FeatureSelector(verbose=1)\n",
    "\n",
    "# Fit it on the train dataset\n",
    "df = fsel.fit_transform(X, y)\n",
    "print(\"New number of features: \", df.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "There are 10 original features, and after features selection there are 6 features, the discarded features is 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on the training set:  0.5279193863361498\n",
      "R2 score on the test set:  0.45260276297191915\n"
     ]
    }
   ],
   "source": [
    "# Perform a train-test split on your dataset. Select a regression model from skLearn and fit it to the\n",
    "# training dataset. What is the R2 score on the training and test set?\n",
    "\n",
    "# Perform a train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rreg_model = LinearRegression()\n",
    "result_logistic = rreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"R2 score on the training set: \", result_logistic.score(X_train, y_train))\n",
    "print(\"R2 score on the test set: \", result_logistic.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a linear regression model. The $R^2$ for training set is 0.53, and the $R^2$ for testing set is 0.45. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 13:37:30,791 INFO: [AutoFeat] The 3 step feature engineering process could generate up to 60445 features.\n",
      "2024-04-27 13:37:30,792 INFO: [AutoFeat] With 353 data points this new feature matrix would use about 0.09 gb of space.\n",
      "2024-04-27 13:37:30,796 INFO: [feateng] Step 1: transformation of original features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]               0/             10 features transformed\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 13:37:31,819 INFO: [feateng] Generated 45 transformed features from 10 original features - done.\n",
      "2024-04-27 13:37:31,824 INFO: [feateng] Step 2: first combination of features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]            1400/           1485 feature tuples combined\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 13:37:33,274 INFO: [feateng] Generated 5789 feature combinations from 1485 original feature tuples - done.\n",
      "2024-04-27 13:37:33,279 INFO: [feateng] Step 3: transformation of new features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]            5000/           5789 features transformed\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhongyihao/anaconda3/envs/trading/lib/python3.12/site-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/zhongyihao/anaconda3/envs/trading/lib/python3.12/site-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]            5600/           5789 features transformed\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 13:37:43,013 INFO: [feateng] Generated 24430 transformed features from 5789 original features - done.\n",
      "2024-04-27 13:37:43,053 INFO: [feateng] Generated altogether 32266 new features in 3 steps\n",
      "2024-04-27 13:37:43,053 INFO: [feateng] Removing correlated features, as well as additions at the highest level\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]            5700/           5789 features transformed\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 13:37:43,270 INFO: [feateng] Generated a total of 14871 additional features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[featsel] Scaling data..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 13:37:44,076 INFO: [featsel] Feature selection run 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 13:38:28,567 INFO: [featsel] Feature selection run 2/5\n",
      "2024-04-27 13:39:09,195 INFO: [featsel] Feature selection run 3/5\n",
      "2024-04-27 13:39:38,424 INFO: [featsel] Feature selection run 4/5\n",
      "2024-04-27 13:40:33,087 INFO: [featsel] Feature selection run 5/5\n",
      "2024-04-27 13:41:01,473 INFO: [featsel] 36 features after 5 feature selection runs\n",
      "/Users/zhongyihao/anaconda3/envs/trading/lib/python3.12/site-packages/autofeat/featsel.py:270: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  if np.max(np.abs(correlations[c].ravel()[:i])) < 0.9:\n",
      "2024-04-27 13:41:01,487 INFO: [featsel] 31 features after correlation filtering\n",
      "2024-04-27 13:41:01,685 INFO: [featsel] 11 features after noise filtering\n",
      "2024-04-27 13:41:01,705 INFO: [AutoFeat] Computing 11 new features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat]     6/   11 new features\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 13:41:02,327 INFO: [AutoFeat]    11/   11 new features ...done.\n",
      "2024-04-27 13:41:02,335 INFO: [AutoFeat] Final dataframe with 21 feature columns (11 new).\n",
      "2024-04-27 13:41:02,335 INFO: [AutoFeat] Training final regression model.\n",
      "2024-04-27 13:41:02,344 INFO: [AutoFeat] Trained model: largest coefficients:\n",
      "2024-04-27 13:41:02,345 INFO: -70.30327923185092\n",
      "2024-04-27 13:41:02,345 INFO: 781094.306607 * x000**3*x001\n",
      "2024-04-27 13:41:02,346 INFO: -3983.086911 * exp(x006)*Abs(x001)\n",
      "2024-04-27 13:41:02,346 INFO: 362.715436 * exp(x002)*exp(x003)\n",
      "2024-04-27 13:41:02,347 INFO: 332.458747 * x000**9/x009**3\n",
      "2024-04-27 13:41:02,347 INFO: 215.883125 * Abs(x002 + Abs(x009))\n",
      "2024-04-27 13:41:02,347 INFO: 37.282823 * exp(x002)*exp(x008)\n",
      "2024-04-27 13:41:02,348 INFO: 24.680193 * Abs(x008)/x008\n",
      "2024-04-27 13:41:02,348 INFO: -4.397543 * x004**2*Abs(1/x003)\n",
      "2024-04-27 13:41:02,348 INFO: -0.854832 * x006/Abs(x002)\n",
      "2024-04-27 13:41:02,349 INFO: 0.037580 * 1/(x003**2 - x008)\n",
      "2024-04-27 13:41:02,349 INFO: -0.010361 * 1/(x008 - Abs(x009))\n",
      "2024-04-27 13:41:02,350 INFO: [AutoFeat] Final score: 0.6100\n",
      "2024-04-27 13:41:02,351 INFO: [AutoFeat] Computing 11 new features.\n",
      "2024-04-27 13:41:02,359 INFO: [AutoFeat]    11/   11 new features ...done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Final Train R^2: 0.6224 features\n",
      "## Final Test R^2: 0.5172\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an AutoFeatRegressor with 3 steps of feature engineering\n",
    "afreg = AutoFeatRegressor(verbose=1, feateng_steps=3)\n",
    "\n",
    "# Fit it on the train dataset\n",
    "X_train_afreg = afreg.fit_transform(X_train, y_train)\n",
    "X_test_afreg = afreg.transform(X_test)\n",
    "\n",
    "result_afreg = rreg_model.fit(X_train_afreg, y_train)\n",
    "\n",
    "print(\"## Final Train R^2: %.4f\" % result_afreg.score(X_train_afreg, y_train))\n",
    "print(\"## Final Test R^2: %.4f\" %  result_afreg.score(X_test_afreg, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Features:  {'x001', 'x004**2*Abs(1/x003)', 'x003', 'x006/Abs(x002)', 'Abs(x008)/x008', 'x004', 'x002', 'exp(x006)*Abs(x001)', 'x000**9/x009**3', 'exp(x002)*exp(x003)', 'Abs(x002 + Abs(x009))', 'x008', 'x009', '1/(x008 - Abs(x009))', 'x005', 'x000', 'x000**3*x001', 'x007', '1/(x003**2 - x008)', 'exp(x002)*exp(x008)', 'x006'}\n",
      "Original Features:  ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "print(\"New Features: \", set(X_train_afreg.columns))\n",
    "print(\"Original Features: \", datasets.load_diabetes().feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import uniform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
    "X_digits = X_digits / X_digits.max()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist(config):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    drop_rate = config[\"drop_rate\"]\n",
    "    num_classes = 10\n",
    "    epochs = 12\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=config[\"conv_filters\"], kernel_size=(3, 3), \n",
    "                               activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(config[\"hidden\"], activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(drop_rate),\n",
    "        tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            lr=config[\"lr\"]),\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=0,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[TuneReportCallback({\n",
    "            \"mean_accuracy\": \"accuracy\"\n",
    "        })])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "        train_mnist,\n",
    "        name=\"exp\",\n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        stop={\n",
    "            \"mean_accuracy\": 0.99,\n",
    "        },\n",
    "        resources_per_trial={\n",
    "            \"gpu\": 1\n",
    "        },\n",
    "        config={\n",
    "            \"batch_size\": tune.grid_search([32, 64, 128]),\n",
    "            \"hidden\": tune.grid_search([128, 256, 512]),\n",
    "            \"conv_filters\": tune.grid_search([16,32,64]),\n",
    "            \"lr\": tune.uniform(0.001, 0.1),\n",
    "            \"drop_rate\": tune.uniform(0.0, 1.0),\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learner 1 is 2.5x faster than learner 2\n",
    "\n",
    "The staleness as follows:\n",
    "\n",
    "$g[L_1,2]$: 0, this is the start and first of the calculation, of both learner 1 and 2\n",
    "\n",
    "$g[L_1,2]$: 0, still there is no updated gradient from other learner during computation. \n",
    "\n",
    "$g[L_1,3]$: 1, it fail to pick up learner 2 g[L_2, 2] which happen at 2.5s, while learner 1 is running from 2s to 3s.\n",
    "\n",
    "$g[L_1,4]$: 0, there is no updated gradient from other learner during computation. \n",
    "\n",
    "$g[L_2,1]$: 0, this is the start and first of the calculation, of both learner 1 and 2\n",
    "\n",
    "$g[L_2,2]$: 2, there are 2 results from learn 1 updated during 2.5 s to 5 s: $g[L_1,3]$ and $g[L_1,4]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_nightly_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
