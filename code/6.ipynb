{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gcYGrUVNY0t"
      },
      "source": [
        "# Homework 6\n",
        "\n",
        "Yihao Zhong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRkGXVu6NY0v"
      },
      "source": [
        "## Problem 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEkWbOI-NY0v"
      },
      "source": [
        "### 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIiCuqHPNY0v"
      },
      "source": [
        "Model interpretability and explainability are important because they enable trust, transparency, and account for robustness for downstream users. Interpretable models allow downstream users to understand how predictions are made, facilitating debugging, improvement, and also compliance with regulations (equality, non-descriminatic etc). Explainability helps detect biases, uncover insights, and enhance user acceptance. Without interpretability, the decision-making process remains a \"black box,\" hindering trust and limiting the model's practical applicability in domains that require clear explanations, such as healthcare and finance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCTODwDHNY0v"
      },
      "source": [
        "### 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFPW9pXeNY0v"
      },
      "outputs": [],
      "source": [
        "!pip install autofeat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFmBM-I4NY0w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from autofeat import FeatureSelector, AutoFeatRegressor\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9hZUmRxNY0w",
        "outputId": "8971138a-a3e5-4525-f219-a2349bc7c047"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original number of features:  10\n"
          ]
        }
      ],
      "source": [
        "# Load the diabetes dataset and get the featues and target\n",
        "X, y = datasets.load_diabetes(return_X_y=True)\n",
        "\n",
        "print(\"Original number of features: \", X.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsEOLKbONY0w",
        "outputId": "97971961-1234-4419-ab99-35c9b696f8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[featsel] Scaling data..."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:15,434 INFO: [featsel] Feature selection run 1/5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:16,154 INFO: [featsel] Feature selection run 2/5\n",
            "2024-04-27 13:37:16,188 INFO: [featsel] Feature selection run 3/5\n",
            "2024-04-27 13:37:16,220 INFO: [featsel] Feature selection run 4/5\n",
            "2024-04-27 13:37:16,251 INFO: [featsel] Feature selection run 5/5\n",
            "2024-04-27 13:37:16,284 INFO: [featsel] 7 features after 5 feature selection runs\n",
            "/Users/zhongyihao/anaconda3/envs/trading/lib/python3.12/site-packages/autofeat/featsel.py:270: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
            "  if np.max(np.abs(correlations[c].ravel()[:i])) < 0.9:\n",
            "2024-04-27 13:37:16,286 INFO: [featsel] 7 features after correlation filtering\n",
            "2024-04-27 13:37:16,295 INFO: [featsel] 6 features after noise filtering\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New number of features:  6\n"
          ]
        }
      ],
      "source": [
        "fsel = FeatureSelector(verbose=1)\n",
        "\n",
        "# Fit it on the train dataset\n",
        "df = fsel.fit_transform(X, y)\n",
        "print(\"New number of features: \", df.shape[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEnyV2E4NY0x"
      },
      "source": [
        "Answer:\n",
        "\n",
        "There are 10 original features, and after features selection there are 6 features, the discarded features is 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOk8qahYNY0x"
      },
      "source": [
        "### 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_wJ924UNY0x",
        "outputId": "d37b5920-c7dc-4650-b8d2-2629186e606d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 score on the training set:  0.5279193863361498\n",
            "R2 score on the test set:  0.45260276297191915\n"
          ]
        }
      ],
      "source": [
        "# Perform a train-test split on your dataset. Select a regression model from skLearn and fit it to the\n",
        "# training dataset. What is the R2 score on the training and test set?\n",
        "\n",
        "# Perform a train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "rreg_model = LinearRegression()\n",
        "result_logistic = rreg_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"R2 score on the training set: \", result_logistic.score(X_train, y_train))\n",
        "print(\"R2 score on the test set: \", result_logistic.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMC9XteoNY0x"
      },
      "source": [
        "We perform a linear regression model. The $R^2$ for training set is 0.53, and the $R^2$ for testing set is 0.45."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srqCYZ3NNY0x"
      },
      "source": [
        "### 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5u30-iWNY0x",
        "outputId": "e296f8d6-e2e6-4f44-8114-a4fd47adc7aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:30,791 INFO: [AutoFeat] The 3 step feature engineering process could generate up to 60445 features.\n",
            "2024-04-27 13:37:30,792 INFO: [AutoFeat] With 353 data points this new feature matrix would use about 0.09 gb of space.\n",
            "2024-04-27 13:37:30,796 INFO: [feateng] Step 1: transformation of original features\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[feateng]               0/             10 features transformed\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:31,819 INFO: [feateng] Generated 45 transformed features from 10 original features - done.\n",
            "2024-04-27 13:37:31,824 INFO: [feateng] Step 2: first combination of features\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[feateng]            1400/           1485 feature tuples combined\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:33,274 INFO: [feateng] Generated 5789 feature combinations from 1485 original feature tuples - done.\n",
            "2024-04-27 13:37:33,279 INFO: [feateng] Step 3: transformation of new features\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[feateng]            5000/           5789 features transformed\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zhongyihao/anaconda3/envs/trading/lib/python3.12/site-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/Users/zhongyihao/anaconda3/envs/trading/lib/python3.12/site-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[feateng]            5600/           5789 features transformed\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:43,013 INFO: [feateng] Generated 24430 transformed features from 5789 original features - done.\n",
            "2024-04-27 13:37:43,053 INFO: [feateng] Generated altogether 32266 new features in 3 steps\n",
            "2024-04-27 13:37:43,053 INFO: [feateng] Removing correlated features, as well as additions at the highest level\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[feateng]            5700/           5789 features transformed\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:43,270 INFO: [feateng] Generated a total of 14871 additional features\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[featsel] Scaling data..."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:44,076 INFO: [featsel] Feature selection run 1/5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:38:28,567 INFO: [featsel] Feature selection run 2/5\n",
            "2024-04-27 13:39:09,195 INFO: [featsel] Feature selection run 3/5\n",
            "2024-04-27 13:39:38,424 INFO: [featsel] Feature selection run 4/5\n",
            "2024-04-27 13:40:33,087 INFO: [featsel] Feature selection run 5/5\n",
            "2024-04-27 13:41:01,473 INFO: [featsel] 36 features after 5 feature selection runs\n",
            "/Users/zhongyihao/anaconda3/envs/trading/lib/python3.12/site-packages/autofeat/featsel.py:270: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
            "  if np.max(np.abs(correlations[c].ravel()[:i])) < 0.9:\n",
            "2024-04-27 13:41:01,487 INFO: [featsel] 31 features after correlation filtering\n",
            "2024-04-27 13:41:01,685 INFO: [featsel] 11 features after noise filtering\n",
            "2024-04-27 13:41:01,705 INFO: [AutoFeat] Computing 11 new features.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[AutoFeat]     6/   11 new features\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:41:02,327 INFO: [AutoFeat]    11/   11 new features ...done.\n",
            "2024-04-27 13:41:02,335 INFO: [AutoFeat] Final dataframe with 21 feature columns (11 new).\n",
            "2024-04-27 13:41:02,335 INFO: [AutoFeat] Training final regression model.\n",
            "2024-04-27 13:41:02,344 INFO: [AutoFeat] Trained model: largest coefficients:\n",
            "2024-04-27 13:41:02,345 INFO: -70.30327923185092\n",
            "2024-04-27 13:41:02,345 INFO: 781094.306607 * x000**3*x001\n",
            "2024-04-27 13:41:02,346 INFO: -3983.086911 * exp(x006)*Abs(x001)\n",
            "2024-04-27 13:41:02,346 INFO: 362.715436 * exp(x002)*exp(x003)\n",
            "2024-04-27 13:41:02,347 INFO: 332.458747 * x000**9/x009**3\n",
            "2024-04-27 13:41:02,347 INFO: 215.883125 * Abs(x002 + Abs(x009))\n",
            "2024-04-27 13:41:02,347 INFO: 37.282823 * exp(x002)*exp(x008)\n",
            "2024-04-27 13:41:02,348 INFO: 24.680193 * Abs(x008)/x008\n",
            "2024-04-27 13:41:02,348 INFO: -4.397543 * x004**2*Abs(1/x003)\n",
            "2024-04-27 13:41:02,348 INFO: -0.854832 * x006/Abs(x002)\n",
            "2024-04-27 13:41:02,349 INFO: 0.037580 * 1/(x003**2 - x008)\n",
            "2024-04-27 13:41:02,349 INFO: -0.010361 * 1/(x008 - Abs(x009))\n",
            "2024-04-27 13:41:02,350 INFO: [AutoFeat] Final score: 0.6100\n",
            "2024-04-27 13:41:02,351 INFO: [AutoFeat] Computing 11 new features.\n",
            "2024-04-27 13:41:02,359 INFO: [AutoFeat]    11/   11 new features ...done.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Final Train R^2: 0.6224 features\n",
            "## Final Test R^2: 0.5172\n"
          ]
        }
      ],
      "source": [
        "# Instantiate an AutoFeatRegressor with 3 steps of feature engineering\n",
        "afreg = AutoFeatRegressor(verbose=1, feateng_steps=3)\n",
        "\n",
        "# Fit it on the train dataset\n",
        "X_train_afreg = afreg.fit_transform(X_train, y_train)\n",
        "X_test_afreg = afreg.transform(X_test)\n",
        "\n",
        "result_afreg = rreg_model.fit(X_train_afreg, y_train)\n",
        "\n",
        "print(\"## Final Train R^2: %.4f\" % result_afreg.score(X_train_afreg, y_train))\n",
        "print(\"## Final Test R^2: %.4f\" %  result_afreg.score(X_test_afreg, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvwy-5DcNY0y",
        "outputId": "9b5bc0a7-623b-4d76-cb12-9f9d458eec61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New Features:  {'x001', 'x004**2*Abs(1/x003)', 'x003', 'x006/Abs(x002)', 'Abs(x008)/x008', 'x004', 'x002', 'exp(x006)*Abs(x001)', 'x000**9/x009**3', 'exp(x002)*exp(x003)', 'Abs(x002 + Abs(x009))', 'x008', 'x009', '1/(x008 - Abs(x009))', 'x005', 'x000', 'x000**3*x001', 'x007', '1/(x003**2 - x008)', 'exp(x002)*exp(x008)', 'x006'}\n",
            "Original Features:  ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
          ]
        }
      ],
      "source": [
        "print(\"New Features: \", set(X_train_afreg.columns))\n",
        "print(\"Original Features: \", datasets.load_diabetes().feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z90Er1k6NY0y"
      },
      "source": [
        "The $R^2$ score on the train data is 0.62, increased by 17%. The $R^2$ score on the test data is 0.45, increased by 14.3%. The performance improve after we use the Autofeat, which introduce more features and hence more complexity and non-linearity to the regression model.\n",
        "\n",
        "Five new features are 'x004**2*Abs(1/x003)', 'x006/Abs(x002)', 'Abs(x008)/x008', 'exp(x006)*Abs(x001)', 'exp(x002)*exp(x003)'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrzVeprdNY0y"
      },
      "source": [
        "## Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-DAMb7vNY0y"
      },
      "source": [
        "### 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ7GKpJtNY0y"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import datasets, neighbors, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import uniform\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViVJ4XvhNY0y"
      },
      "outputs": [],
      "source": [
        "X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
        "X_digits = X_digits / X_digits.max()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits,\n",
        "                                                    test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQmghYiJNY0y"
      },
      "outputs": [],
      "source": [
        "def train_mnist(config):\n",
        "    batch_size = config[\"batch_size\"]\n",
        "    drop_rate = config[\"drop_rate\"]\n",
        "    num_classes = 10\n",
        "    epochs = 12\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(filters=config[\"conv_filters\"], kernel_size=(3, 3),\n",
        "                               activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(config[\"hidden\"], activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(drop_rate),\n",
        "        tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            lr=config[\"lr\"]),\n",
        "        metrics=[\"accuracy\"])\n",
        "\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        verbose=0,\n",
        "        validation_data=(x_test, y_test),\n",
        "        callbacks=[TuneReportCallback({\n",
        "            \"mean_accuracy\": \"accuracy\"\n",
        "        })])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Be53kXgnNY0y"
      },
      "outputs": [],
      "source": [
        "analysis = tune.run(\n",
        "        train_mnist,\n",
        "        name=\"exp\",\n",
        "        metric=\"mean_accuracy\",\n",
        "        mode=\"max\",\n",
        "        stop={\n",
        "            \"mean_accuracy\": 0.99,\n",
        "        },\n",
        "        resources_per_trial={\n",
        "            \"gpu\": 1\n",
        "        },\n",
        "        config={\n",
        "            \"batch_size\": tune.grid_search([32, 64, 128]),\n",
        "            \"hidden\": tune.grid_search([128, 256, 512]),\n",
        "            \"conv_filters\": tune.grid_search([16,32,64]),\n",
        "            \"lr\": tune.uniform(0.001, 0.1),\n",
        "            \"drop_rate\": tune.uniform(0.0, 1.0),\n",
        "        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-l5L5vjNY0y"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWVZSAMFNY0y"
      },
      "source": [
        "### 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALPNdbV9NY0y"
      },
      "source": [
        "### 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjaEsmdWNY0y"
      },
      "source": [
        "## Problem 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTMZYDFwNY0y"
      },
      "source": [
        "Learner 1 is 2.5x faster than learner 2\n",
        "\n",
        "The staleness as follows:\n",
        "\n",
        "$g[L_1,2]$: 0, this is the start and first of the calculation, of both learner 1 and 2\n",
        "\n",
        "$g[L_1,2]$: 0, still there is no updated gradient from other learner during computation.\n",
        "\n",
        "$g[L_1,3]$: 1, it fail to pick up learner 2 g[L_2, 2] which happen at 2.5s, while learner 1 is running from 2s to 3s.\n",
        "\n",
        "$g[L_1,4]$: 0, there is no updated gradient from other learner during computation.\n",
        "\n",
        "$g[L_2,1]$: 0, this is the start and first of the calculation, of both learner 1 and 2\n",
        "\n",
        "$g[L_2,2]$: 2, there are 2 results from learn 1 updated during 2.5 s to 5 s: $g[L_1,3]$ and $g[L_1,4]$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoOrG3e3NY0y"
      },
      "source": [
        "## Problem 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gJIAXMkNY0z"
      },
      "source": [
        "### 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIAH51nzNY0z"
      },
      "source": [
        "### 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQS0ROtJNY0z"
      },
      "source": [
        "### 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_BPUHu1NY0z"
      },
      "source": [
        "### 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJYFjjUGNY0z"
      },
      "source": [
        "## Problem 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYR-4b3mNY0z"
      },
      "source": [
        "### 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEJnTiLjNY0z",
        "outputId": "3a6228d4-6025-4fac-96b1-f02222eceafc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-ssd'...\n",
            "remote: Enumerating objects: 819, done.\u001b[K\n",
            "remote: Counting objects: 100% (437/437), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 819 (delta 411), reused 405 (delta 405), pack-reused 382\u001b[K\n",
            "Receiving objects: 100% (819/819), 1.05 MiB | 3.51 MiB/s, done.\n",
            "Resolving deltas: 100% (552/552), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/qfgaohao/pytorch-ssd.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWONHBG5NY0z",
        "outputId": "d99915c8-ded1-4312-b48e-8e7f81be1bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages (4.9.0.80)\n",
            "Requirement already satisfied: tqdm in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages (4.66.2)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages (from opencv-python) (1.24.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFPKS130NY0z"
      },
      "outputs": [],
      "source": [
        "!python pytorch-ssd/eval_ssd.py --net mb1-ssd  --dataset data/VOCdevkit/VOC2007 --trained_model pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth --label_file pytorch-ssd/models/voc-model-labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9Qbet6BNY0z"
      },
      "source": [
        "The result is as follow, (copy and paste from hpc from above command)\n",
        "\n",
        "Average Precision Per-class:\n",
        "\n",
        "aeroplane: 0.6843271224059599\n",
        "\n",
        "bicycle: 0.7911140237662206\n",
        "\n",
        "bird: 0.6171819168583986\n",
        "\n",
        "boat: 0.5612220055063379\n",
        "\n",
        "bottle: 0.3485216621466003\n",
        "\n",
        "bus: 0.7677814849265677\n",
        "\n",
        "car: 0.7280986468467315\n",
        "\n",
        "cat: 0.8369208203985581\n",
        "\n",
        "chair: 0.5169138632991064\n",
        "\n",
        "cow: 0.6238697603075337\n",
        "\n",
        "diningtable: 0.7062172972736019\n",
        "\n",
        "dog: 0.7872868219961326\n",
        "\n",
        "horse: 0.819446325939355\n",
        "\n",
        "motorbike: 0.7918539457195842\n",
        "\n",
        "person: 0.702363739134837\n",
        "\n",
        "pottedplant: 0.39852951468542563\n",
        "\n",
        "sheep: 0.6066678298227772\n",
        "\n",
        "sofa: 0.7573083661544429\n",
        "\n",
        "train: 0.8262441264750008\n",
        "\n",
        "tvmonitor: 0.6461898726506375\n",
        "\n",
        "Average Precision Across All Classes: 0.6759029573156905"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyF81VhpNY04"
      },
      "source": [
        "### 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHfOCEuXNY04",
        "outputId": "4a98545d-ceb5-4061-ed50-e344cb9a1f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.34.93-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.35.0,>=1.34.93 (from boto3)\n",
            "  Downloading botocore-1.34.93-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.93->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.93->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.93->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.34.93 botocore-1.34.93 jmespath-1.0.1 s3transfer-0.10.1\n"
          ]
        }
      ],
      "source": [
        "pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hULA94MINY05",
        "outputId": "c7b6b61e-7c85-4107-b473-4b5ec002ae61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-28 19:50:21,730 - root - Download https://storage.googleapis.com/openimages/2018_04/class-descriptions-boxable.csv.\n",
            "2024-04-28 19:50:21,842 - root - Download https://storage.googleapis.com/openimages/2018_04/train/train-annotations-bbox.csv.\n",
            "2024-04-28 19:50:26,623 - root - Read annotation file data/open_images/train-annotations-bbox.csv\n",
            "2024-04-28 19:50:43,293 - root - train bounding boxes size: 1307\n",
            "2024-04-28 19:50:43,293 - root - Approximate Image Stats: \n",
            "2024-04-28 19:50:43,297 - root - Handgun: 561/990 = 0.57.\n",
            "2024-04-28 19:50:43,297 - root - Shotgun: 429/990 = 0.43.\n",
            "2024-04-28 19:50:43,297 - root - Label distribution: \n",
            "2024-04-28 19:50:43,297 - root - Handgun: 727/1307 = 0.56.\n",
            "2024-04-28 19:50:43,297 - root - Shotgun: 580/1307 = 0.44.\n",
            "2024-04-28 19:50:43,297 - root - Shuffle dataset.\n",
            "2024-04-28 19:50:43,297 - root - Save train data to data/open_images/sub-train-annotations-bbox.csv.\n",
            "2024-04-28 19:50:43,307 - root - Download https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-bbox.csv.\n",
            "2024-04-28 19:50:43,582 - root - Read annotation file data/open_images/validation-annotations-bbox.csv\n",
            "2024-04-28 19:50:43,852 - root - validation bounding boxes size: 50\n",
            "2024-04-28 19:50:43,852 - root - Approximate Image Stats: \n",
            "2024-04-28 19:50:43,854 - root - Handgun: 20/39 = 0.51.\n",
            "2024-04-28 19:50:43,854 - root - Shotgun: 19/39 = 0.49.\n",
            "2024-04-28 19:50:43,854 - root - Label distribution: \n",
            "2024-04-28 19:50:43,854 - root - Shotgun: 26/50 = 0.52.\n",
            "2024-04-28 19:50:43,855 - root - Handgun: 24/50 = 0.48.\n",
            "2024-04-28 19:50:43,855 - root - Shuffle dataset.\n",
            "2024-04-28 19:50:43,855 - root - Save validation data to data/open_images/sub-validation-annotations-bbox.csv.\n",
            "2024-04-28 19:50:43,856 - root - Download https://storage.googleapis.com/openimages/2018_04/test/test-annotations-bbox.csv.\n",
            "2024-04-28 19:50:44,258 - root - Read annotation file data/open_images/test-annotations-bbox.csv\n",
            "2024-04-28 19:50:45,003 - root - test bounding boxes size: 147\n",
            "2024-04-28 19:50:45,003 - root - Approximate Image Stats: \n",
            "2024-04-28 19:50:45,005 - root - Handgun: 72/130 = 0.55.\n",
            "2024-04-28 19:50:45,005 - root - Shotgun: 58/130 = 0.45.\n",
            "2024-04-28 19:50:45,005 - root - Label distribution: \n",
            "2024-04-28 19:50:45,005 - root - Handgun: 81/147 = 0.55.\n",
            "2024-04-28 19:50:45,005 - root - Shotgun: 66/147 = 0.45.\n",
            "2024-04-28 19:50:45,005 - root - Shuffle dataset.\n",
            "2024-04-28 19:50:45,005 - root - Save test data to data/open_images/sub-test-annotations-bbox.csv.\n",
            "2024-04-28 19:50:45,007 - root - Start downloading 1121 images.\n",
            "2024-04-28 19:50:46,831 - root - Downloaded 100 images.\n",
            "2024-04-28 19:50:47,866 - root - Downloaded 200 images.\n",
            "2024-04-28 19:50:48,956 - root - Downloaded 300 images.\n",
            "2024-04-28 19:50:49,941 - root - Downloaded 400 images.\n",
            "2024-04-28 19:50:50,941 - root - Downloaded 500 images.\n",
            "2024-04-28 19:50:51,937 - root - Downloaded 600 images.\n",
            "2024-04-28 19:50:52,904 - root - Downloaded 700 images.\n",
            "2024-04-28 19:50:53,892 - root - Downloaded 800 images.\n",
            "2024-04-28 19:50:54,852 - root - Downloaded 900 images.\n",
            "2024-04-28 19:50:56,253 - root - Downloaded 1000 images.\n",
            "2024-04-28 19:50:57,513 - root - Downloaded 1100 images.\n",
            "2024-04-28 19:50:58,169 - root - Task Done.\n"
          ]
        }
      ],
      "source": [
        "!python pytorch-ssd/open_images_downloader.py --root data/open_images --class_names \"Handgun,Shotgun\" --num_workers 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw0ZSGlfNY05"
      },
      "source": [
        "Download successfully, I choose Handguns and Shotguns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPYgW0KZt4fi",
        "outputId": "fed700e8-7561-4beb-94b0-7fb2659dd62a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/pytorch-ssd\n"
          ]
        }
      ],
      "source": [
        "%cd pytorch-ssd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzIOCSWQNY05",
        "outputId": "fffec4c8-7a9a-4820-f75f-b7820b5ba320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-28 19:52:05,584 - root - INFO - Use Cuda.\n",
            "2024-04-28 19:52:05,584 - root - INFO - Namespace(dataset_type='open_images', datasets=['../data/open_images'], validation_dataset=None, balance_data=False, net='mb1-ssd', freeze_base_net=False, freeze_net=False, mb2_width_mult=1.0, lr=0.01, momentum=0.9, weight_decay=0.0005, gamma=0.1, base_net_lr=0.001, extra_layers_lr=None, base_net=None, pretrained_ssd='models/mobilenet-v1-ssd-mp-0_675.pth', resume=None, scheduler='cosine', milestones='80,100', t_max=100.0, batch_size=5, num_epochs=100, num_workers=4, validation_epochs=5, debug_steps=100, use_cuda=True, checkpoint_folder='models/')\n",
            "2024-04-28 19:52:05,618 - root - INFO - Prepare training datasets.\n",
            "2024-04-28 19:52:06,164 - root - INFO - Dataset Summary:Number of Images: 961\n",
            "Minimum Number of Images for a Class: -1\n",
            "Label Distribution:\n",
            "\tHandgun: 727\n",
            "\tShotgun: 580\n",
            "2024-04-28 19:52:06,165 - root - INFO - Stored labels into file models/open-images-model-labels.txt.\n",
            "2024-04-28 19:52:06,166 - root - INFO - Train dataset size: 961\n",
            "2024-04-28 19:52:06,166 - root - INFO - Prepare Validation datasets.\n",
            "2024-04-28 19:52:06,235 - root - INFO - Dataset Summary:Number of Images: 123\n",
            "Minimum Number of Images for a Class: -1\n",
            "Label Distribution:\n",
            "\tHandgun: 81\n",
            "\tShotgun: 66\n",
            "2024-04-28 19:52:06,235 - root - INFO - validation dataset size: 123\n",
            "2024-04-28 19:52:06,235 - root - INFO - Build network.\n",
            "2024-04-28 19:52:06,318 - root - INFO - Init from pretrained ssd models/mobilenet-v1-ssd-mp-0_675.pth\n",
            "2024-04-28 19:52:06,366 - root - INFO - Took 0.05 seconds to load the model.\n",
            "2024-04-28 19:52:06,503 - root - INFO - Learning rate: 0.01, Base net learning rate: 0.001, Extra Layers learning rate: 0.01.\n",
            "2024-04-28 19:52:06,503 - root - INFO - Uses CosineAnnealingLR scheduler.\n",
            "2024-04-28 19:52:06,503 - root - INFO - Start training from epoch 0.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "2024-04-28 19:52:20,628 - root - INFO - Epoch: 0, Step: 100, Average Loss: 5.8176, Average Regression Loss 2.3205, Average Classification Loss: 3.4972\n",
            "2024-04-28 19:52:32,217 - root - INFO - Epoch: 0, Validation Loss: 3.7129, Validation Regression Loss 1.3253, Validation Classification Loss: 2.3876\n",
            "2024-04-28 19:52:32,275 - root - INFO - Saved model models/mb1-ssd-Epoch-0-Loss-3.7128826236724852.pth\n",
            "2024-04-28 19:52:44,038 - root - INFO - Epoch: 1, Step: 100, Average Loss: 4.4184, Average Regression Loss 1.6226, Average Classification Loss: 2.7957\n",
            "2024-04-28 19:53:05,887 - root - INFO - Epoch: 2, Step: 100, Average Loss: 3.9290, Average Regression Loss 1.3654, Average Classification Loss: 2.5635\n",
            "2024-04-28 19:53:27,733 - root - INFO - Epoch: 3, Step: 100, Average Loss: 3.8789, Average Regression Loss 1.3391, Average Classification Loss: 2.5398\n",
            "2024-04-28 19:53:47,590 - root - INFO - Epoch: 4, Step: 100, Average Loss: 3.7963, Average Regression Loss 1.2713, Average Classification Loss: 2.5250\n",
            "2024-04-28 19:54:09,574 - root - INFO - Epoch: 5, Step: 100, Average Loss: 3.5804, Average Regression Loss 1.2162, Average Classification Loss: 2.3642\n",
            "2024-04-28 19:54:20,449 - root - INFO - Epoch: 5, Validation Loss: 3.2142, Validation Regression Loss 1.0485, Validation Classification Loss: 2.1657\n",
            "2024-04-28 19:54:20,507 - root - INFO - Saved model models/mb1-ssd-Epoch-5-Loss-3.214212374687195.pth\n",
            "2024-04-28 19:54:32,085 - root - INFO - Epoch: 6, Step: 100, Average Loss: 3.5306, Average Regression Loss 1.1841, Average Classification Loss: 2.3464\n",
            "2024-04-28 19:54:52,789 - root - INFO - Epoch: 7, Step: 100, Average Loss: 3.4804, Average Regression Loss 1.1304, Average Classification Loss: 2.3500\n",
            "2024-04-28 19:55:14,136 - root - INFO - Epoch: 8, Step: 100, Average Loss: 3.7923, Average Regression Loss 1.2432, Average Classification Loss: 2.5491\n",
            "2024-04-28 19:55:35,123 - root - INFO - Epoch: 9, Step: 100, Average Loss: 3.5430, Average Regression Loss 1.1451, Average Classification Loss: 2.3979\n",
            "2024-04-28 19:55:55,672 - root - INFO - Epoch: 10, Step: 100, Average Loss: 3.2505, Average Regression Loss 1.0468, Average Classification Loss: 2.2037\n",
            "2024-04-28 19:56:06,490 - root - INFO - Epoch: 10, Validation Loss: 3.0161, Validation Regression Loss 0.9907, Validation Classification Loss: 2.0255\n",
            "2024-04-28 19:56:06,547 - root - INFO - Saved model models/mb1-ssd-Epoch-10-Loss-3.0161177825927736.pth\n",
            "2024-04-28 19:56:18,184 - root - INFO - Epoch: 11, Step: 100, Average Loss: 3.2630, Average Regression Loss 1.0369, Average Classification Loss: 2.2261\n",
            "2024-04-28 19:56:39,678 - root - INFO - Epoch: 12, Step: 100, Average Loss: 3.2754, Average Regression Loss 1.0446, Average Classification Loss: 2.2308\n",
            "2024-04-28 19:57:01,559 - root - INFO - Epoch: 13, Step: 100, Average Loss: 3.2263, Average Regression Loss 1.0358, Average Classification Loss: 2.1905\n",
            "2024-04-28 19:57:22,606 - root - INFO - Epoch: 14, Step: 100, Average Loss: 3.2880, Average Regression Loss 1.0769, Average Classification Loss: 2.2111\n",
            "2024-04-28 19:57:44,088 - root - INFO - Epoch: 15, Step: 100, Average Loss: 3.0621, Average Regression Loss 0.9794, Average Classification Loss: 2.0827\n",
            "2024-04-28 19:57:54,400 - root - INFO - Epoch: 15, Validation Loss: 2.8506, Validation Regression Loss 0.9328, Validation Classification Loss: 1.9178\n",
            "2024-04-28 19:57:54,455 - root - INFO - Saved model models/mb1-ssd-Epoch-15-Loss-2.8505722808837892.pth\n",
            "2024-04-28 19:58:05,165 - root - INFO - Epoch: 16, Step: 100, Average Loss: 3.2838, Average Regression Loss 1.0643, Average Classification Loss: 2.2195\n",
            "2024-04-28 19:58:26,135 - root - INFO - Epoch: 17, Step: 100, Average Loss: 3.0942, Average Regression Loss 0.9811, Average Classification Loss: 2.1132\n",
            "2024-04-28 19:58:47,113 - root - INFO - Epoch: 18, Step: 100, Average Loss: 3.1558, Average Regression Loss 0.9963, Average Classification Loss: 2.1595\n",
            "2024-04-28 19:59:09,386 - root - INFO - Epoch: 19, Step: 100, Average Loss: 3.1333, Average Regression Loss 1.0351, Average Classification Loss: 2.0981\n",
            "2024-04-28 19:59:30,316 - root - INFO - Epoch: 20, Step: 100, Average Loss: 3.0170, Average Regression Loss 0.9488, Average Classification Loss: 2.0682\n",
            "2024-04-28 19:59:40,514 - root - INFO - Epoch: 20, Validation Loss: 2.8006, Validation Regression Loss 0.8711, Validation Classification Loss: 1.9295\n",
            "2024-04-28 19:59:40,569 - root - INFO - Saved model models/mb1-ssd-Epoch-20-Loss-2.8006146574020385.pth\n",
            "2024-04-28 19:59:52,645 - root - INFO - Epoch: 21, Step: 100, Average Loss: 3.1201, Average Regression Loss 1.0393, Average Classification Loss: 2.0809\n",
            "2024-04-28 20:00:12,661 - root - INFO - Epoch: 22, Step: 100, Average Loss: 3.0573, Average Regression Loss 0.9784, Average Classification Loss: 2.0788\n",
            "2024-04-28 20:00:34,062 - root - INFO - Epoch: 23, Step: 100, Average Loss: 3.0724, Average Regression Loss 1.0117, Average Classification Loss: 2.0607\n",
            "2024-04-28 20:00:55,306 - root - INFO - Epoch: 24, Step: 100, Average Loss: 3.0503, Average Regression Loss 0.9730, Average Classification Loss: 2.0773\n",
            "2024-04-28 20:01:14,870 - root - INFO - Epoch: 25, Step: 100, Average Loss: 2.9372, Average Regression Loss 0.9282, Average Classification Loss: 2.0091\n",
            "2024-04-28 20:01:25,679 - root - INFO - Epoch: 25, Validation Loss: 3.0601, Validation Regression Loss 0.9503, Validation Classification Loss: 2.1098\n",
            "2024-04-28 20:01:25,737 - root - INFO - Saved model models/mb1-ssd-Epoch-25-Loss-3.0601189947128296.pth\n",
            "2024-04-28 20:01:37,011 - root - INFO - Epoch: 26, Step: 100, Average Loss: 3.0041, Average Regression Loss 0.9443, Average Classification Loss: 2.0598\n",
            "2024-04-28 20:01:56,705 - root - INFO - Epoch: 27, Step: 100, Average Loss: 2.7009, Average Regression Loss 0.8349, Average Classification Loss: 1.8661\n",
            "2024-04-28 20:02:16,417 - root - INFO - Epoch: 28, Step: 100, Average Loss: 2.7956, Average Regression Loss 0.8798, Average Classification Loss: 1.9157\n",
            "2024-04-28 20:02:37,349 - root - INFO - Epoch: 29, Step: 100, Average Loss: 2.7595, Average Regression Loss 0.8434, Average Classification Loss: 1.9161\n",
            "2024-04-28 20:02:57,332 - root - INFO - Epoch: 30, Step: 100, Average Loss: 2.9520, Average Regression Loss 0.9232, Average Classification Loss: 2.0288\n",
            "2024-04-28 20:03:07,830 - root - INFO - Epoch: 30, Validation Loss: 2.8361, Validation Regression Loss 0.8649, Validation Classification Loss: 1.9712\n",
            "2024-04-28 20:03:07,886 - root - INFO - Saved model models/mb1-ssd-Epoch-30-Loss-2.8361488676071165.pth\n",
            "2024-04-28 20:03:19,597 - root - INFO - Epoch: 31, Step: 100, Average Loss: 2.8739, Average Regression Loss 0.9232, Average Classification Loss: 1.9507\n",
            "2024-04-28 20:03:41,036 - root - INFO - Epoch: 32, Step: 100, Average Loss: 2.8507, Average Regression Loss 0.8805, Average Classification Loss: 1.9702\n",
            "2024-04-28 20:04:02,618 - root - INFO - Epoch: 33, Step: 100, Average Loss: 3.0188, Average Regression Loss 0.9553, Average Classification Loss: 2.0635\n",
            "2024-04-28 20:04:24,365 - root - INFO - Epoch: 34, Step: 100, Average Loss: 2.6404, Average Regression Loss 0.8078, Average Classification Loss: 1.8326\n",
            "2024-04-28 20:04:44,483 - root - INFO - Epoch: 35, Step: 100, Average Loss: 2.6446, Average Regression Loss 0.7780, Average Classification Loss: 1.8666\n",
            "2024-04-28 20:04:55,323 - root - INFO - Epoch: 35, Validation Loss: 2.8666, Validation Regression Loss 0.8609, Validation Classification Loss: 2.0057\n",
            "2024-04-28 20:04:55,379 - root - INFO - Saved model models/mb1-ssd-Epoch-35-Loss-2.8666466808319093.pth\n",
            "2024-04-28 20:05:06,295 - root - INFO - Epoch: 36, Step: 100, Average Loss: 2.7712, Average Regression Loss 0.8643, Average Classification Loss: 1.9069\n",
            "2024-04-28 20:05:28,607 - root - INFO - Epoch: 37, Step: 100, Average Loss: 2.6759, Average Regression Loss 0.8160, Average Classification Loss: 1.8599\n",
            "2024-04-28 20:05:49,259 - root - INFO - Epoch: 38, Step: 100, Average Loss: 2.6556, Average Regression Loss 0.7650, Average Classification Loss: 1.8906\n",
            "2024-04-28 20:06:10,445 - root - INFO - Epoch: 39, Step: 100, Average Loss: 2.5961, Average Regression Loss 0.7813, Average Classification Loss: 1.8148\n",
            "2024-04-28 20:06:30,520 - root - INFO - Epoch: 40, Step: 100, Average Loss: 2.5207, Average Regression Loss 0.7832, Average Classification Loss: 1.7375\n",
            "2024-04-28 20:06:42,450 - root - INFO - Epoch: 40, Validation Loss: 2.9387, Validation Regression Loss 0.8615, Validation Classification Loss: 2.0771\n",
            "2024-04-28 20:06:42,504 - root - INFO - Saved model models/mb1-ssd-Epoch-40-Loss-2.9386500453948976.pth\n",
            "2024-04-28 20:06:53,895 - root - INFO - Epoch: 41, Step: 100, Average Loss: 2.5645, Average Regression Loss 0.7900, Average Classification Loss: 1.7746\n",
            "2024-04-28 20:07:14,747 - root - INFO - Epoch: 42, Step: 100, Average Loss: 2.5849, Average Regression Loss 0.7885, Average Classification Loss: 1.7963\n",
            "2024-04-28 20:07:36,661 - root - INFO - Epoch: 43, Step: 100, Average Loss: 2.5135, Average Regression Loss 0.7340, Average Classification Loss: 1.7796\n",
            "2024-04-28 20:07:57,258 - root - INFO - Epoch: 44, Step: 100, Average Loss: 2.6205, Average Regression Loss 0.7945, Average Classification Loss: 1.8260\n",
            "2024-04-28 20:08:19,295 - root - INFO - Epoch: 45, Step: 100, Average Loss: 2.6885, Average Regression Loss 0.8399, Average Classification Loss: 1.8486\n",
            "2024-04-28 20:08:29,821 - root - INFO - Epoch: 45, Validation Loss: 2.9144, Validation Regression Loss 0.8908, Validation Classification Loss: 2.0235\n",
            "2024-04-28 20:08:29,876 - root - INFO - Saved model models/mb1-ssd-Epoch-45-Loss-2.914350161552429.pth\n",
            "2024-04-28 20:08:41,105 - root - INFO - Epoch: 46, Step: 100, Average Loss: 2.5371, Average Regression Loss 0.7667, Average Classification Loss: 1.7703\n",
            "2024-04-28 20:09:01,279 - root - INFO - Epoch: 47, Step: 100, Average Loss: 2.5299, Average Regression Loss 0.7607, Average Classification Loss: 1.7692\n",
            "2024-04-28 20:09:22,214 - root - INFO - Epoch: 48, Step: 100, Average Loss: 2.4885, Average Regression Loss 0.7478, Average Classification Loss: 1.7406\n",
            "2024-04-28 20:09:43,589 - root - INFO - Epoch: 49, Step: 100, Average Loss: 2.4867, Average Regression Loss 0.7355, Average Classification Loss: 1.7513\n",
            "2024-04-28 20:10:06,023 - root - INFO - Epoch: 50, Step: 100, Average Loss: 2.6343, Average Regression Loss 0.7799, Average Classification Loss: 1.8544\n",
            "2024-04-28 20:10:16,378 - root - INFO - Epoch: 50, Validation Loss: 2.6916, Validation Regression Loss 0.8054, Validation Classification Loss: 1.8862\n",
            "2024-04-28 20:10:16,438 - root - INFO - Saved model models/mb1-ssd-Epoch-50-Loss-2.691582536697388.pth\n",
            "2024-04-28 20:10:27,051 - root - INFO - Epoch: 51, Step: 100, Average Loss: 2.3904, Average Regression Loss 0.7231, Average Classification Loss: 1.6673\n",
            "2024-04-28 20:10:48,472 - root - INFO - Epoch: 52, Step: 100, Average Loss: 2.4145, Average Regression Loss 0.7325, Average Classification Loss: 1.6821\n",
            "2024-04-28 20:11:10,376 - root - INFO - Epoch: 53, Step: 100, Average Loss: 2.4207, Average Regression Loss 0.7302, Average Classification Loss: 1.6904\n",
            "2024-04-28 20:11:31,308 - root - INFO - Epoch: 54, Step: 100, Average Loss: 2.4244, Average Regression Loss 0.6835, Average Classification Loss: 1.7409\n",
            "2024-04-28 20:11:51,648 - root - INFO - Epoch: 55, Step: 100, Average Loss: 2.4461, Average Regression Loss 0.7273, Average Classification Loss: 1.7187\n",
            "2024-04-28 20:12:02,020 - root - INFO - Epoch: 55, Validation Loss: 2.8336, Validation Regression Loss 0.8591, Validation Classification Loss: 1.9745\n",
            "2024-04-28 20:12:02,075 - root - INFO - Saved model models/mb1-ssd-Epoch-55-Loss-2.83359605550766.pth\n",
            "2024-04-28 20:12:13,425 - root - INFO - Epoch: 56, Step: 100, Average Loss: 2.3049, Average Regression Loss 0.6922, Average Classification Loss: 1.6127\n",
            "2024-04-28 20:12:35,460 - root - INFO - Epoch: 57, Step: 100, Average Loss: 2.2609, Average Regression Loss 0.6709, Average Classification Loss: 1.5900\n",
            "2024-04-28 20:12:55,958 - root - INFO - Epoch: 58, Step: 100, Average Loss: 2.1768, Average Regression Loss 0.6243, Average Classification Loss: 1.5525\n",
            "2024-04-28 20:13:17,783 - root - INFO - Epoch: 59, Step: 100, Average Loss: 2.2426, Average Regression Loss 0.6650, Average Classification Loss: 1.5776\n",
            "2024-04-28 20:13:38,110 - root - INFO - Epoch: 60, Step: 100, Average Loss: 2.3188, Average Regression Loss 0.6672, Average Classification Loss: 1.6516\n",
            "2024-04-28 20:13:49,995 - root - INFO - Epoch: 60, Validation Loss: 2.8544, Validation Regression Loss 0.8584, Validation Classification Loss: 1.9960\n",
            "2024-04-28 20:13:50,050 - root - INFO - Saved model models/mb1-ssd-Epoch-60-Loss-2.8543707227706907.pth\n",
            "2024-04-28 20:14:01,540 - root - INFO - Epoch: 61, Step: 100, Average Loss: 2.1394, Average Regression Loss 0.5778, Average Classification Loss: 1.5616\n",
            "2024-04-28 20:14:22,413 - root - INFO - Epoch: 62, Step: 100, Average Loss: 2.3198, Average Regression Loss 0.7032, Average Classification Loss: 1.6166\n",
            "2024-04-28 20:14:44,713 - root - INFO - Epoch: 63, Step: 100, Average Loss: 2.2402, Average Regression Loss 0.6404, Average Classification Loss: 1.5999\n",
            "2024-04-28 20:15:05,631 - root - INFO - Epoch: 64, Step: 100, Average Loss: 2.1520, Average Regression Loss 0.6126, Average Classification Loss: 1.5394\n",
            "2024-04-28 20:15:27,343 - root - INFO - Epoch: 65, Step: 100, Average Loss: 2.1156, Average Regression Loss 0.6107, Average Classification Loss: 1.5049\n",
            "2024-04-28 20:15:37,455 - root - INFO - Epoch: 65, Validation Loss: 2.8353, Validation Regression Loss 0.8152, Validation Classification Loss: 2.0201\n",
            "2024-04-28 20:15:37,511 - root - INFO - Saved model models/mb1-ssd-Epoch-65-Loss-2.8352642965316774.pth\n",
            "2024-04-28 20:15:48,326 - root - INFO - Epoch: 66, Step: 100, Average Loss: 2.1175, Average Regression Loss 0.5948, Average Classification Loss: 1.5227\n",
            "2024-04-28 20:16:09,612 - root - INFO - Epoch: 67, Step: 100, Average Loss: 2.2051, Average Regression Loss 0.6211, Average Classification Loss: 1.5840\n",
            "2024-04-28 20:16:31,255 - root - INFO - Epoch: 68, Step: 100, Average Loss: 2.1673, Average Regression Loss 0.6244, Average Classification Loss: 1.5429\n",
            "2024-04-28 20:16:51,545 - root - INFO - Epoch: 69, Step: 100, Average Loss: 1.9746, Average Regression Loss 0.5488, Average Classification Loss: 1.4258\n",
            "2024-04-28 20:17:12,853 - root - INFO - Epoch: 70, Step: 100, Average Loss: 2.0724, Average Regression Loss 0.5997, Average Classification Loss: 1.4727\n",
            "2024-04-28 20:17:23,551 - root - INFO - Epoch: 70, Validation Loss: 2.7660, Validation Regression Loss 0.8307, Validation Classification Loss: 1.9353\n",
            "2024-04-28 20:17:23,606 - root - INFO - Saved model models/mb1-ssd-Epoch-70-Loss-2.766000008583069.pth\n",
            "2024-04-28 20:17:34,337 - root - INFO - Epoch: 71, Step: 100, Average Loss: 2.1681, Average Regression Loss 0.6033, Average Classification Loss: 1.5649\n",
            "2024-04-28 20:17:54,523 - root - INFO - Epoch: 72, Step: 100, Average Loss: 2.0184, Average Regression Loss 0.5644, Average Classification Loss: 1.4541\n",
            "2024-04-28 20:18:15,313 - root - INFO - Epoch: 73, Step: 100, Average Loss: 2.0370, Average Regression Loss 0.5684, Average Classification Loss: 1.4686\n",
            "2024-04-28 20:18:37,296 - root - INFO - Epoch: 74, Step: 100, Average Loss: 1.9966, Average Regression Loss 0.5802, Average Classification Loss: 1.4164\n",
            "2024-04-28 20:18:59,501 - root - INFO - Epoch: 75, Step: 100, Average Loss: 1.9734, Average Regression Loss 0.5660, Average Classification Loss: 1.4074\n",
            "2024-04-28 20:19:11,021 - root - INFO - Epoch: 75, Validation Loss: 2.7819, Validation Regression Loss 0.8029, Validation Classification Loss: 1.9790\n",
            "2024-04-28 20:19:11,076 - root - INFO - Saved model models/mb1-ssd-Epoch-75-Loss-2.7818708539009096.pth\n",
            "2024-04-28 20:19:23,115 - root - INFO - Epoch: 76, Step: 100, Average Loss: 1.9664, Average Regression Loss 0.5475, Average Classification Loss: 1.4188\n",
            "2024-04-28 20:19:45,655 - root - INFO - Epoch: 77, Step: 100, Average Loss: 1.9685, Average Regression Loss 0.5792, Average Classification Loss: 1.3893\n",
            "2024-04-28 20:20:07,288 - root - INFO - Epoch: 78, Step: 100, Average Loss: 1.9713, Average Regression Loss 0.5474, Average Classification Loss: 1.4238\n",
            "2024-04-28 20:20:28,557 - root - INFO - Epoch: 79, Step: 100, Average Loss: 1.9344, Average Regression Loss 0.5434, Average Classification Loss: 1.3910\n",
            "2024-04-28 20:20:49,053 - root - INFO - Epoch: 80, Step: 100, Average Loss: 1.9415, Average Regression Loss 0.5291, Average Classification Loss: 1.4123\n",
            "2024-04-28 20:20:59,656 - root - INFO - Epoch: 80, Validation Loss: 2.7982, Validation Regression Loss 0.8030, Validation Classification Loss: 1.9952\n",
            "2024-04-28 20:20:59,713 - root - INFO - Saved model models/mb1-ssd-Epoch-80-Loss-2.798204951286316.pth\n",
            "2024-04-28 20:21:11,372 - root - INFO - Epoch: 81, Step: 100, Average Loss: 1.8959, Average Regression Loss 0.5364, Average Classification Loss: 1.3595\n",
            "2024-04-28 20:21:31,141 - root - INFO - Epoch: 82, Step: 100, Average Loss: 1.9275, Average Regression Loss 0.5530, Average Classification Loss: 1.3745\n",
            "2024-04-28 20:21:53,100 - root - INFO - Epoch: 83, Step: 100, Average Loss: 2.0129, Average Regression Loss 0.5566, Average Classification Loss: 1.4563\n",
            "2024-04-28 20:22:14,457 - root - INFO - Epoch: 84, Step: 100, Average Loss: 1.9458, Average Regression Loss 0.5689, Average Classification Loss: 1.3769\n",
            "2024-04-28 20:22:35,950 - root - INFO - Epoch: 85, Step: 100, Average Loss: 1.9860, Average Regression Loss 0.5498, Average Classification Loss: 1.4362\n",
            "2024-04-28 20:22:46,891 - root - INFO - Epoch: 85, Validation Loss: 2.8108, Validation Regression Loss 0.8064, Validation Classification Loss: 2.0044\n",
            "2024-04-28 20:22:46,947 - root - INFO - Saved model models/mb1-ssd-Epoch-85-Loss-2.8108258962631227.pth\n",
            "2024-04-28 20:22:57,457 - root - INFO - Epoch: 86, Step: 100, Average Loss: 1.9118, Average Regression Loss 0.5229, Average Classification Loss: 1.3890\n",
            "2024-04-28 20:23:19,342 - root - INFO - Epoch: 87, Step: 100, Average Loss: 2.0057, Average Regression Loss 0.5782, Average Classification Loss: 1.4275\n",
            "2024-04-28 20:23:41,506 - root - INFO - Epoch: 88, Step: 100, Average Loss: 1.9402, Average Regression Loss 0.5778, Average Classification Loss: 1.3624\n",
            "2024-04-28 20:24:01,882 - root - INFO - Epoch: 89, Step: 100, Average Loss: 1.9133, Average Regression Loss 0.5202, Average Classification Loss: 1.3931\n",
            "2024-04-28 20:24:23,074 - root - INFO - Epoch: 90, Step: 100, Average Loss: 1.8872, Average Regression Loss 0.5254, Average Classification Loss: 1.3618\n",
            "2024-04-28 20:24:33,120 - root - INFO - Epoch: 90, Validation Loss: 2.7820, Validation Regression Loss 0.7858, Validation Classification Loss: 1.9962\n",
            "2024-04-28 20:24:33,175 - root - INFO - Saved model models/mb1-ssd-Epoch-90-Loss-2.7819643449783324.pth\n",
            "2024-04-28 20:24:44,209 - root - INFO - Epoch: 91, Step: 100, Average Loss: 2.0057, Average Regression Loss 0.5671, Average Classification Loss: 1.4386\n",
            "2024-04-28 20:25:04,816 - root - INFO - Epoch: 92, Step: 100, Average Loss: 1.9282, Average Regression Loss 0.5434, Average Classification Loss: 1.3847\n",
            "2024-04-28 20:25:26,142 - root - INFO - Epoch: 93, Step: 100, Average Loss: 2.0357, Average Regression Loss 0.6114, Average Classification Loss: 1.4243\n",
            "2024-04-28 20:25:46,738 - root - INFO - Epoch: 94, Step: 100, Average Loss: 1.9018, Average Regression Loss 0.4998, Average Classification Loss: 1.4019\n",
            "2024-04-28 20:26:07,269 - root - INFO - Epoch: 95, Step: 100, Average Loss: 1.8166, Average Regression Loss 0.5104, Average Classification Loss: 1.3062\n",
            "2024-04-28 20:26:17,217 - root - INFO - Epoch: 95, Validation Loss: 2.7526, Validation Regression Loss 0.7781, Validation Classification Loss: 1.9745\n",
            "2024-04-28 20:26:17,272 - root - INFO - Saved model models/mb1-ssd-Epoch-95-Loss-2.7526174116134645.pth\n",
            "2024-04-28 20:26:29,160 - root - INFO - Epoch: 96, Step: 100, Average Loss: 1.9313, Average Regression Loss 0.5328, Average Classification Loss: 1.3986\n",
            "2024-04-28 20:26:50,075 - root - INFO - Epoch: 97, Step: 100, Average Loss: 1.8057, Average Regression Loss 0.5037, Average Classification Loss: 1.3020\n",
            "2024-04-28 20:27:12,816 - root - INFO - Epoch: 98, Step: 100, Average Loss: 1.9176, Average Regression Loss 0.5251, Average Classification Loss: 1.3925\n",
            "2024-04-28 20:27:34,098 - root - INFO - Epoch: 99, Step: 100, Average Loss: 1.9512, Average Regression Loss 0.5389, Average Classification Loss: 1.4123\n",
            "2024-04-28 20:27:44,356 - root - INFO - Epoch: 99, Validation Loss: 2.7985, Validation Regression Loss 0.7985, Validation Classification Loss: 2.0000\n",
            "2024-04-28 20:27:44,411 - root - INFO - Saved model models/mb1-ssd-Epoch-99-Loss-2.798509557247162.pth\n"
          ]
        }
      ],
      "source": [
        "!python train_ssd.py --dataset_type open_images --datasets ../data/open_images --net mb1-ssd --pretrained_ssd models/mobilenet-v1-ssd-mp-0_675.pth --scheduler cosine --lr 0.01 --t_max 100 --validation_epochs 5 --num_epochs 100 --base_net_lr 0.001  --batch_size 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_MurjQgRaFA",
        "outputId": "7340a917-b34f-4bbb-d0bb-e58c285044be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/pytorch-ssd/eval_ssd.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  all_gt_boxes[class_index][image_id] = torch.tensor(all_gt_boxes[class_index][image_id])\n",
            "It took 0.04636216163635254 seconds to load the model.\n",
            "process image 0\n",
            "Load Image: 0.019361 seconds.\n",
            "Inference time:  0.6022565364837646\n",
            "Prediction: 0.611756 seconds.\n",
            "process image 1\n",
            "Load Image: 0.009265 seconds.\n",
            "Inference time:  0.005998373031616211\n",
            "Prediction: 0.016124 seconds.\n",
            "process image 2\n",
            "Load Image: 0.007794 seconds.\n",
            "Inference time:  0.00577545166015625\n",
            "Prediction: 0.014228 seconds.\n",
            "process image 3\n",
            "Load Image: 0.010273 seconds.\n",
            "Inference time:  0.006129026412963867\n",
            "Prediction: 0.010442 seconds.\n",
            "process image 4\n",
            "Load Image: 0.014009 seconds.\n",
            "Inference time:  0.0057332515716552734\n",
            "Prediction: 0.011431 seconds.\n",
            "process image 5\n",
            "Load Image: 0.008108 seconds.\n",
            "Inference time:  0.006911754608154297\n",
            "Prediction: 0.019938 seconds.\n",
            "process image 6\n",
            "Load Image: 0.007970 seconds.\n",
            "Inference time:  0.006722927093505859\n",
            "Prediction: 0.014618 seconds.\n",
            "process image 7\n",
            "Load Image: 0.010936 seconds.\n",
            "Inference time:  0.0061948299407958984\n",
            "Prediction: 0.017478 seconds.\n",
            "process image 8\n",
            "Load Image: 0.012516 seconds.\n",
            "Inference time:  0.0062906742095947266\n",
            "Prediction: 0.014324 seconds.\n",
            "process image 9\n",
            "Load Image: 0.014498 seconds.\n",
            "Inference time:  0.0061779022216796875\n",
            "Prediction: 0.018897 seconds.\n",
            "process image 10\n",
            "Load Image: 0.015007 seconds.\n",
            "Inference time:  0.0059299468994140625\n",
            "Prediction: 0.024511 seconds.\n",
            "process image 11\n",
            "Load Image: 0.004669 seconds.\n",
            "Inference time:  0.005816936492919922\n",
            "Prediction: 0.010463 seconds.\n",
            "process image 12\n",
            "Load Image: 0.008841 seconds.\n",
            "Inference time:  0.0057220458984375\n",
            "Prediction: 0.008897 seconds.\n",
            "process image 13\n",
            "Load Image: 0.008770 seconds.\n",
            "Inference time:  0.005789518356323242\n",
            "Prediction: 0.017917 seconds.\n",
            "process image 14\n",
            "Load Image: 0.015273 seconds.\n",
            "Inference time:  0.005759477615356445\n",
            "Prediction: 0.017855 seconds.\n",
            "process image 15\n",
            "Load Image: 0.010657 seconds.\n",
            "Inference time:  0.005661487579345703\n",
            "Prediction: 0.008473 seconds.\n",
            "process image 16\n",
            "Load Image: 0.013266 seconds.\n",
            "Inference time:  0.005590915679931641\n",
            "Prediction: 0.017372 seconds.\n",
            "process image 17\n",
            "Load Image: 0.014255 seconds.\n",
            "Inference time:  0.0056610107421875\n",
            "Prediction: 0.008930 seconds.\n",
            "process image 18\n",
            "Load Image: 0.014851 seconds.\n",
            "Inference time:  0.005680084228515625\n",
            "Prediction: 0.010995 seconds.\n",
            "process image 19\n",
            "Load Image: 0.006201 seconds.\n",
            "Inference time:  0.005585432052612305\n",
            "Prediction: 0.009145 seconds.\n",
            "process image 20\n",
            "Load Image: 0.010387 seconds.\n",
            "Inference time:  0.00566864013671875\n",
            "Prediction: 0.008500 seconds.\n",
            "process image 21\n",
            "Load Image: 0.006579 seconds.\n",
            "Inference time:  0.005603313446044922\n",
            "Prediction: 0.012940 seconds.\n",
            "process image 22\n",
            "Load Image: 0.010368 seconds.\n",
            "Inference time:  0.0055887699127197266\n",
            "Prediction: 0.014454 seconds.\n",
            "process image 23\n",
            "Load Image: 0.008499 seconds.\n",
            "Inference time:  0.0055620670318603516\n",
            "Prediction: 0.009843 seconds.\n",
            "process image 24\n",
            "Load Image: 0.023427 seconds.\n",
            "Inference time:  0.005944728851318359\n",
            "Prediction: 0.017305 seconds.\n",
            "process image 25\n",
            "Load Image: 0.016585 seconds.\n",
            "Inference time:  0.0057833194732666016\n",
            "Prediction: 0.012592 seconds.\n",
            "process image 26\n",
            "Load Image: 0.010315 seconds.\n",
            "Inference time:  0.0056803226470947266\n",
            "Prediction: 0.017360 seconds.\n",
            "process image 27\n",
            "Load Image: 0.009214 seconds.\n",
            "Inference time:  0.005602359771728516\n",
            "Prediction: 0.008522 seconds.\n",
            "process image 28\n",
            "Load Image: 0.012424 seconds.\n",
            "Inference time:  0.00558161735534668\n",
            "Prediction: 0.016105 seconds.\n",
            "process image 29\n",
            "Load Image: 0.006059 seconds.\n",
            "Inference time:  0.005510807037353516\n",
            "Prediction: 0.008761 seconds.\n",
            "process image 30\n",
            "Load Image: 0.020822 seconds.\n",
            "Inference time:  0.0056324005126953125\n",
            "Prediction: 0.013140 seconds.\n",
            "process image 31\n",
            "Load Image: 0.006612 seconds.\n",
            "Inference time:  0.005584239959716797\n",
            "Prediction: 0.010285 seconds.\n",
            "process image 32\n",
            "Load Image: 0.010479 seconds.\n",
            "Inference time:  0.005621910095214844\n",
            "Prediction: 0.008634 seconds.\n",
            "process image 33\n",
            "Load Image: 0.014161 seconds.\n",
            "Inference time:  0.0056035518646240234\n",
            "Prediction: 0.010755 seconds.\n",
            "process image 34\n",
            "Load Image: 0.010069 seconds.\n",
            "Inference time:  0.005600690841674805\n",
            "Prediction: 0.016415 seconds.\n",
            "process image 35\n",
            "Load Image: 0.007985 seconds.\n",
            "Inference time:  0.0065424442291259766\n",
            "Prediction: 0.009806 seconds.\n",
            "process image 36\n",
            "Load Image: 0.018013 seconds.\n",
            "Inference time:  0.005602836608886719\n",
            "Prediction: 0.018601 seconds.\n",
            "process image 37\n",
            "Load Image: 0.008391 seconds.\n",
            "Inference time:  0.005507707595825195\n",
            "Prediction: 0.009322 seconds.\n",
            "process image 38\n",
            "Load Image: 0.013516 seconds.\n",
            "Inference time:  0.005442619323730469\n",
            "Prediction: 0.014659 seconds.\n",
            "process image 39\n",
            "Load Image: 0.010496 seconds.\n",
            "Inference time:  0.0054912567138671875\n",
            "Prediction: 0.015320 seconds.\n",
            "process image 40\n",
            "Load Image: 0.009610 seconds.\n",
            "Inference time:  0.005455732345581055\n",
            "Prediction: 0.014722 seconds.\n",
            "process image 41\n",
            "Load Image: 0.012322 seconds.\n",
            "Inference time:  0.0053863525390625\n",
            "Prediction: 0.014555 seconds.\n",
            "process image 42\n",
            "Load Image: 0.007933 seconds.\n",
            "Inference time:  0.007459163665771484\n",
            "Prediction: 0.012822 seconds.\n",
            "process image 43\n",
            "Load Image: 0.016605 seconds.\n",
            "Inference time:  0.00574946403503418\n",
            "Prediction: 0.023191 seconds.\n",
            "process image 44\n",
            "Load Image: 0.021562 seconds.\n",
            "Inference time:  0.005612373352050781\n",
            "Prediction: 0.017360 seconds.\n",
            "process image 45\n",
            "Load Image: 0.010674 seconds.\n",
            "Inference time:  0.005560159683227539\n",
            "Prediction: 0.017718 seconds.\n",
            "process image 46\n",
            "Load Image: 0.004007 seconds.\n",
            "Inference time:  0.005530357360839844\n",
            "Prediction: 0.009105 seconds.\n",
            "process image 47\n",
            "Load Image: 0.025445 seconds.\n",
            "Inference time:  0.005586385726928711\n",
            "Prediction: 0.008716 seconds.\n",
            "process image 48\n",
            "Load Image: 0.008518 seconds.\n",
            "Inference time:  0.005469083786010742\n",
            "Prediction: 0.018467 seconds.\n",
            "process image 49\n",
            "Load Image: 0.013253 seconds.\n",
            "Inference time:  0.005556583404541016\n",
            "Prediction: 0.016437 seconds.\n",
            "process image 50\n",
            "Load Image: 0.013320 seconds.\n",
            "Inference time:  0.0055119991302490234\n",
            "Prediction: 0.008308 seconds.\n",
            "process image 51\n",
            "Load Image: 0.007652 seconds.\n",
            "Inference time:  0.005510091781616211\n",
            "Prediction: 0.010423 seconds.\n",
            "process image 52\n",
            "Load Image: 0.005326 seconds.\n",
            "Inference time:  0.005506753921508789\n",
            "Prediction: 0.009340 seconds.\n",
            "process image 53\n",
            "Load Image: 0.014857 seconds.\n",
            "Inference time:  0.005524158477783203\n",
            "Prediction: 0.018805 seconds.\n",
            "process image 54\n",
            "Load Image: 0.008840 seconds.\n",
            "Inference time:  0.005490779876708984\n",
            "Prediction: 0.011850 seconds.\n",
            "process image 55\n",
            "Load Image: 0.009527 seconds.\n",
            "Inference time:  0.0055310726165771484\n",
            "Prediction: 0.015410 seconds.\n",
            "process image 56\n",
            "Load Image: 0.009954 seconds.\n",
            "Inference time:  0.005515098571777344\n",
            "Prediction: 0.019545 seconds.\n",
            "process image 57\n",
            "Load Image: 0.022233 seconds.\n",
            "Inference time:  0.005723714828491211\n",
            "Prediction: 0.016567 seconds.\n",
            "process image 58\n",
            "Load Image: 0.013635 seconds.\n",
            "Inference time:  0.005540132522583008\n",
            "Prediction: 0.008262 seconds.\n",
            "process image 59\n",
            "Load Image: 0.007250 seconds.\n",
            "Inference time:  0.005485057830810547\n",
            "Prediction: 0.008663 seconds.\n",
            "process image 60\n",
            "Load Image: 0.010399 seconds.\n",
            "Inference time:  0.005458831787109375\n",
            "Prediction: 0.021004 seconds.\n",
            "process image 61\n",
            "Load Image: 0.011458 seconds.\n",
            "Inference time:  0.005507707595825195\n",
            "Prediction: 0.008550 seconds.\n",
            "process image 62\n",
            "Load Image: 0.015986 seconds.\n",
            "Inference time:  0.005634784698486328\n",
            "Prediction: 0.014394 seconds.\n",
            "process image 63\n",
            "Load Image: 0.019022 seconds.\n",
            "Inference time:  0.005829811096191406\n",
            "Prediction: 0.011706 seconds.\n",
            "process image 64\n",
            "Load Image: 0.008809 seconds.\n",
            "Inference time:  0.0056133270263671875\n",
            "Prediction: 0.008698 seconds.\n",
            "process image 65\n",
            "Load Image: 0.011003 seconds.\n",
            "Inference time:  0.0056149959564208984\n",
            "Prediction: 0.009947 seconds.\n",
            "process image 66\n",
            "Load Image: 0.011717 seconds.\n",
            "Inference time:  0.005641460418701172\n",
            "Prediction: 0.015750 seconds.\n",
            "process image 67\n",
            "Load Image: 0.013659 seconds.\n",
            "Inference time:  0.006078243255615234\n",
            "Prediction: 0.024309 seconds.\n",
            "process image 68\n",
            "Load Image: 0.012439 seconds.\n",
            "Inference time:  0.005553007125854492\n",
            "Prediction: 0.017620 seconds.\n",
            "process image 69\n",
            "Load Image: 0.007342 seconds.\n",
            "Inference time:  0.005566835403442383\n",
            "Prediction: 0.008289 seconds.\n",
            "process image 70\n",
            "Load Image: 0.003895 seconds.\n",
            "Inference time:  0.005587339401245117\n",
            "Prediction: 0.010273 seconds.\n",
            "process image 71\n",
            "Load Image: 0.007659 seconds.\n",
            "Inference time:  0.005505561828613281\n",
            "Prediction: 0.020171 seconds.\n",
            "process image 72\n",
            "Load Image: 0.012206 seconds.\n",
            "Inference time:  0.0054950714111328125\n",
            "Prediction: 0.008484 seconds.\n",
            "process image 73\n",
            "Load Image: 0.006198 seconds.\n",
            "Inference time:  0.005594730377197266\n",
            "Prediction: 0.010447 seconds.\n",
            "process image 74\n",
            "Load Image: 0.008861 seconds.\n",
            "Inference time:  0.0056629180908203125\n",
            "Prediction: 0.020107 seconds.\n",
            "process image 75\n",
            "Load Image: 0.009273 seconds.\n",
            "Inference time:  0.005518198013305664\n",
            "Prediction: 0.011106 seconds.\n",
            "process image 76\n",
            "Load Image: 0.012307 seconds.\n",
            "Inference time:  0.005787849426269531\n",
            "Prediction: 0.014997 seconds.\n",
            "process image 77\n",
            "Load Image: 0.011390 seconds.\n",
            "Inference time:  0.0056378841400146484\n",
            "Prediction: 0.017378 seconds.\n",
            "process image 78\n",
            "Load Image: 0.012706 seconds.\n",
            "Inference time:  0.00568699836730957\n",
            "Prediction: 0.009788 seconds.\n",
            "process image 79\n",
            "Load Image: 0.012681 seconds.\n",
            "Inference time:  0.005563497543334961\n",
            "Prediction: 0.008947 seconds.\n",
            "process image 80\n",
            "Load Image: 0.008761 seconds.\n",
            "Inference time:  0.005522966384887695\n",
            "Prediction: 0.020480 seconds.\n",
            "process image 81\n",
            "Load Image: 0.007888 seconds.\n",
            "Inference time:  0.005488157272338867\n",
            "Prediction: 0.022079 seconds.\n",
            "process image 82\n",
            "Load Image: 0.009518 seconds.\n",
            "Inference time:  0.0055048465728759766\n",
            "Prediction: 0.012023 seconds.\n",
            "process image 83\n",
            "Load Image: 0.007867 seconds.\n",
            "Inference time:  0.0054895877838134766\n",
            "Prediction: 0.015184 seconds.\n",
            "process image 84\n",
            "Load Image: 0.014687 seconds.\n",
            "Inference time:  0.005507469177246094\n",
            "Prediction: 0.012887 seconds.\n",
            "process image 85\n",
            "Load Image: 0.009990 seconds.\n",
            "Inference time:  0.005863189697265625\n",
            "Prediction: 0.009228 seconds.\n",
            "process image 86\n",
            "Load Image: 0.012968 seconds.\n",
            "Inference time:  0.0055353641510009766\n",
            "Prediction: 0.008718 seconds.\n",
            "process image 87\n",
            "Load Image: 0.010342 seconds.\n",
            "Inference time:  0.005429506301879883\n",
            "Prediction: 0.010005 seconds.\n",
            "process image 88\n",
            "Load Image: 0.012463 seconds.\n",
            "Inference time:  0.005455970764160156\n",
            "Prediction: 0.008492 seconds.\n",
            "process image 89\n",
            "Load Image: 0.012027 seconds.\n",
            "Inference time:  0.0053501129150390625\n",
            "Prediction: 0.010922 seconds.\n",
            "process image 90\n",
            "Load Image: 0.009887 seconds.\n",
            "Inference time:  0.005410909652709961\n",
            "Prediction: 0.008825 seconds.\n",
            "process image 91\n",
            "Load Image: 0.010885 seconds.\n",
            "Inference time:  0.005457162857055664\n",
            "Prediction: 0.015326 seconds.\n",
            "process image 92\n",
            "Load Image: 0.013090 seconds.\n",
            "Inference time:  0.0054585933685302734\n",
            "Prediction: 0.008828 seconds.\n",
            "process image 93\n",
            "Load Image: 0.006182 seconds.\n",
            "Inference time:  0.005478620529174805\n",
            "Prediction: 0.010460 seconds.\n",
            "process image 94\n",
            "Load Image: 0.009521 seconds.\n",
            "Inference time:  0.00545501708984375\n",
            "Prediction: 0.009561 seconds.\n",
            "process image 95\n",
            "Load Image: 0.014307 seconds.\n",
            "Inference time:  0.005511760711669922\n",
            "Prediction: 0.009993 seconds.\n",
            "process image 96\n",
            "Load Image: 0.008644 seconds.\n",
            "Inference time:  0.005620479583740234\n",
            "Prediction: 0.008809 seconds.\n",
            "process image 97\n",
            "Load Image: 0.006521 seconds.\n",
            "Inference time:  0.005504131317138672\n",
            "Prediction: 0.011497 seconds.\n",
            "process image 98\n",
            "Load Image: 0.014155 seconds.\n",
            "Inference time:  0.0055980682373046875\n",
            "Prediction: 0.014478 seconds.\n",
            "process image 99\n",
            "Load Image: 0.009221 seconds.\n",
            "Inference time:  0.0056645870208740234\n",
            "Prediction: 0.017628 seconds.\n",
            "process image 100\n",
            "Load Image: 0.015313 seconds.\n",
            "Inference time:  0.0059053897857666016\n",
            "Prediction: 0.013660 seconds.\n",
            "process image 101\n",
            "Load Image: 0.015333 seconds.\n",
            "Inference time:  0.006344795227050781\n",
            "Prediction: 0.009671 seconds.\n",
            "process image 102\n",
            "Load Image: 0.019382 seconds.\n",
            "Inference time:  0.005825042724609375\n",
            "Prediction: 0.020910 seconds.\n",
            "process image 103\n",
            "Load Image: 0.007635 seconds.\n",
            "Inference time:  0.005738258361816406\n",
            "Prediction: 0.008931 seconds.\n",
            "process image 104\n",
            "Load Image: 0.009387 seconds.\n",
            "Inference time:  0.006105184555053711\n",
            "Prediction: 0.011163 seconds.\n",
            "process image 105\n",
            "Load Image: 0.010317 seconds.\n",
            "Inference time:  0.005541086196899414\n",
            "Prediction: 0.017181 seconds.\n",
            "process image 106\n",
            "Load Image: 0.017449 seconds.\n",
            "Inference time:  0.005680084228515625\n",
            "Prediction: 0.022858 seconds.\n",
            "process image 107\n",
            "Load Image: 0.010067 seconds.\n",
            "Inference time:  0.005636692047119141\n",
            "Prediction: 0.013284 seconds.\n",
            "process image 108\n",
            "Load Image: 0.008175 seconds.\n",
            "Inference time:  0.005581855773925781\n",
            "Prediction: 0.013520 seconds.\n",
            "process image 109\n",
            "Load Image: 0.012822 seconds.\n",
            "Inference time:  0.006629467010498047\n",
            "Prediction: 0.025965 seconds.\n",
            "process image 110\n",
            "Load Image: 0.011739 seconds.\n",
            "Inference time:  0.0056879520416259766\n",
            "Prediction: 0.012069 seconds.\n",
            "process image 111\n",
            "Load Image: 0.010424 seconds.\n",
            "Inference time:  0.005532264709472656\n",
            "Prediction: 0.018092 seconds.\n",
            "process image 112\n",
            "Load Image: 0.011016 seconds.\n",
            "Inference time:  0.005518198013305664\n",
            "Prediction: 0.014100 seconds.\n",
            "process image 113\n",
            "Load Image: 0.009897 seconds.\n",
            "Inference time:  0.005626678466796875\n",
            "Prediction: 0.008441 seconds.\n",
            "process image 114\n",
            "Load Image: 0.004057 seconds.\n",
            "Inference time:  0.005621194839477539\n",
            "Prediction: 0.012759 seconds.\n",
            "process image 115\n",
            "Load Image: 0.026023 seconds.\n",
            "Inference time:  0.0058782100677490234\n",
            "Prediction: 0.018692 seconds.\n",
            "process image 116\n",
            "Load Image: 0.015449 seconds.\n",
            "Inference time:  0.005523681640625\n",
            "Prediction: 0.008708 seconds.\n",
            "process image 117\n",
            "Load Image: 0.013683 seconds.\n",
            "Inference time:  0.005530357360839844\n",
            "Prediction: 0.010473 seconds.\n",
            "process image 118\n",
            "Load Image: 0.013325 seconds.\n",
            "Inference time:  0.005500316619873047\n",
            "Prediction: 0.012305 seconds.\n",
            "process image 119\n",
            "Load Image: 0.005954 seconds.\n",
            "Inference time:  0.005466938018798828\n",
            "Prediction: 0.008344 seconds.\n",
            "process image 120\n",
            "Load Image: 0.023803 seconds.\n",
            "Inference time:  0.0056192874908447266\n",
            "Prediction: 0.025286 seconds.\n",
            "process image 121\n",
            "Load Image: 0.025271 seconds.\n",
            "Inference time:  0.005753040313720703\n",
            "Prediction: 0.016384 seconds.\n",
            "process image 122\n",
            "Load Image: 0.014363 seconds.\n",
            "Inference time:  0.005610227584838867\n",
            "Prediction: 0.011684 seconds.\n",
            "\n",
            "\n",
            "Average Precision Per-class:\n",
            "Handgun: 0.8292257251879146\n",
            "Shotgun: 0.5969613222703153\n",
            "\n",
            "Average Precision Across All Classes:0.7130935237291149\n"
          ]
        }
      ],
      "source": [
        "!python eval_ssd.py --dataset_type open_images --net mb1-ssd --dataset ../data/open_images --trained_model models/mb1-ssd-Epoch-99-Loss-2.798509557247162.pth --label_file models/open-images-model-labels.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJlLfE8sQQcN",
        "outputId": "fbef9fad-6839-460d-a7cc-1e9dcc376859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/pytorch-ssd/eval_ssd.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  all_gt_boxes[class_index][image_id] = torch.tensor(all_gt_boxes[class_index][image_id])\n",
            "It took 0.04904580116271973 seconds to load the model.\n",
            "process image 0\n",
            "Load Image: 0.019377 seconds.\n",
            "Inference time:  0.5990192890167236\n",
            "Prediction: 0.621946 seconds.\n",
            "process image 1\n",
            "Load Image: 0.009439 seconds.\n",
            "Inference time:  0.0062274932861328125\n",
            "Prediction: 0.025332 seconds.\n",
            "process image 2\n",
            "Load Image: 0.007796 seconds.\n",
            "Inference time:  0.005885124206542969\n",
            "Prediction: 0.026655 seconds.\n",
            "process image 3\n",
            "Load Image: 0.010315 seconds.\n",
            "Inference time:  0.006087541580200195\n",
            "Prediction: 0.030978 seconds.\n",
            "process image 4\n",
            "Load Image: 0.014173 seconds.\n",
            "Inference time:  0.006224393844604492\n",
            "Prediction: 0.025230 seconds.\n",
            "process image 5\n",
            "Load Image: 0.008260 seconds.\n",
            "Inference time:  0.005950450897216797\n",
            "Prediction: 0.026568 seconds.\n",
            "process image 6\n",
            "Load Image: 0.007965 seconds.\n",
            "Inference time:  0.005731105804443359\n",
            "Prediction: 0.023701 seconds.\n",
            "process image 7\n",
            "Load Image: 0.010275 seconds.\n",
            "Inference time:  0.005829334259033203\n",
            "Prediction: 0.024758 seconds.\n",
            "process image 8\n",
            "Load Image: 0.012490 seconds.\n",
            "Inference time:  0.007245063781738281\n",
            "Prediction: 0.040067 seconds.\n",
            "process image 9\n",
            "Load Image: 0.014065 seconds.\n",
            "Inference time:  0.007149696350097656\n",
            "Prediction: 0.037764 seconds.\n",
            "process image 10\n",
            "Load Image: 0.014911 seconds.\n",
            "Inference time:  0.007551431655883789\n",
            "Prediction: 0.029785 seconds.\n",
            "process image 11\n",
            "Load Image: 0.004659 seconds.\n",
            "Inference time:  0.0057027339935302734\n",
            "Prediction: 0.035077 seconds.\n",
            "process image 12\n",
            "Load Image: 0.009014 seconds.\n",
            "Inference time:  0.007334470748901367\n",
            "Prediction: 0.035892 seconds.\n",
            "process image 13\n",
            "Load Image: 0.008675 seconds.\n",
            "Inference time:  0.00792384147644043\n",
            "Prediction: 0.045032 seconds.\n",
            "process image 14\n",
            "Load Image: 0.015594 seconds.\n",
            "Inference time:  0.007376432418823242\n",
            "Prediction: 0.035907 seconds.\n",
            "process image 15\n",
            "Load Image: 0.010667 seconds.\n",
            "Inference time:  0.0077741146087646484\n",
            "Prediction: 0.032754 seconds.\n",
            "process image 16\n",
            "Load Image: 0.013415 seconds.\n",
            "Inference time:  0.007284879684448242\n",
            "Prediction: 0.038746 seconds.\n",
            "process image 17\n",
            "Load Image: 0.014313 seconds.\n",
            "Inference time:  0.0071446895599365234\n",
            "Prediction: 0.039330 seconds.\n",
            "process image 18\n",
            "Load Image: 0.014885 seconds.\n",
            "Inference time:  0.007699489593505859\n",
            "Prediction: 0.036072 seconds.\n",
            "process image 19\n",
            "Load Image: 0.009404 seconds.\n",
            "Inference time:  0.0073735713958740234\n",
            "Prediction: 0.042000 seconds.\n",
            "process image 20\n",
            "Load Image: 0.010504 seconds.\n",
            "Inference time:  0.007170677185058594\n",
            "Prediction: 0.037564 seconds.\n",
            "process image 21\n",
            "Load Image: 0.006900 seconds.\n",
            "Inference time:  0.006098270416259766\n",
            "Prediction: 0.024993 seconds.\n",
            "process image 22\n",
            "Load Image: 0.010479 seconds.\n",
            "Inference time:  0.005893230438232422\n",
            "Prediction: 0.028460 seconds.\n",
            "process image 23\n",
            "Load Image: 0.008644 seconds.\n",
            "Inference time:  0.005902528762817383\n",
            "Prediction: 0.023287 seconds.\n",
            "process image 24\n",
            "Load Image: 0.023308 seconds.\n",
            "Inference time:  0.005982398986816406\n",
            "Prediction: 0.022315 seconds.\n",
            "process image 25\n",
            "Load Image: 0.016642 seconds.\n",
            "Inference time:  0.005913496017456055\n",
            "Prediction: 0.022724 seconds.\n",
            "process image 26\n",
            "Load Image: 0.010437 seconds.\n",
            "Inference time:  0.006234169006347656\n",
            "Prediction: 0.027879 seconds.\n",
            "process image 27\n",
            "Load Image: 0.009892 seconds.\n",
            "Inference time:  0.006471157073974609\n",
            "Prediction: 0.029521 seconds.\n",
            "process image 28\n",
            "Load Image: 0.012768 seconds.\n",
            "Inference time:  0.005925178527832031\n",
            "Prediction: 0.025414 seconds.\n",
            "process image 29\n",
            "Load Image: 0.006143 seconds.\n",
            "Inference time:  0.00569605827331543\n",
            "Prediction: 0.033775 seconds.\n",
            "process image 30\n",
            "Load Image: 0.020757 seconds.\n",
            "Inference time:  0.00588536262512207\n",
            "Prediction: 0.021018 seconds.\n",
            "process image 31\n",
            "Load Image: 0.006727 seconds.\n",
            "Inference time:  0.005778074264526367\n",
            "Prediction: 0.027662 seconds.\n",
            "process image 32\n",
            "Load Image: 0.010537 seconds.\n",
            "Inference time:  0.005807161331176758\n",
            "Prediction: 0.021615 seconds.\n",
            "process image 33\n",
            "Load Image: 0.014222 seconds.\n",
            "Inference time:  0.005898952484130859\n",
            "Prediction: 0.026574 seconds.\n",
            "process image 34\n",
            "Load Image: 0.010050 seconds.\n",
            "Inference time:  0.005815267562866211\n",
            "Prediction: 0.023291 seconds.\n",
            "process image 35\n",
            "Load Image: 0.007935 seconds.\n",
            "Inference time:  0.005919456481933594\n",
            "Prediction: 0.029809 seconds.\n",
            "process image 36\n",
            "Load Image: 0.017869 seconds.\n",
            "Inference time:  0.005902767181396484\n",
            "Prediction: 0.022938 seconds.\n",
            "process image 37\n",
            "Load Image: 0.008725 seconds.\n",
            "Inference time:  0.006048917770385742\n",
            "Prediction: 0.024144 seconds.\n",
            "process image 38\n",
            "Load Image: 0.013427 seconds.\n",
            "Inference time:  0.005742073059082031\n",
            "Prediction: 0.028528 seconds.\n",
            "process image 39\n",
            "Load Image: 0.010731 seconds.\n",
            "Inference time:  0.005848884582519531\n",
            "Prediction: 0.022177 seconds.\n",
            "process image 40\n",
            "Load Image: 0.009657 seconds.\n",
            "Inference time:  0.005768299102783203\n",
            "Prediction: 0.024675 seconds.\n",
            "process image 41\n",
            "Load Image: 0.012420 seconds.\n",
            "Inference time:  0.005809783935546875\n",
            "Prediction: 0.027980 seconds.\n",
            "process image 42\n",
            "Load Image: 0.008101 seconds.\n",
            "Inference time:  0.00580906867980957\n",
            "Prediction: 0.026456 seconds.\n",
            "process image 43\n",
            "Load Image: 0.016353 seconds.\n",
            "Inference time:  0.005858182907104492\n",
            "Prediction: 0.021670 seconds.\n",
            "process image 44\n",
            "Load Image: 0.021877 seconds.\n",
            "Inference time:  0.005908966064453125\n",
            "Prediction: 0.025530 seconds.\n",
            "process image 45\n",
            "Load Image: 0.010610 seconds.\n",
            "Inference time:  0.005780935287475586\n",
            "Prediction: 0.022381 seconds.\n",
            "process image 46\n",
            "Load Image: 0.003950 seconds.\n",
            "Inference time:  0.0058248043060302734\n",
            "Prediction: 0.029196 seconds.\n",
            "process image 47\n",
            "Load Image: 0.024825 seconds.\n",
            "Inference time:  0.005957126617431641\n",
            "Prediction: 0.030362 seconds.\n",
            "process image 48\n",
            "Load Image: 0.008658 seconds.\n",
            "Inference time:  0.005742788314819336\n",
            "Prediction: 0.022561 seconds.\n",
            "process image 49\n",
            "Load Image: 0.013284 seconds.\n",
            "Inference time:  0.0064542293548583984\n",
            "Prediction: 0.026086 seconds.\n",
            "process image 50\n",
            "Load Image: 0.013306 seconds.\n",
            "Inference time:  0.005826234817504883\n",
            "Prediction: 0.029164 seconds.\n",
            "process image 51\n",
            "Load Image: 0.007806 seconds.\n",
            "Inference time:  0.005881786346435547\n",
            "Prediction: 0.027853 seconds.\n",
            "process image 52\n",
            "Load Image: 0.005406 seconds.\n",
            "Inference time:  0.006157636642456055\n",
            "Prediction: 0.031538 seconds.\n",
            "process image 53\n",
            "Load Image: 0.014699 seconds.\n",
            "Inference time:  0.005924224853515625\n",
            "Prediction: 0.028661 seconds.\n",
            "process image 54\n",
            "Load Image: 0.009301 seconds.\n",
            "Inference time:  0.007605552673339844\n",
            "Prediction: 0.028813 seconds.\n",
            "process image 55\n",
            "Load Image: 0.009636 seconds.\n",
            "Inference time:  0.005845785140991211\n",
            "Prediction: 0.021136 seconds.\n",
            "process image 56\n",
            "Load Image: 0.010045 seconds.\n",
            "Inference time:  0.005735635757446289\n",
            "Prediction: 0.028338 seconds.\n",
            "process image 57\n",
            "Load Image: 0.022531 seconds.\n",
            "Inference time:  0.005843400955200195\n",
            "Prediction: 0.024904 seconds.\n",
            "process image 58\n",
            "Load Image: 0.013688 seconds.\n",
            "Inference time:  0.0057659149169921875\n",
            "Prediction: 0.030287 seconds.\n",
            "process image 59\n",
            "Load Image: 0.007332 seconds.\n",
            "Inference time:  0.006001710891723633\n",
            "Prediction: 0.028890 seconds.\n",
            "process image 60\n",
            "Load Image: 0.010551 seconds.\n",
            "Inference time:  0.005917072296142578\n",
            "Prediction: 0.028988 seconds.\n",
            "process image 61\n",
            "Load Image: 0.011680 seconds.\n",
            "Inference time:  0.005860567092895508\n",
            "Prediction: 0.022056 seconds.\n",
            "process image 62\n",
            "Load Image: 0.016072 seconds.\n",
            "Inference time:  0.00601959228515625\n",
            "Prediction: 0.023376 seconds.\n",
            "process image 63\n",
            "Load Image: 0.019540 seconds.\n",
            "Inference time:  0.006315469741821289\n",
            "Prediction: 0.030522 seconds.\n",
            "process image 64\n",
            "Load Image: 0.008838 seconds.\n",
            "Inference time:  0.005881071090698242\n",
            "Prediction: 0.023298 seconds.\n",
            "process image 65\n",
            "Load Image: 0.010942 seconds.\n",
            "Inference time:  0.005777120590209961\n",
            "Prediction: 0.022953 seconds.\n",
            "process image 66\n",
            "Load Image: 0.011580 seconds.\n",
            "Inference time:  0.005689382553100586\n",
            "Prediction: 0.024735 seconds.\n",
            "process image 67\n",
            "Load Image: 0.013867 seconds.\n",
            "Inference time:  0.005875825881958008\n",
            "Prediction: 0.025014 seconds.\n",
            "process image 68\n",
            "Load Image: 0.012465 seconds.\n",
            "Inference time:  0.005635499954223633\n",
            "Prediction: 0.023658 seconds.\n",
            "process image 69\n",
            "Load Image: 0.007296 seconds.\n",
            "Inference time:  0.005595207214355469\n",
            "Prediction: 0.022855 seconds.\n",
            "process image 70\n",
            "Load Image: 0.003937 seconds.\n",
            "Inference time:  0.00565338134765625\n",
            "Prediction: 0.026317 seconds.\n",
            "process image 71\n",
            "Load Image: 0.007695 seconds.\n",
            "Inference time:  0.005610466003417969\n",
            "Prediction: 0.022215 seconds.\n",
            "process image 72\n",
            "Load Image: 0.012104 seconds.\n",
            "Inference time:  0.00565791130065918\n",
            "Prediction: 0.039521 seconds.\n",
            "process image 73\n",
            "Load Image: 0.006134 seconds.\n",
            "Inference time:  0.0067899227142333984\n",
            "Prediction: 0.025480 seconds.\n",
            "process image 74\n",
            "Load Image: 0.008979 seconds.\n",
            "Inference time:  0.005704641342163086\n",
            "Prediction: 0.023925 seconds.\n",
            "process image 75\n",
            "Load Image: 0.009234 seconds.\n",
            "Inference time:  0.005537986755371094\n",
            "Prediction: 0.029145 seconds.\n",
            "process image 76\n",
            "Load Image: 0.012897 seconds.\n",
            "Inference time:  0.005707263946533203\n",
            "Prediction: 0.022834 seconds.\n",
            "process image 77\n",
            "Load Image: 0.011217 seconds.\n",
            "Inference time:  0.005608320236206055\n",
            "Prediction: 0.027416 seconds.\n",
            "process image 78\n",
            "Load Image: 0.012358 seconds.\n",
            "Inference time:  0.00570225715637207\n",
            "Prediction: 0.026894 seconds.\n",
            "process image 79\n",
            "Load Image: 0.012755 seconds.\n",
            "Inference time:  0.005771636962890625\n",
            "Prediction: 0.025057 seconds.\n",
            "process image 80\n",
            "Load Image: 0.008875 seconds.\n",
            "Inference time:  0.005779266357421875\n",
            "Prediction: 0.026735 seconds.\n",
            "process image 81\n",
            "Load Image: 0.008126 seconds.\n",
            "Inference time:  0.006161689758300781\n",
            "Prediction: 0.025680 seconds.\n",
            "process image 82\n",
            "Load Image: 0.009743 seconds.\n",
            "Inference time:  0.0058116912841796875\n",
            "Prediction: 0.025651 seconds.\n",
            "process image 83\n",
            "Load Image: 0.007890 seconds.\n",
            "Inference time:  0.005655527114868164\n",
            "Prediction: 0.019990 seconds.\n",
            "process image 84\n",
            "Load Image: 0.014658 seconds.\n",
            "Inference time:  0.005692005157470703\n",
            "Prediction: 0.021536 seconds.\n",
            "process image 85\n",
            "Load Image: 0.010326 seconds.\n",
            "Inference time:  0.0063474178314208984\n",
            "Prediction: 0.028338 seconds.\n",
            "process image 86\n",
            "Load Image: 0.013291 seconds.\n",
            "Inference time:  0.005906105041503906\n",
            "Prediction: 0.027794 seconds.\n",
            "process image 87\n",
            "Load Image: 0.010395 seconds.\n",
            "Inference time:  0.005595684051513672\n",
            "Prediction: 0.021500 seconds.\n",
            "process image 88\n",
            "Load Image: 0.012444 seconds.\n",
            "Inference time:  0.005708217620849609\n",
            "Prediction: 0.027385 seconds.\n",
            "process image 89\n",
            "Load Image: 0.012157 seconds.\n",
            "Inference time:  0.005656242370605469\n",
            "Prediction: 0.024570 seconds.\n",
            "process image 90\n",
            "Load Image: 0.009896 seconds.\n",
            "Inference time:  0.0059893131256103516\n",
            "Prediction: 0.025962 seconds.\n",
            "process image 91\n",
            "Load Image: 0.011056 seconds.\n",
            "Inference time:  0.005672931671142578\n",
            "Prediction: 0.025873 seconds.\n",
            "process image 92\n",
            "Load Image: 0.013004 seconds.\n",
            "Inference time:  0.005593538284301758\n",
            "Prediction: 0.024816 seconds.\n",
            "process image 93\n",
            "Load Image: 0.006206 seconds.\n",
            "Inference time:  0.0055675506591796875\n",
            "Prediction: 0.026633 seconds.\n",
            "process image 94\n",
            "Load Image: 0.009541 seconds.\n",
            "Inference time:  0.005568027496337891\n",
            "Prediction: 0.027487 seconds.\n",
            "process image 95\n",
            "Load Image: 0.014815 seconds.\n",
            "Inference time:  0.005580902099609375\n",
            "Prediction: 0.031598 seconds.\n",
            "process image 96\n",
            "Load Image: 0.007976 seconds.\n",
            "Inference time:  0.005517721176147461\n",
            "Prediction: 0.028512 seconds.\n",
            "process image 97\n",
            "Load Image: 0.006556 seconds.\n",
            "Inference time:  0.005627870559692383\n",
            "Prediction: 0.021495 seconds.\n",
            "process image 98\n",
            "Load Image: 0.014592 seconds.\n",
            "Inference time:  0.005629539489746094\n",
            "Prediction: 0.026728 seconds.\n",
            "process image 99\n",
            "Load Image: 0.009101 seconds.\n",
            "Inference time:  0.005730867385864258\n",
            "Prediction: 0.026719 seconds.\n",
            "process image 100\n",
            "Load Image: 0.019877 seconds.\n",
            "Inference time:  0.005972385406494141\n",
            "Prediction: 0.023783 seconds.\n",
            "process image 101\n",
            "Load Image: 0.013811 seconds.\n",
            "Inference time:  0.005509138107299805\n",
            "Prediction: 0.031446 seconds.\n",
            "process image 102\n",
            "Load Image: 0.019178 seconds.\n",
            "Inference time:  0.006930828094482422\n",
            "Prediction: 0.040697 seconds.\n",
            "process image 103\n",
            "Load Image: 0.007453 seconds.\n",
            "Inference time:  0.005569934844970703\n",
            "Prediction: 0.023928 seconds.\n",
            "process image 104\n",
            "Load Image: 0.009274 seconds.\n",
            "Inference time:  0.0054585933685302734\n",
            "Prediction: 0.022176 seconds.\n",
            "process image 105\n",
            "Load Image: 0.010231 seconds.\n",
            "Inference time:  0.005590200424194336\n",
            "Prediction: 0.026443 seconds.\n",
            "process image 106\n",
            "Load Image: 0.017536 seconds.\n",
            "Inference time:  0.005802631378173828\n",
            "Prediction: 0.020873 seconds.\n",
            "process image 107\n",
            "Load Image: 0.009920 seconds.\n",
            "Inference time:  0.005803346633911133\n",
            "Prediction: 0.021821 seconds.\n",
            "process image 108\n",
            "Load Image: 0.008962 seconds.\n",
            "Inference time:  0.0061719417572021484\n",
            "Prediction: 0.023616 seconds.\n",
            "process image 109\n",
            "Load Image: 0.012820 seconds.\n",
            "Inference time:  0.005721569061279297\n",
            "Prediction: 0.027035 seconds.\n",
            "process image 110\n",
            "Load Image: 0.011672 seconds.\n",
            "Inference time:  0.005581855773925781\n",
            "Prediction: 0.026194 seconds.\n",
            "process image 111\n",
            "Load Image: 0.010428 seconds.\n",
            "Inference time:  0.005672454833984375\n",
            "Prediction: 0.027993 seconds.\n",
            "process image 112\n",
            "Load Image: 0.010935 seconds.\n",
            "Inference time:  0.005661725997924805\n",
            "Prediction: 0.021683 seconds.\n",
            "process image 113\n",
            "Load Image: 0.009964 seconds.\n",
            "Inference time:  0.005612850189208984\n",
            "Prediction: 0.023841 seconds.\n",
            "process image 114\n",
            "Load Image: 0.004121 seconds.\n",
            "Inference time:  0.00558781623840332\n",
            "Prediction: 0.025048 seconds.\n",
            "process image 115\n",
            "Load Image: 0.025396 seconds.\n",
            "Inference time:  0.005629062652587891\n",
            "Prediction: 0.027009 seconds.\n",
            "process image 116\n",
            "Load Image: 0.015516 seconds.\n",
            "Inference time:  0.006060123443603516\n",
            "Prediction: 0.032388 seconds.\n",
            "process image 117\n",
            "Load Image: 0.013853 seconds.\n",
            "Inference time:  0.006007671356201172\n",
            "Prediction: 0.027710 seconds.\n",
            "process image 118\n",
            "Load Image: 0.013345 seconds.\n",
            "Inference time:  0.00572967529296875\n",
            "Prediction: 0.024964 seconds.\n",
            "process image 119\n",
            "Load Image: 0.006085 seconds.\n",
            "Inference time:  0.005755186080932617\n",
            "Prediction: 0.032252 seconds.\n",
            "process image 120\n",
            "Load Image: 0.023952 seconds.\n",
            "Inference time:  0.005688190460205078\n",
            "Prediction: 0.026186 seconds.\n",
            "process image 121\n",
            "Load Image: 0.025103 seconds.\n",
            "Inference time:  0.005669593811035156\n",
            "Prediction: 0.024213 seconds.\n",
            "process image 122\n",
            "Load Image: 0.014386 seconds.\n",
            "Inference time:  0.005750179290771484\n",
            "Prediction: 0.027771 seconds.\n",
            "\n",
            "\n",
            "Average Precision Per-class:\n",
            "Handgun: 0.7103875229654111\n",
            "Shotgun: 0.28310441747307086\n",
            "\n",
            "Average Precision Across All Classes:0.49674597021924094\n"
          ]
        }
      ],
      "source": [
        "!python eval_ssd.py --dataset_type open_images --net mb1-ssd --dataset ../data/open_images --trained_model models/mb1-ssd-Epoch-0-Loss-3.7128826236724852.pth --label_file models/open-images-model-labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2YJk8n2NY05"
      },
      "source": [
        "### 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAnrkmMGaRJb",
        "outputId": "ee95f157-5c58-4a76-d399-c38997c35cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.0-cp310-cp310-macosx_10_15_universal2.whl (16.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-macosx_11_0_universal2.whl (14.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting netron\n",
            "  Downloading netron-7.6.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting protobuf>=3.20.2\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-macosx_10_9_universal2.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.0/404.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages (from onnx) (1.24.3)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages (from onnxruntime) (23.0)\n",
            "Collecting flatbuffers\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: sympy in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages (from onnxruntime) (1.11.1)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->onnxruntime) (1.2.1)\n",
            "Installing collected packages: netron, flatbuffers, protobuf, humanfriendly, onnx, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 flatbuffers-24.3.25 humanfriendly-10.0 netron-7.6.3 onnx-1.16.0 onnxruntime-1.17.3 protobuf-5.26.1\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx onnxruntime netron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/zhongyihao/Downloads/DS301 Advance ML/deep-learning/code/pytorch-ssd\n"
          ]
        }
      ],
      "source": [
        "%cd pytorch-ssd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctBOtULqaS6e",
        "outputId": "e8fd5cf9-f476-473b-c69c-aa07058f1456"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages/torch/onnx/utils.py:2029: UserWarning: Provided key output for dynamic axes is not a valid input/output name\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "File saved: models/mb1-ssd-10.onnx.\n"
          ]
        }
      ],
      "source": [
        "# Some standard imports\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.onnx\n",
        "\n",
        "from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd\n",
        "import torch.onnx\n",
        "import onnx\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "# Parameters\n",
        "\n",
        "model_path = 'models/mb1-ssd-Epoch-99-Loss-2.798509557247162.pth'\n",
        "label_path = 'models/open-images-model-labels.txt'\n",
        "\n",
        "class_names = [name.strip() for name in open(label_path).readlines()]\n",
        "\n",
        "\n",
        "net = create_mobilenetv1_ssd(len(class_names), is_test=True)\n",
        "net.load(model_path)\n",
        "net.eval()\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "model_onnx_path = f\"models/mb1-ssd-10.onnx\"\n",
        "\n",
        "x = torch.randn(1, 3, 300, 300, requires_grad=True).to(device)\n",
        "\n",
        "torch.onnx.export(net,\n",
        "                  x,\n",
        "                  model_onnx_path,\n",
        "                  verbose=False,\n",
        "                  export_params=True,\n",
        "                  output_names=['scores', 'boxes'],\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                                'output' : {0 : 'batch_size'}})\n",
        "\n",
        "# Load the ONNX model and print a message\n",
        "model = onnx.load(model_onnx_path)\n",
        "print(f\"File saved: {model_onnx_path}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DijaeTkONY05"
      },
      "source": [
        "### 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmHZ0rB8mOMJ",
        "outputId": "1e4c3f7a-5aaa-4f0e-eb89-3dd311009a7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Check\n"
          ]
        }
      ],
      "source": [
        "\n",
        "onnx_model = onnx.load(\"models/mb1-ssd-10.onnx\")\n",
        "\n",
        "# Check\n",
        "onnx.checker.check_model(onnx_model)\n",
        "print(\"Check\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ujf8NqyNY05"
      },
      "source": [
        "### 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppOR6EW9meY3",
        "outputId": "bfe58dc8-bb96-47b6-ca3f-2ed10cd91ab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "graph torch_jit (\n",
            "  %input[FLOAT, batch_sizex3x300x300]\n",
            ") initializers (\n",
            "  %extras.0.0.weight[FLOAT, 256x1024x1x1]\n",
            "  %extras.0.0.bias[FLOAT, 256]\n",
            "  %extras.0.2.weight[FLOAT, 512x256x3x3]\n",
            "  %extras.0.2.bias[FLOAT, 512]\n",
            "  %extras.1.0.weight[FLOAT, 128x512x1x1]\n",
            "  %extras.1.0.bias[FLOAT, 128]\n",
            "  %extras.1.2.weight[FLOAT, 256x128x3x3]\n",
            "  %extras.1.2.bias[FLOAT, 256]\n",
            "  %extras.2.0.weight[FLOAT, 128x256x1x1]\n",
            "  %extras.2.0.bias[FLOAT, 128]\n",
            "  %extras.2.2.weight[FLOAT, 256x128x3x3]\n",
            "  %extras.2.2.bias[FLOAT, 256]\n",
            "  %extras.3.0.weight[FLOAT, 128x256x1x1]\n",
            "  %extras.3.0.bias[FLOAT, 128]\n",
            "  %extras.3.2.weight[FLOAT, 256x128x3x3]\n",
            "  %extras.3.2.bias[FLOAT, 256]\n",
            "  %classification_headers.0.weight[FLOAT, 18x512x3x3]\n",
            "  %classification_headers.0.bias[FLOAT, 18]\n",
            "  %classification_headers.1.weight[FLOAT, 18x1024x3x3]\n",
            "  %classification_headers.1.bias[FLOAT, 18]\n",
            "  %classification_headers.2.weight[FLOAT, 18x512x3x3]\n",
            "  %classification_headers.2.bias[FLOAT, 18]\n",
            "  %classification_headers.3.weight[FLOAT, 18x256x3x3]\n",
            "  %classification_headers.3.bias[FLOAT, 18]\n",
            "  %classification_headers.4.weight[FLOAT, 18x256x3x3]\n",
            "  %classification_headers.4.bias[FLOAT, 18]\n",
            "  %classification_headers.5.weight[FLOAT, 18x256x3x3]\n",
            "  %classification_headers.5.bias[FLOAT, 18]\n",
            "  %regression_headers.0.weight[FLOAT, 24x512x3x3]\n",
            "  %regression_headers.0.bias[FLOAT, 24]\n",
            "  %regression_headers.1.weight[FLOAT, 24x1024x3x3]\n",
            "  %regression_headers.1.bias[FLOAT, 24]\n",
            "  %regression_headers.2.weight[FLOAT, 24x512x3x3]\n",
            "  %regression_headers.2.bias[FLOAT, 24]\n",
            "  %regression_headers.3.weight[FLOAT, 24x256x3x3]\n",
            "  %regression_headers.3.bias[FLOAT, 24]\n",
            "  %regression_headers.4.weight[FLOAT, 24x256x3x3]\n",
            "  %regression_headers.4.bias[FLOAT, 24]\n",
            "  %regression_headers.5.weight[FLOAT, 24x256x3x3]\n",
            "  %regression_headers.5.bias[FLOAT, 24]\n",
            "  %onnx::Conv_500[FLOAT, 32x3x3x3]\n",
            "  %onnx::Conv_501[FLOAT, 32]\n",
            "  %onnx::Conv_503[FLOAT, 32x1x3x3]\n",
            "  %onnx::Conv_504[FLOAT, 32]\n",
            "  %onnx::Conv_506[FLOAT, 64x32x1x1]\n",
            "  %onnx::Conv_507[FLOAT, 64]\n",
            "  %onnx::Conv_509[FLOAT, 64x1x3x3]\n",
            "  %onnx::Conv_510[FLOAT, 64]\n",
            "  %onnx::Conv_512[FLOAT, 128x64x1x1]\n",
            "  %onnx::Conv_513[FLOAT, 128]\n",
            "  %onnx::Conv_515[FLOAT, 128x1x3x3]\n",
            "  %onnx::Conv_516[FLOAT, 128]\n",
            "  %onnx::Conv_518[FLOAT, 128x128x1x1]\n",
            "  %onnx::Conv_519[FLOAT, 128]\n",
            "  %onnx::Conv_521[FLOAT, 128x1x3x3]\n",
            "  %onnx::Conv_522[FLOAT, 128]\n",
            "  %onnx::Conv_524[FLOAT, 256x128x1x1]\n",
            "  %onnx::Conv_525[FLOAT, 256]\n",
            "  %onnx::Conv_527[FLOAT, 256x1x3x3]\n",
            "  %onnx::Conv_528[FLOAT, 256]\n",
            "  %onnx::Conv_530[FLOAT, 256x256x1x1]\n",
            "  %onnx::Conv_531[FLOAT, 256]\n",
            "  %onnx::Conv_533[FLOAT, 256x1x3x3]\n",
            "  %onnx::Conv_534[FLOAT, 256]\n",
            "  %onnx::Conv_536[FLOAT, 512x256x1x1]\n",
            "  %onnx::Conv_537[FLOAT, 512]\n",
            "  %onnx::Conv_539[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_540[FLOAT, 512]\n",
            "  %onnx::Conv_542[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_543[FLOAT, 512]\n",
            "  %onnx::Conv_545[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_546[FLOAT, 512]\n",
            "  %onnx::Conv_548[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_549[FLOAT, 512]\n",
            "  %onnx::Conv_551[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_552[FLOAT, 512]\n",
            "  %onnx::Conv_554[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_555[FLOAT, 512]\n",
            "  %onnx::Conv_557[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_558[FLOAT, 512]\n",
            "  %onnx::Conv_560[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_561[FLOAT, 512]\n",
            "  %onnx::Conv_563[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_564[FLOAT, 512]\n",
            "  %onnx::Conv_566[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_567[FLOAT, 512]\n",
            "  %onnx::Conv_569[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_570[FLOAT, 512]\n",
            "  %onnx::Conv_572[FLOAT, 1024x512x1x1]\n",
            "  %onnx::Conv_573[FLOAT, 1024]\n",
            "  %onnx::Conv_575[FLOAT, 1024x1x3x3]\n",
            "  %onnx::Conv_576[FLOAT, 1024]\n",
            "  %onnx::Conv_578[FLOAT, 1024x1024x1x1]\n",
            "  %onnx::Conv_579[FLOAT, 1024]\n",
            ") {\n",
            "  %/base_net.0/base_net.0.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%input, %onnx::Conv_500, %onnx::Conv_501)\n",
            "  %/base_net.0/base_net.0.2/Relu_output_0 = Relu(%/base_net.0/base_net.0.0/Conv_output_0)\n",
            "  %/base_net.1/base_net.1.0/Conv_output_0 = Conv[dilations = [1, 1], group = 32, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.0/base_net.0.2/Relu_output_0, %onnx::Conv_503, %onnx::Conv_504)\n",
            "  %/base_net.1/base_net.1.2/Relu_output_0 = Relu(%/base_net.1/base_net.1.0/Conv_output_0)\n",
            "  %/base_net.1/base_net.1.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.1/base_net.1.2/Relu_output_0, %onnx::Conv_506, %onnx::Conv_507)\n",
            "  %/base_net.1/base_net.1.5/Relu_output_0 = Relu(%/base_net.1/base_net.1.3/Conv_output_0)\n",
            "  %/base_net.2/base_net.2.0/Conv_output_0 = Conv[dilations = [1, 1], group = 64, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.1/base_net.1.5/Relu_output_0, %onnx::Conv_509, %onnx::Conv_510)\n",
            "  %/base_net.2/base_net.2.2/Relu_output_0 = Relu(%/base_net.2/base_net.2.0/Conv_output_0)\n",
            "  %/base_net.2/base_net.2.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.2/base_net.2.2/Relu_output_0, %onnx::Conv_512, %onnx::Conv_513)\n",
            "  %/base_net.2/base_net.2.5/Relu_output_0 = Relu(%/base_net.2/base_net.2.3/Conv_output_0)\n",
            "  %/base_net.3/base_net.3.0/Conv_output_0 = Conv[dilations = [1, 1], group = 128, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.2/base_net.2.5/Relu_output_0, %onnx::Conv_515, %onnx::Conv_516)\n",
            "  %/base_net.3/base_net.3.2/Relu_output_0 = Relu(%/base_net.3/base_net.3.0/Conv_output_0)\n",
            "  %/base_net.3/base_net.3.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.3/base_net.3.2/Relu_output_0, %onnx::Conv_518, %onnx::Conv_519)\n",
            "  %/base_net.3/base_net.3.5/Relu_output_0 = Relu(%/base_net.3/base_net.3.3/Conv_output_0)\n",
            "  %/base_net.4/base_net.4.0/Conv_output_0 = Conv[dilations = [1, 1], group = 128, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.3/base_net.3.5/Relu_output_0, %onnx::Conv_521, %onnx::Conv_522)\n",
            "  %/base_net.4/base_net.4.2/Relu_output_0 = Relu(%/base_net.4/base_net.4.0/Conv_output_0)\n",
            "  %/base_net.4/base_net.4.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.4/base_net.4.2/Relu_output_0, %onnx::Conv_524, %onnx::Conv_525)\n",
            "  %/base_net.4/base_net.4.5/Relu_output_0 = Relu(%/base_net.4/base_net.4.3/Conv_output_0)\n",
            "  %/base_net.5/base_net.5.0/Conv_output_0 = Conv[dilations = [1, 1], group = 256, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.4/base_net.4.5/Relu_output_0, %onnx::Conv_527, %onnx::Conv_528)\n",
            "  %/base_net.5/base_net.5.2/Relu_output_0 = Relu(%/base_net.5/base_net.5.0/Conv_output_0)\n",
            "  %/base_net.5/base_net.5.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.5/base_net.5.2/Relu_output_0, %onnx::Conv_530, %onnx::Conv_531)\n",
            "  %/base_net.5/base_net.5.5/Relu_output_0 = Relu(%/base_net.5/base_net.5.3/Conv_output_0)\n",
            "  %/base_net.6/base_net.6.0/Conv_output_0 = Conv[dilations = [1, 1], group = 256, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.5/base_net.5.5/Relu_output_0, %onnx::Conv_533, %onnx::Conv_534)\n",
            "  %/base_net.6/base_net.6.2/Relu_output_0 = Relu(%/base_net.6/base_net.6.0/Conv_output_0)\n",
            "  %/base_net.6/base_net.6.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.6/base_net.6.2/Relu_output_0, %onnx::Conv_536, %onnx::Conv_537)\n",
            "  %/base_net.6/base_net.6.5/Relu_output_0 = Relu(%/base_net.6/base_net.6.3/Conv_output_0)\n",
            "  %/base_net.7/base_net.7.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.6/base_net.6.5/Relu_output_0, %onnx::Conv_539, %onnx::Conv_540)\n",
            "  %/base_net.7/base_net.7.2/Relu_output_0 = Relu(%/base_net.7/base_net.7.0/Conv_output_0)\n",
            "  %/base_net.7/base_net.7.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.7/base_net.7.2/Relu_output_0, %onnx::Conv_542, %onnx::Conv_543)\n",
            "  %/base_net.7/base_net.7.5/Relu_output_0 = Relu(%/base_net.7/base_net.7.3/Conv_output_0)\n",
            "  %/base_net.8/base_net.8.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.7/base_net.7.5/Relu_output_0, %onnx::Conv_545, %onnx::Conv_546)\n",
            "  %/base_net.8/base_net.8.2/Relu_output_0 = Relu(%/base_net.8/base_net.8.0/Conv_output_0)\n",
            "  %/base_net.8/base_net.8.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.8/base_net.8.2/Relu_output_0, %onnx::Conv_548, %onnx::Conv_549)\n",
            "  %/base_net.8/base_net.8.5/Relu_output_0 = Relu(%/base_net.8/base_net.8.3/Conv_output_0)\n",
            "  %/base_net.9/base_net.9.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.8/base_net.8.5/Relu_output_0, %onnx::Conv_551, %onnx::Conv_552)\n",
            "  %/base_net.9/base_net.9.2/Relu_output_0 = Relu(%/base_net.9/base_net.9.0/Conv_output_0)\n",
            "  %/base_net.9/base_net.9.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.9/base_net.9.2/Relu_output_0, %onnx::Conv_554, %onnx::Conv_555)\n",
            "  %/base_net.9/base_net.9.5/Relu_output_0 = Relu(%/base_net.9/base_net.9.3/Conv_output_0)\n",
            "  %/base_net.10/base_net.10.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.9/base_net.9.5/Relu_output_0, %onnx::Conv_557, %onnx::Conv_558)\n",
            "  %/base_net.10/base_net.10.2/Relu_output_0 = Relu(%/base_net.10/base_net.10.0/Conv_output_0)\n",
            "  %/base_net.10/base_net.10.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.10/base_net.10.2/Relu_output_0, %onnx::Conv_560, %onnx::Conv_561)\n",
            "  %/base_net.10/base_net.10.5/Relu_output_0 = Relu(%/base_net.10/base_net.10.3/Conv_output_0)\n",
            "  %/base_net.11/base_net.11.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.10/base_net.10.5/Relu_output_0, %onnx::Conv_563, %onnx::Conv_564)\n",
            "  %/base_net.11/base_net.11.2/Relu_output_0 = Relu(%/base_net.11/base_net.11.0/Conv_output_0)\n",
            "  %/base_net.11/base_net.11.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.11/base_net.11.2/Relu_output_0, %onnx::Conv_566, %onnx::Conv_567)\n",
            "  %/base_net.11/base_net.11.5/Relu_output_0 = Relu(%/base_net.11/base_net.11.3/Conv_output_0)\n",
            "  %/classification_headers.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.11/base_net.11.5/Relu_output_0, %classification_headers.0.weight, %classification_headers.0.bias)\n",
            "  %/Transpose_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.0/Conv_output_0)\n",
            "  %/Shape_output_0 = Shape(%/Transpose_output_0)\n",
            "  %/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_output_0 = Gather[axis = 0](%/Shape_output_0, %/Constant_output_0)\n",
            "  %onnx::Unsqueeze_279 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_output_0 = Unsqueeze(%/Gather_output_0, %onnx::Unsqueeze_279)\n",
            "  %/Constant_1_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_2_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_output_0 = Concat[axis = 0](%/Unsqueeze_output_0, %/Constant_1_output_0, %/Constant_2_output_0)\n",
            "  %/Reshape_output_0 = Reshape[allowzero = 0](%/Transpose_output_0, %/Concat_output_0)\n",
            "  %/regression_headers.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.11/base_net.11.5/Relu_output_0, %regression_headers.0.weight, %regression_headers.0.bias)\n",
            "  %/Transpose_1_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.0/Conv_output_0)\n",
            "  %/Shape_1_output_0 = Shape(%/Transpose_1_output_0)\n",
            "  %/Constant_3_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_1_output_0 = Gather[axis = 0](%/Shape_1_output_0, %/Constant_3_output_0)\n",
            "  %onnx::Unsqueeze_293 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_1_output_0 = Unsqueeze(%/Gather_1_output_0, %onnx::Unsqueeze_293)\n",
            "  %/Constant_4_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_5_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_1_output_0 = Concat[axis = 0](%/Unsqueeze_1_output_0, %/Constant_4_output_0, %/Constant_5_output_0)\n",
            "  %/Reshape_1_output_0 = Reshape[allowzero = 0](%/Transpose_1_output_0, %/Concat_1_output_0)\n",
            "  %/base_net.12/base_net.12.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.11/base_net.11.5/Relu_output_0, %onnx::Conv_569, %onnx::Conv_570)\n",
            "  %/base_net.12/base_net.12.2/Relu_output_0 = Relu(%/base_net.12/base_net.12.0/Conv_output_0)\n",
            "  %/base_net.12/base_net.12.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.12/base_net.12.2/Relu_output_0, %onnx::Conv_572, %onnx::Conv_573)\n",
            "  %/base_net.12/base_net.12.5/Relu_output_0 = Relu(%/base_net.12/base_net.12.3/Conv_output_0)\n",
            "  %/base_net.13/base_net.13.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1024, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.12/base_net.12.5/Relu_output_0, %onnx::Conv_575, %onnx::Conv_576)\n",
            "  %/base_net.13/base_net.13.2/Relu_output_0 = Relu(%/base_net.13/base_net.13.0/Conv_output_0)\n",
            "  %/base_net.13/base_net.13.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.13/base_net.13.2/Relu_output_0, %onnx::Conv_578, %onnx::Conv_579)\n",
            "  %/base_net.13/base_net.13.5/Relu_output_0 = Relu(%/base_net.13/base_net.13.3/Conv_output_0)\n",
            "  %/classification_headers.1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.13/base_net.13.5/Relu_output_0, %classification_headers.1.weight, %classification_headers.1.bias)\n",
            "  %/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.1/Conv_output_0)\n",
            "  %/Shape_2_output_0 = Shape(%/Transpose_2_output_0)\n",
            "  %/Constant_6_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_2_output_0 = Gather[axis = 0](%/Shape_2_output_0, %/Constant_6_output_0)\n",
            "  %onnx::Unsqueeze_318 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_2_output_0 = Unsqueeze(%/Gather_2_output_0, %onnx::Unsqueeze_318)\n",
            "  %/Constant_7_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_8_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_2_output_0 = Concat[axis = 0](%/Unsqueeze_2_output_0, %/Constant_7_output_0, %/Constant_8_output_0)\n",
            "  %/Reshape_2_output_0 = Reshape[allowzero = 0](%/Transpose_2_output_0, %/Concat_2_output_0)\n",
            "  %/regression_headers.1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.13/base_net.13.5/Relu_output_0, %regression_headers.1.weight, %regression_headers.1.bias)\n",
            "  %/Transpose_3_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.1/Conv_output_0)\n",
            "  %/Shape_3_output_0 = Shape(%/Transpose_3_output_0)\n",
            "  %/Constant_9_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_3_output_0 = Gather[axis = 0](%/Shape_3_output_0, %/Constant_9_output_0)\n",
            "  %onnx::Unsqueeze_331 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_3_output_0 = Unsqueeze(%/Gather_3_output_0, %onnx::Unsqueeze_331)\n",
            "  %/Constant_10_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_11_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_3_output_0 = Concat[axis = 0](%/Unsqueeze_3_output_0, %/Constant_10_output_0, %/Constant_11_output_0)\n",
            "  %/Reshape_3_output_0 = Reshape[allowzero = 0](%/Transpose_3_output_0, %/Concat_3_output_0)\n",
            "  %/extras.0/extras.0.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.13/base_net.13.5/Relu_output_0, %extras.0.0.weight, %extras.0.0.bias)\n",
            "  %/extras.0/extras.0.1/Relu_output_0 = Relu(%/extras.0/extras.0.0/Conv_output_0)\n",
            "  %/extras.0/extras.0.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.0/extras.0.1/Relu_output_0, %extras.0.2.weight, %extras.0.2.bias)\n",
            "  %/extras.0/extras.0.3/Relu_output_0 = Relu(%/extras.0/extras.0.2/Conv_output_0)\n",
            "  %/classification_headers.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.0/extras.0.3/Relu_output_0, %classification_headers.2.weight, %classification_headers.2.bias)\n",
            "  %/Transpose_4_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.2/Conv_output_0)\n",
            "  %/Shape_4_output_0 = Shape(%/Transpose_4_output_0)\n",
            "  %/Constant_12_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_4_output_0 = Gather[axis = 0](%/Shape_4_output_0, %/Constant_12_output_0)\n",
            "  %onnx::Unsqueeze_348 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_4_output_0 = Unsqueeze(%/Gather_4_output_0, %onnx::Unsqueeze_348)\n",
            "  %/Constant_13_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_14_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_4_output_0 = Concat[axis = 0](%/Unsqueeze_4_output_0, %/Constant_13_output_0, %/Constant_14_output_0)\n",
            "  %/Reshape_4_output_0 = Reshape[allowzero = 0](%/Transpose_4_output_0, %/Concat_4_output_0)\n",
            "  %/regression_headers.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.0/extras.0.3/Relu_output_0, %regression_headers.2.weight, %regression_headers.2.bias)\n",
            "  %/Transpose_5_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.2/Conv_output_0)\n",
            "  %/Shape_5_output_0 = Shape(%/Transpose_5_output_0)\n",
            "  %/Constant_15_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_5_output_0 = Gather[axis = 0](%/Shape_5_output_0, %/Constant_15_output_0)\n",
            "  %onnx::Unsqueeze_361 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_5_output_0 = Unsqueeze(%/Gather_5_output_0, %onnx::Unsqueeze_361)\n",
            "  %/Constant_16_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_17_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_5_output_0 = Concat[axis = 0](%/Unsqueeze_5_output_0, %/Constant_16_output_0, %/Constant_17_output_0)\n",
            "  %/Reshape_5_output_0 = Reshape[allowzero = 0](%/Transpose_5_output_0, %/Concat_5_output_0)\n",
            "  %/extras.1/extras.1.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/extras.0/extras.0.3/Relu_output_0, %extras.1.0.weight, %extras.1.0.bias)\n",
            "  %/extras.1/extras.1.1/Relu_output_0 = Relu(%/extras.1/extras.1.0/Conv_output_0)\n",
            "  %/extras.1/extras.1.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.1/extras.1.1/Relu_output_0, %extras.1.2.weight, %extras.1.2.bias)\n",
            "  %/extras.1/extras.1.3/Relu_output_0 = Relu(%/extras.1/extras.1.2/Conv_output_0)\n",
            "  %/classification_headers.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.1/extras.1.3/Relu_output_0, %classification_headers.3.weight, %classification_headers.3.bias)\n",
            "  %/Transpose_6_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.3/Conv_output_0)\n",
            "  %/Shape_6_output_0 = Shape(%/Transpose_6_output_0)\n",
            "  %/Constant_18_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_6_output_0 = Gather[axis = 0](%/Shape_6_output_0, %/Constant_18_output_0)\n",
            "  %onnx::Unsqueeze_378 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_6_output_0 = Unsqueeze(%/Gather_6_output_0, %onnx::Unsqueeze_378)\n",
            "  %/Constant_19_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_20_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_6_output_0 = Concat[axis = 0](%/Unsqueeze_6_output_0, %/Constant_19_output_0, %/Constant_20_output_0)\n",
            "  %/Reshape_6_output_0 = Reshape[allowzero = 0](%/Transpose_6_output_0, %/Concat_6_output_0)\n",
            "  %/regression_headers.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.1/extras.1.3/Relu_output_0, %regression_headers.3.weight, %regression_headers.3.bias)\n",
            "  %/Transpose_7_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.3/Conv_output_0)\n",
            "  %/Shape_7_output_0 = Shape(%/Transpose_7_output_0)\n",
            "  %/Constant_21_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_7_output_0 = Gather[axis = 0](%/Shape_7_output_0, %/Constant_21_output_0)\n",
            "  %onnx::Unsqueeze_391 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_7_output_0 = Unsqueeze(%/Gather_7_output_0, %onnx::Unsqueeze_391)\n",
            "  %/Constant_22_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_23_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_7_output_0 = Concat[axis = 0](%/Unsqueeze_7_output_0, %/Constant_22_output_0, %/Constant_23_output_0)\n",
            "  %/Reshape_7_output_0 = Reshape[allowzero = 0](%/Transpose_7_output_0, %/Concat_7_output_0)\n",
            "  %/extras.2/extras.2.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/extras.1/extras.1.3/Relu_output_0, %extras.2.0.weight, %extras.2.0.bias)\n",
            "  %/extras.2/extras.2.1/Relu_output_0 = Relu(%/extras.2/extras.2.0/Conv_output_0)\n",
            "  %/extras.2/extras.2.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.2/extras.2.1/Relu_output_0, %extras.2.2.weight, %extras.2.2.bias)\n",
            "  %/extras.2/extras.2.3/Relu_output_0 = Relu(%/extras.2/extras.2.2/Conv_output_0)\n",
            "  %/classification_headers.4/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.2/extras.2.3/Relu_output_0, %classification_headers.4.weight, %classification_headers.4.bias)\n",
            "  %/Transpose_8_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.4/Conv_output_0)\n",
            "  %/Shape_8_output_0 = Shape(%/Transpose_8_output_0)\n",
            "  %/Constant_24_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_8_output_0 = Gather[axis = 0](%/Shape_8_output_0, %/Constant_24_output_0)\n",
            "  %onnx::Unsqueeze_408 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_8_output_0 = Unsqueeze(%/Gather_8_output_0, %onnx::Unsqueeze_408)\n",
            "  %/Constant_25_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_26_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_8_output_0 = Concat[axis = 0](%/Unsqueeze_8_output_0, %/Constant_25_output_0, %/Constant_26_output_0)\n",
            "  %/Reshape_8_output_0 = Reshape[allowzero = 0](%/Transpose_8_output_0, %/Concat_8_output_0)\n",
            "  %/regression_headers.4/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.2/extras.2.3/Relu_output_0, %regression_headers.4.weight, %regression_headers.4.bias)\n",
            "  %/Transpose_9_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.4/Conv_output_0)\n",
            "  %/Shape_9_output_0 = Shape(%/Transpose_9_output_0)\n",
            "  %/Constant_27_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_9_output_0 = Gather[axis = 0](%/Shape_9_output_0, %/Constant_27_output_0)\n",
            "  %onnx::Unsqueeze_421 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_9_output_0 = Unsqueeze(%/Gather_9_output_0, %onnx::Unsqueeze_421)\n",
            "  %/Constant_28_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_29_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_9_output_0 = Concat[axis = 0](%/Unsqueeze_9_output_0, %/Constant_28_output_0, %/Constant_29_output_0)\n",
            "  %/Reshape_9_output_0 = Reshape[allowzero = 0](%/Transpose_9_output_0, %/Concat_9_output_0)\n",
            "  %/extras.3/extras.3.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/extras.2/extras.2.3/Relu_output_0, %extras.3.0.weight, %extras.3.0.bias)\n",
            "  %/extras.3/extras.3.1/Relu_output_0 = Relu(%/extras.3/extras.3.0/Conv_output_0)\n",
            "  %/extras.3/extras.3.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.3/extras.3.1/Relu_output_0, %extras.3.2.weight, %extras.3.2.bias)\n",
            "  %/extras.3/extras.3.3/Relu_output_0 = Relu(%/extras.3/extras.3.2/Conv_output_0)\n",
            "  %/classification_headers.5/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.3/extras.3.3/Relu_output_0, %classification_headers.5.weight, %classification_headers.5.bias)\n",
            "  %/Transpose_10_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.5/Conv_output_0)\n",
            "  %/Shape_10_output_0 = Shape(%/Transpose_10_output_0)\n",
            "  %/Constant_30_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_10_output_0 = Gather[axis = 0](%/Shape_10_output_0, %/Constant_30_output_0)\n",
            "  %onnx::Unsqueeze_438 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_10_output_0 = Unsqueeze(%/Gather_10_output_0, %onnx::Unsqueeze_438)\n",
            "  %/Constant_31_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_32_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_10_output_0 = Concat[axis = 0](%/Unsqueeze_10_output_0, %/Constant_31_output_0, %/Constant_32_output_0)\n",
            "  %/Reshape_10_output_0 = Reshape[allowzero = 0](%/Transpose_10_output_0, %/Concat_10_output_0)\n",
            "  %/regression_headers.5/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.3/extras.3.3/Relu_output_0, %regression_headers.5.weight, %regression_headers.5.bias)\n",
            "  %/Transpose_11_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.5/Conv_output_0)\n",
            "  %/Shape_11_output_0 = Shape(%/Transpose_11_output_0)\n",
            "  %/Constant_33_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_11_output_0 = Gather[axis = 0](%/Shape_11_output_0, %/Constant_33_output_0)\n",
            "  %onnx::Unsqueeze_451 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_11_output_0 = Unsqueeze(%/Gather_11_output_0, %onnx::Unsqueeze_451)\n",
            "  %/Constant_34_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_35_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_11_output_0 = Concat[axis = 0](%/Unsqueeze_11_output_0, %/Constant_34_output_0, %/Constant_35_output_0)\n",
            "  %/Reshape_11_output_0 = Reshape[allowzero = 0](%/Transpose_11_output_0, %/Concat_11_output_0)\n",
            "  %/Concat_12_output_0 = Concat[axis = 1](%/Reshape_output_0, %/Reshape_2_output_0, %/Reshape_4_output_0, %/Reshape_6_output_0, %/Reshape_8_output_0, %/Reshape_10_output_0)\n",
            "  %/Concat_13_output_0 = Concat[axis = 1](%/Reshape_1_output_0, %/Reshape_3_output_0, %/Reshape_5_output_0, %/Reshape_7_output_0, %/Reshape_9_output_0, %/Reshape_11_output_0)\n",
            "  %scores = Softmax[axis = 2](%/Concat_12_output_0)\n",
            "  %/Constant_36_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_37_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_38_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_39_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_output_0 = Slice(%/Concat_13_output_0, %/Constant_37_output_0, %/Constant_38_output_0, %/Constant_36_output_0, %/Constant_39_output_0)\n",
            "  %/Constant_40_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Mul_output_0 = Mul(%/Slice_output_0, %/Constant_40_output_0)\n",
            "  %/Constant_41_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Mul_1_output_0 = Mul(%/Mul_output_0, %/Constant_41_output_0)\n",
            "  %/Constant_42_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Add_output_0 = Add(%/Mul_1_output_0, %/Constant_42_output_0)\n",
            "  %/Constant_43_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_44_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_45_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_46_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_1_output_0 = Slice(%/Concat_13_output_0, %/Constant_44_output_0, %/Constant_45_output_0, %/Constant_43_output_0, %/Constant_46_output_0)\n",
            "  %/Constant_47_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Mul_2_output_0 = Mul(%/Slice_1_output_0, %/Constant_47_output_0)\n",
            "  %/Exp_output_0 = Exp(%/Mul_2_output_0)\n",
            "  %/Constant_48_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Mul_3_output_0 = Mul(%/Exp_output_0, %/Constant_48_output_0)\n",
            "  %/Concat_14_output_0 = Concat[axis = 2](%/Add_output_0, %/Mul_3_output_0)\n",
            "  %/Constant_49_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_50_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_51_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_52_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_2_output_0 = Slice(%/Concat_14_output_0, %/Constant_50_output_0, %/Constant_51_output_0, %/Constant_49_output_0, %/Constant_52_output_0)\n",
            "  %/Constant_53_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_54_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_55_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_56_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_3_output_0 = Slice(%/Concat_14_output_0, %/Constant_54_output_0, %/Constant_55_output_0, %/Constant_53_output_0, %/Constant_56_output_0)\n",
            "  %/Constant_57_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Div_output_0 = Div(%/Slice_3_output_0, %/Constant_57_output_0)\n",
            "  %/Sub_output_0 = Sub(%/Slice_2_output_0, %/Div_output_0)\n",
            "  %/Add_1_output_0 = Add(%/Slice_2_output_0, %/Div_output_0)\n",
            "  %boxes = Concat[axis = 2](%/Sub_output_0, %/Add_1_output_0)\n",
            "  return %scores, %boxes\n",
            "}\n",
            "(1, 3000, 3)\n",
            "(1, 3000, 4)\n"
          ]
        }
      ],
      "source": [
        "import onnx\n",
        "import onnxruntime\n",
        "\n",
        "onnx_model = onnx.load(model_onnx_path)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "print(onnx.helper.printable_graph(onnx_model.graph))\n",
        "ort_session = onnxruntime.InferenceSession(model_onnx_path)\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "print(ort_outs[0].shape)\n",
        "print(ort_outs[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdmtAA3eNY05"
      },
      "source": [
        "### 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrwKWqMAnMqz",
        "outputId": "ddb9c85c-859c-49ad-a086-fe12d4c8d36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "graph torch_jit (\n",
            "  %input[FLOAT, batch_sizex3x300x300]\n",
            ") initializers (\n",
            "  %extras.0.0.weight[FLOAT, 256x1024x1x1]\n",
            "  %extras.0.0.bias[FLOAT, 256]\n",
            "  %extras.0.2.weight[FLOAT, 512x256x3x3]\n",
            "  %extras.0.2.bias[FLOAT, 512]\n",
            "  %extras.1.0.weight[FLOAT, 128x512x1x1]\n",
            "  %extras.1.0.bias[FLOAT, 128]\n",
            "  %extras.1.2.weight[FLOAT, 256x128x3x3]\n",
            "  %extras.1.2.bias[FLOAT, 256]\n",
            "  %extras.2.0.weight[FLOAT, 128x256x1x1]\n",
            "  %extras.2.0.bias[FLOAT, 128]\n",
            "  %extras.2.2.weight[FLOAT, 256x128x3x3]\n",
            "  %extras.2.2.bias[FLOAT, 256]\n",
            "  %extras.3.0.weight[FLOAT, 128x256x1x1]\n",
            "  %extras.3.0.bias[FLOAT, 128]\n",
            "  %extras.3.2.weight[FLOAT, 256x128x3x3]\n",
            "  %extras.3.2.bias[FLOAT, 256]\n",
            "  %classification_headers.0.weight[FLOAT, 18x512x3x3]\n",
            "  %classification_headers.0.bias[FLOAT, 18]\n",
            "  %classification_headers.1.weight[FLOAT, 18x1024x3x3]\n",
            "  %classification_headers.1.bias[FLOAT, 18]\n",
            "  %classification_headers.2.weight[FLOAT, 18x512x3x3]\n",
            "  %classification_headers.2.bias[FLOAT, 18]\n",
            "  %classification_headers.3.weight[FLOAT, 18x256x3x3]\n",
            "  %classification_headers.3.bias[FLOAT, 18]\n",
            "  %classification_headers.4.weight[FLOAT, 18x256x3x3]\n",
            "  %classification_headers.4.bias[FLOAT, 18]\n",
            "  %classification_headers.5.weight[FLOAT, 18x256x3x3]\n",
            "  %classification_headers.5.bias[FLOAT, 18]\n",
            "  %regression_headers.0.weight[FLOAT, 24x512x3x3]\n",
            "  %regression_headers.0.bias[FLOAT, 24]\n",
            "  %regression_headers.1.weight[FLOAT, 24x1024x3x3]\n",
            "  %regression_headers.1.bias[FLOAT, 24]\n",
            "  %regression_headers.2.weight[FLOAT, 24x512x3x3]\n",
            "  %regression_headers.2.bias[FLOAT, 24]\n",
            "  %regression_headers.3.weight[FLOAT, 24x256x3x3]\n",
            "  %regression_headers.3.bias[FLOAT, 24]\n",
            "  %regression_headers.4.weight[FLOAT, 24x256x3x3]\n",
            "  %regression_headers.4.bias[FLOAT, 24]\n",
            "  %regression_headers.5.weight[FLOAT, 24x256x3x3]\n",
            "  %regression_headers.5.bias[FLOAT, 24]\n",
            "  %onnx::Conv_500[FLOAT, 32x3x3x3]\n",
            "  %onnx::Conv_501[FLOAT, 32]\n",
            "  %onnx::Conv_503[FLOAT, 32x1x3x3]\n",
            "  %onnx::Conv_504[FLOAT, 32]\n",
            "  %onnx::Conv_506[FLOAT, 64x32x1x1]\n",
            "  %onnx::Conv_507[FLOAT, 64]\n",
            "  %onnx::Conv_509[FLOAT, 64x1x3x3]\n",
            "  %onnx::Conv_510[FLOAT, 64]\n",
            "  %onnx::Conv_512[FLOAT, 128x64x1x1]\n",
            "  %onnx::Conv_513[FLOAT, 128]\n",
            "  %onnx::Conv_515[FLOAT, 128x1x3x3]\n",
            "  %onnx::Conv_516[FLOAT, 128]\n",
            "  %onnx::Conv_518[FLOAT, 128x128x1x1]\n",
            "  %onnx::Conv_519[FLOAT, 128]\n",
            "  %onnx::Conv_521[FLOAT, 128x1x3x3]\n",
            "  %onnx::Conv_522[FLOAT, 128]\n",
            "  %onnx::Conv_524[FLOAT, 256x128x1x1]\n",
            "  %onnx::Conv_525[FLOAT, 256]\n",
            "  %onnx::Conv_527[FLOAT, 256x1x3x3]\n",
            "  %onnx::Conv_528[FLOAT, 256]\n",
            "  %onnx::Conv_530[FLOAT, 256x256x1x1]\n",
            "  %onnx::Conv_531[FLOAT, 256]\n",
            "  %onnx::Conv_533[FLOAT, 256x1x3x3]\n",
            "  %onnx::Conv_534[FLOAT, 256]\n",
            "  %onnx::Conv_536[FLOAT, 512x256x1x1]\n",
            "  %onnx::Conv_537[FLOAT, 512]\n",
            "  %onnx::Conv_539[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_540[FLOAT, 512]\n",
            "  %onnx::Conv_542[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_543[FLOAT, 512]\n",
            "  %onnx::Conv_545[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_546[FLOAT, 512]\n",
            "  %onnx::Conv_548[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_549[FLOAT, 512]\n",
            "  %onnx::Conv_551[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_552[FLOAT, 512]\n",
            "  %onnx::Conv_554[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_555[FLOAT, 512]\n",
            "  %onnx::Conv_557[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_558[FLOAT, 512]\n",
            "  %onnx::Conv_560[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_561[FLOAT, 512]\n",
            "  %onnx::Conv_563[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_564[FLOAT, 512]\n",
            "  %onnx::Conv_566[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_567[FLOAT, 512]\n",
            "  %onnx::Conv_569[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_570[FLOAT, 512]\n",
            "  %onnx::Conv_572[FLOAT, 1024x512x1x1]\n",
            "  %onnx::Conv_573[FLOAT, 1024]\n",
            "  %onnx::Conv_575[FLOAT, 1024x1x3x3]\n",
            "  %onnx::Conv_576[FLOAT, 1024]\n",
            "  %onnx::Conv_578[FLOAT, 1024x1024x1x1]\n",
            "  %onnx::Conv_579[FLOAT, 1024]\n",
            ") {\n",
            "  %/base_net.0/base_net.0.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%input, %onnx::Conv_500, %onnx::Conv_501)\n",
            "  %/base_net.0/base_net.0.2/Relu_output_0 = Relu(%/base_net.0/base_net.0.0/Conv_output_0)\n",
            "  %/base_net.1/base_net.1.0/Conv_output_0 = Conv[dilations = [1, 1], group = 32, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.0/base_net.0.2/Relu_output_0, %onnx::Conv_503, %onnx::Conv_504)\n",
            "  %/base_net.1/base_net.1.2/Relu_output_0 = Relu(%/base_net.1/base_net.1.0/Conv_output_0)\n",
            "  %/base_net.1/base_net.1.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.1/base_net.1.2/Relu_output_0, %onnx::Conv_506, %onnx::Conv_507)\n",
            "  %/base_net.1/base_net.1.5/Relu_output_0 = Relu(%/base_net.1/base_net.1.3/Conv_output_0)\n",
            "  %/base_net.2/base_net.2.0/Conv_output_0 = Conv[dilations = [1, 1], group = 64, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.1/base_net.1.5/Relu_output_0, %onnx::Conv_509, %onnx::Conv_510)\n",
            "  %/base_net.2/base_net.2.2/Relu_output_0 = Relu(%/base_net.2/base_net.2.0/Conv_output_0)\n",
            "  %/base_net.2/base_net.2.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.2/base_net.2.2/Relu_output_0, %onnx::Conv_512, %onnx::Conv_513)\n",
            "  %/base_net.2/base_net.2.5/Relu_output_0 = Relu(%/base_net.2/base_net.2.3/Conv_output_0)\n",
            "  %/base_net.3/base_net.3.0/Conv_output_0 = Conv[dilations = [1, 1], group = 128, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.2/base_net.2.5/Relu_output_0, %onnx::Conv_515, %onnx::Conv_516)\n",
            "  %/base_net.3/base_net.3.2/Relu_output_0 = Relu(%/base_net.3/base_net.3.0/Conv_output_0)\n",
            "  %/base_net.3/base_net.3.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.3/base_net.3.2/Relu_output_0, %onnx::Conv_518, %onnx::Conv_519)\n",
            "  %/base_net.3/base_net.3.5/Relu_output_0 = Relu(%/base_net.3/base_net.3.3/Conv_output_0)\n",
            "  %/base_net.4/base_net.4.0/Conv_output_0 = Conv[dilations = [1, 1], group = 128, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.3/base_net.3.5/Relu_output_0, %onnx::Conv_521, %onnx::Conv_522)\n",
            "  %/base_net.4/base_net.4.2/Relu_output_0 = Relu(%/base_net.4/base_net.4.0/Conv_output_0)\n",
            "  %/base_net.4/base_net.4.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.4/base_net.4.2/Relu_output_0, %onnx::Conv_524, %onnx::Conv_525)\n",
            "  %/base_net.4/base_net.4.5/Relu_output_0 = Relu(%/base_net.4/base_net.4.3/Conv_output_0)\n",
            "  %/base_net.5/base_net.5.0/Conv_output_0 = Conv[dilations = [1, 1], group = 256, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.4/base_net.4.5/Relu_output_0, %onnx::Conv_527, %onnx::Conv_528)\n",
            "  %/base_net.5/base_net.5.2/Relu_output_0 = Relu(%/base_net.5/base_net.5.0/Conv_output_0)\n",
            "  %/base_net.5/base_net.5.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.5/base_net.5.2/Relu_output_0, %onnx::Conv_530, %onnx::Conv_531)\n",
            "  %/base_net.5/base_net.5.5/Relu_output_0 = Relu(%/base_net.5/base_net.5.3/Conv_output_0)\n",
            "  %/base_net.6/base_net.6.0/Conv_output_0 = Conv[dilations = [1, 1], group = 256, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.5/base_net.5.5/Relu_output_0, %onnx::Conv_533, %onnx::Conv_534)\n",
            "  %/base_net.6/base_net.6.2/Relu_output_0 = Relu(%/base_net.6/base_net.6.0/Conv_output_0)\n",
            "  %/base_net.6/base_net.6.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.6/base_net.6.2/Relu_output_0, %onnx::Conv_536, %onnx::Conv_537)\n",
            "  %/base_net.6/base_net.6.5/Relu_output_0 = Relu(%/base_net.6/base_net.6.3/Conv_output_0)\n",
            "  %/base_net.7/base_net.7.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.6/base_net.6.5/Relu_output_0, %onnx::Conv_539, %onnx::Conv_540)\n",
            "  %/base_net.7/base_net.7.2/Relu_output_0 = Relu(%/base_net.7/base_net.7.0/Conv_output_0)\n",
            "  %/base_net.7/base_net.7.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.7/base_net.7.2/Relu_output_0, %onnx::Conv_542, %onnx::Conv_543)\n",
            "  %/base_net.7/base_net.7.5/Relu_output_0 = Relu(%/base_net.7/base_net.7.3/Conv_output_0)\n",
            "  %/base_net.8/base_net.8.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.7/base_net.7.5/Relu_output_0, %onnx::Conv_545, %onnx::Conv_546)\n",
            "  %/base_net.8/base_net.8.2/Relu_output_0 = Relu(%/base_net.8/base_net.8.0/Conv_output_0)\n",
            "  %/base_net.8/base_net.8.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.8/base_net.8.2/Relu_output_0, %onnx::Conv_548, %onnx::Conv_549)\n",
            "  %/base_net.8/base_net.8.5/Relu_output_0 = Relu(%/base_net.8/base_net.8.3/Conv_output_0)\n",
            "  %/base_net.9/base_net.9.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.8/base_net.8.5/Relu_output_0, %onnx::Conv_551, %onnx::Conv_552)\n",
            "  %/base_net.9/base_net.9.2/Relu_output_0 = Relu(%/base_net.9/base_net.9.0/Conv_output_0)\n",
            "  %/base_net.9/base_net.9.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.9/base_net.9.2/Relu_output_0, %onnx::Conv_554, %onnx::Conv_555)\n",
            "  %/base_net.9/base_net.9.5/Relu_output_0 = Relu(%/base_net.9/base_net.9.3/Conv_output_0)\n",
            "  %/base_net.10/base_net.10.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.9/base_net.9.5/Relu_output_0, %onnx::Conv_557, %onnx::Conv_558)\n",
            "  %/base_net.10/base_net.10.2/Relu_output_0 = Relu(%/base_net.10/base_net.10.0/Conv_output_0)\n",
            "  %/base_net.10/base_net.10.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.10/base_net.10.2/Relu_output_0, %onnx::Conv_560, %onnx::Conv_561)\n",
            "  %/base_net.10/base_net.10.5/Relu_output_0 = Relu(%/base_net.10/base_net.10.3/Conv_output_0)\n",
            "  %/base_net.11/base_net.11.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.10/base_net.10.5/Relu_output_0, %onnx::Conv_563, %onnx::Conv_564)\n",
            "  %/base_net.11/base_net.11.2/Relu_output_0 = Relu(%/base_net.11/base_net.11.0/Conv_output_0)\n",
            "  %/base_net.11/base_net.11.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.11/base_net.11.2/Relu_output_0, %onnx::Conv_566, %onnx::Conv_567)\n",
            "  %/base_net.11/base_net.11.5/Relu_output_0 = Relu(%/base_net.11/base_net.11.3/Conv_output_0)\n",
            "  %/classification_headers.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.11/base_net.11.5/Relu_output_0, %classification_headers.0.weight, %classification_headers.0.bias)\n",
            "  %/Transpose_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.0/Conv_output_0)\n",
            "  %/Shape_output_0 = Shape(%/Transpose_output_0)\n",
            "  %/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_output_0 = Gather[axis = 0](%/Shape_output_0, %/Constant_output_0)\n",
            "  %onnx::Unsqueeze_279 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_output_0 = Unsqueeze(%/Gather_output_0, %onnx::Unsqueeze_279)\n",
            "  %/Constant_1_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_2_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_output_0 = Concat[axis = 0](%/Unsqueeze_output_0, %/Constant_1_output_0, %/Constant_2_output_0)\n",
            "  %/Reshape_output_0 = Reshape[allowzero = 0](%/Transpose_output_0, %/Concat_output_0)\n",
            "  %/regression_headers.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.11/base_net.11.5/Relu_output_0, %regression_headers.0.weight, %regression_headers.0.bias)\n",
            "  %/Transpose_1_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.0/Conv_output_0)\n",
            "  %/Shape_1_output_0 = Shape(%/Transpose_1_output_0)\n",
            "  %/Constant_3_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_1_output_0 = Gather[axis = 0](%/Shape_1_output_0, %/Constant_3_output_0)\n",
            "  %onnx::Unsqueeze_293 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_1_output_0 = Unsqueeze(%/Gather_1_output_0, %onnx::Unsqueeze_293)\n",
            "  %/Constant_4_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_5_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_1_output_0 = Concat[axis = 0](%/Unsqueeze_1_output_0, %/Constant_4_output_0, %/Constant_5_output_0)\n",
            "  %/Reshape_1_output_0 = Reshape[allowzero = 0](%/Transpose_1_output_0, %/Concat_1_output_0)\n",
            "  %/base_net.12/base_net.12.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.11/base_net.11.5/Relu_output_0, %onnx::Conv_569, %onnx::Conv_570)\n",
            "  %/base_net.12/base_net.12.2/Relu_output_0 = Relu(%/base_net.12/base_net.12.0/Conv_output_0)\n",
            "  %/base_net.12/base_net.12.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.12/base_net.12.2/Relu_output_0, %onnx::Conv_572, %onnx::Conv_573)\n",
            "  %/base_net.12/base_net.12.5/Relu_output_0 = Relu(%/base_net.12/base_net.12.3/Conv_output_0)\n",
            "  %/base_net.13/base_net.13.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1024, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.12/base_net.12.5/Relu_output_0, %onnx::Conv_575, %onnx::Conv_576)\n",
            "  %/base_net.13/base_net.13.2/Relu_output_0 = Relu(%/base_net.13/base_net.13.0/Conv_output_0)\n",
            "  %/base_net.13/base_net.13.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.13/base_net.13.2/Relu_output_0, %onnx::Conv_578, %onnx::Conv_579)\n",
            "  %/base_net.13/base_net.13.5/Relu_output_0 = Relu(%/base_net.13/base_net.13.3/Conv_output_0)\n",
            "  %/classification_headers.1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.13/base_net.13.5/Relu_output_0, %classification_headers.1.weight, %classification_headers.1.bias)\n",
            "  %/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.1/Conv_output_0)\n",
            "  %/Shape_2_output_0 = Shape(%/Transpose_2_output_0)\n",
            "  %/Constant_6_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_2_output_0 = Gather[axis = 0](%/Shape_2_output_0, %/Constant_6_output_0)\n",
            "  %onnx::Unsqueeze_318 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_2_output_0 = Unsqueeze(%/Gather_2_output_0, %onnx::Unsqueeze_318)\n",
            "  %/Constant_7_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_8_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_2_output_0 = Concat[axis = 0](%/Unsqueeze_2_output_0, %/Constant_7_output_0, %/Constant_8_output_0)\n",
            "  %/Reshape_2_output_0 = Reshape[allowzero = 0](%/Transpose_2_output_0, %/Concat_2_output_0)\n",
            "  %/regression_headers.1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.13/base_net.13.5/Relu_output_0, %regression_headers.1.weight, %regression_headers.1.bias)\n",
            "  %/Transpose_3_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.1/Conv_output_0)\n",
            "  %/Shape_3_output_0 = Shape(%/Transpose_3_output_0)\n",
            "  %/Constant_9_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_3_output_0 = Gather[axis = 0](%/Shape_3_output_0, %/Constant_9_output_0)\n",
            "  %onnx::Unsqueeze_331 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_3_output_0 = Unsqueeze(%/Gather_3_output_0, %onnx::Unsqueeze_331)\n",
            "  %/Constant_10_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_11_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_3_output_0 = Concat[axis = 0](%/Unsqueeze_3_output_0, %/Constant_10_output_0, %/Constant_11_output_0)\n",
            "  %/Reshape_3_output_0 = Reshape[allowzero = 0](%/Transpose_3_output_0, %/Concat_3_output_0)\n",
            "  %/extras.0/extras.0.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.13/base_net.13.5/Relu_output_0, %extras.0.0.weight, %extras.0.0.bias)\n",
            "  %/extras.0/extras.0.1/Relu_output_0 = Relu(%/extras.0/extras.0.0/Conv_output_0)\n",
            "  %/extras.0/extras.0.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.0/extras.0.1/Relu_output_0, %extras.0.2.weight, %extras.0.2.bias)\n",
            "  %/extras.0/extras.0.3/Relu_output_0 = Relu(%/extras.0/extras.0.2/Conv_output_0)\n",
            "  %/classification_headers.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.0/extras.0.3/Relu_output_0, %classification_headers.2.weight, %classification_headers.2.bias)\n",
            "  %/Transpose_4_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.2/Conv_output_0)\n",
            "  %/Shape_4_output_0 = Shape(%/Transpose_4_output_0)\n",
            "  %/Constant_12_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_4_output_0 = Gather[axis = 0](%/Shape_4_output_0, %/Constant_12_output_0)\n",
            "  %onnx::Unsqueeze_348 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_4_output_0 = Unsqueeze(%/Gather_4_output_0, %onnx::Unsqueeze_348)\n",
            "  %/Constant_13_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_14_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_4_output_0 = Concat[axis = 0](%/Unsqueeze_4_output_0, %/Constant_13_output_0, %/Constant_14_output_0)\n",
            "  %/Reshape_4_output_0 = Reshape[allowzero = 0](%/Transpose_4_output_0, %/Concat_4_output_0)\n",
            "  %/regression_headers.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.0/extras.0.3/Relu_output_0, %regression_headers.2.weight, %regression_headers.2.bias)\n",
            "  %/Transpose_5_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.2/Conv_output_0)\n",
            "  %/Shape_5_output_0 = Shape(%/Transpose_5_output_0)\n",
            "  %/Constant_15_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_5_output_0 = Gather[axis = 0](%/Shape_5_output_0, %/Constant_15_output_0)\n",
            "  %onnx::Unsqueeze_361 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_5_output_0 = Unsqueeze(%/Gather_5_output_0, %onnx::Unsqueeze_361)\n",
            "  %/Constant_16_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_17_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_5_output_0 = Concat[axis = 0](%/Unsqueeze_5_output_0, %/Constant_16_output_0, %/Constant_17_output_0)\n",
            "  %/Reshape_5_output_0 = Reshape[allowzero = 0](%/Transpose_5_output_0, %/Concat_5_output_0)\n",
            "  %/extras.1/extras.1.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/extras.0/extras.0.3/Relu_output_0, %extras.1.0.weight, %extras.1.0.bias)\n",
            "  %/extras.1/extras.1.1/Relu_output_0 = Relu(%/extras.1/extras.1.0/Conv_output_0)\n",
            "  %/extras.1/extras.1.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.1/extras.1.1/Relu_output_0, %extras.1.2.weight, %extras.1.2.bias)\n",
            "  %/extras.1/extras.1.3/Relu_output_0 = Relu(%/extras.1/extras.1.2/Conv_output_0)\n",
            "  %/classification_headers.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.1/extras.1.3/Relu_output_0, %classification_headers.3.weight, %classification_headers.3.bias)\n",
            "  %/Transpose_6_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.3/Conv_output_0)\n",
            "  %/Shape_6_output_0 = Shape(%/Transpose_6_output_0)\n",
            "  %/Constant_18_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_6_output_0 = Gather[axis = 0](%/Shape_6_output_0, %/Constant_18_output_0)\n",
            "  %onnx::Unsqueeze_378 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_6_output_0 = Unsqueeze(%/Gather_6_output_0, %onnx::Unsqueeze_378)\n",
            "  %/Constant_19_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_20_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_6_output_0 = Concat[axis = 0](%/Unsqueeze_6_output_0, %/Constant_19_output_0, %/Constant_20_output_0)\n",
            "  %/Reshape_6_output_0 = Reshape[allowzero = 0](%/Transpose_6_output_0, %/Concat_6_output_0)\n",
            "  %/regression_headers.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.1/extras.1.3/Relu_output_0, %regression_headers.3.weight, %regression_headers.3.bias)\n",
            "  %/Transpose_7_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.3/Conv_output_0)\n",
            "  %/Shape_7_output_0 = Shape(%/Transpose_7_output_0)\n",
            "  %/Constant_21_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_7_output_0 = Gather[axis = 0](%/Shape_7_output_0, %/Constant_21_output_0)\n",
            "  %onnx::Unsqueeze_391 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_7_output_0 = Unsqueeze(%/Gather_7_output_0, %onnx::Unsqueeze_391)\n",
            "  %/Constant_22_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_23_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_7_output_0 = Concat[axis = 0](%/Unsqueeze_7_output_0, %/Constant_22_output_0, %/Constant_23_output_0)\n",
            "  %/Reshape_7_output_0 = Reshape[allowzero = 0](%/Transpose_7_output_0, %/Concat_7_output_0)\n",
            "  %/extras.2/extras.2.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/extras.1/extras.1.3/Relu_output_0, %extras.2.0.weight, %extras.2.0.bias)\n",
            "  %/extras.2/extras.2.1/Relu_output_0 = Relu(%/extras.2/extras.2.0/Conv_output_0)\n",
            "  %/extras.2/extras.2.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.2/extras.2.1/Relu_output_0, %extras.2.2.weight, %extras.2.2.bias)\n",
            "  %/extras.2/extras.2.3/Relu_output_0 = Relu(%/extras.2/extras.2.2/Conv_output_0)\n",
            "  %/classification_headers.4/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.2/extras.2.3/Relu_output_0, %classification_headers.4.weight, %classification_headers.4.bias)\n",
            "  %/Transpose_8_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.4/Conv_output_0)\n",
            "  %/Shape_8_output_0 = Shape(%/Transpose_8_output_0)\n",
            "  %/Constant_24_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_8_output_0 = Gather[axis = 0](%/Shape_8_output_0, %/Constant_24_output_0)\n",
            "  %onnx::Unsqueeze_408 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_8_output_0 = Unsqueeze(%/Gather_8_output_0, %onnx::Unsqueeze_408)\n",
            "  %/Constant_25_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_26_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_8_output_0 = Concat[axis = 0](%/Unsqueeze_8_output_0, %/Constant_25_output_0, %/Constant_26_output_0)\n",
            "  %/Reshape_8_output_0 = Reshape[allowzero = 0](%/Transpose_8_output_0, %/Concat_8_output_0)\n",
            "  %/regression_headers.4/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.2/extras.2.3/Relu_output_0, %regression_headers.4.weight, %regression_headers.4.bias)\n",
            "  %/Transpose_9_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.4/Conv_output_0)\n",
            "  %/Shape_9_output_0 = Shape(%/Transpose_9_output_0)\n",
            "  %/Constant_27_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_9_output_0 = Gather[axis = 0](%/Shape_9_output_0, %/Constant_27_output_0)\n",
            "  %onnx::Unsqueeze_421 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_9_output_0 = Unsqueeze(%/Gather_9_output_0, %onnx::Unsqueeze_421)\n",
            "  %/Constant_28_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_29_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_9_output_0 = Concat[axis = 0](%/Unsqueeze_9_output_0, %/Constant_28_output_0, %/Constant_29_output_0)\n",
            "  %/Reshape_9_output_0 = Reshape[allowzero = 0](%/Transpose_9_output_0, %/Concat_9_output_0)\n",
            "  %/extras.3/extras.3.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/extras.2/extras.2.3/Relu_output_0, %extras.3.0.weight, %extras.3.0.bias)\n",
            "  %/extras.3/extras.3.1/Relu_output_0 = Relu(%/extras.3/extras.3.0/Conv_output_0)\n",
            "  %/extras.3/extras.3.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.3/extras.3.1/Relu_output_0, %extras.3.2.weight, %extras.3.2.bias)\n",
            "  %/extras.3/extras.3.3/Relu_output_0 = Relu(%/extras.3/extras.3.2/Conv_output_0)\n",
            "  %/classification_headers.5/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.3/extras.3.3/Relu_output_0, %classification_headers.5.weight, %classification_headers.5.bias)\n",
            "  %/Transpose_10_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.5/Conv_output_0)\n",
            "  %/Shape_10_output_0 = Shape(%/Transpose_10_output_0)\n",
            "  %/Constant_30_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_10_output_0 = Gather[axis = 0](%/Shape_10_output_0, %/Constant_30_output_0)\n",
            "  %onnx::Unsqueeze_438 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_10_output_0 = Unsqueeze(%/Gather_10_output_0, %onnx::Unsqueeze_438)\n",
            "  %/Constant_31_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_32_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_10_output_0 = Concat[axis = 0](%/Unsqueeze_10_output_0, %/Constant_31_output_0, %/Constant_32_output_0)\n",
            "  %/Reshape_10_output_0 = Reshape[allowzero = 0](%/Transpose_10_output_0, %/Concat_10_output_0)\n",
            "  %/regression_headers.5/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.3/extras.3.3/Relu_output_0, %regression_headers.5.weight, %regression_headers.5.bias)\n",
            "  %/Transpose_11_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.5/Conv_output_0)\n",
            "  %/Shape_11_output_0 = Shape(%/Transpose_11_output_0)\n",
            "  %/Constant_33_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_11_output_0 = Gather[axis = 0](%/Shape_11_output_0, %/Constant_33_output_0)\n",
            "  %onnx::Unsqueeze_451 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_11_output_0 = Unsqueeze(%/Gather_11_output_0, %onnx::Unsqueeze_451)\n",
            "  %/Constant_34_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_35_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_11_output_0 = Concat[axis = 0](%/Unsqueeze_11_output_0, %/Constant_34_output_0, %/Constant_35_output_0)\n",
            "  %/Reshape_11_output_0 = Reshape[allowzero = 0](%/Transpose_11_output_0, %/Concat_11_output_0)\n",
            "  %/Concat_12_output_0 = Concat[axis = 1](%/Reshape_output_0, %/Reshape_2_output_0, %/Reshape_4_output_0, %/Reshape_6_output_0, %/Reshape_8_output_0, %/Reshape_10_output_0)\n",
            "  %/Concat_13_output_0 = Concat[axis = 1](%/Reshape_1_output_0, %/Reshape_3_output_0, %/Reshape_5_output_0, %/Reshape_7_output_0, %/Reshape_9_output_0, %/Reshape_11_output_0)\n",
            "  %scores = Softmax[axis = 2](%/Concat_12_output_0)\n",
            "  %/Constant_36_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_37_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_38_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_39_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_output_0 = Slice(%/Concat_13_output_0, %/Constant_37_output_0, %/Constant_38_output_0, %/Constant_36_output_0, %/Constant_39_output_0)\n",
            "  %/Constant_40_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Mul_output_0 = Mul(%/Slice_output_0, %/Constant_40_output_0)\n",
            "  %/Constant_41_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Mul_1_output_0 = Mul(%/Mul_output_0, %/Constant_41_output_0)\n",
            "  %/Constant_42_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Add_output_0 = Add(%/Mul_1_output_0, %/Constant_42_output_0)\n",
            "  %/Constant_43_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_44_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_45_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_46_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_1_output_0 = Slice(%/Concat_13_output_0, %/Constant_44_output_0, %/Constant_45_output_0, %/Constant_43_output_0, %/Constant_46_output_0)\n",
            "  %/Constant_47_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Mul_2_output_0 = Mul(%/Slice_1_output_0, %/Constant_47_output_0)\n",
            "  %/Exp_output_0 = Exp(%/Mul_2_output_0)\n",
            "  %/Constant_48_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Mul_3_output_0 = Mul(%/Exp_output_0, %/Constant_48_output_0)\n",
            "  %/Concat_14_output_0 = Concat[axis = 2](%/Add_output_0, %/Mul_3_output_0)\n",
            "  %/Constant_49_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_50_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_51_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_52_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_2_output_0 = Slice(%/Concat_14_output_0, %/Constant_50_output_0, %/Constant_51_output_0, %/Constant_49_output_0, %/Constant_52_output_0)\n",
            "  %/Constant_53_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_54_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_55_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_56_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_3_output_0 = Slice(%/Concat_14_output_0, %/Constant_54_output_0, %/Constant_55_output_0, %/Constant_53_output_0, %/Constant_56_output_0)\n",
            "  %/Constant_57_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Div_output_0 = Div(%/Slice_3_output_0, %/Constant_57_output_0)\n",
            "  %/Sub_output_0 = Sub(%/Slice_2_output_0, %/Div_output_0)\n",
            "  %/Add_1_output_0 = Add(%/Slice_2_output_0, %/Div_output_0)\n",
            "  %boxes = Concat[axis = 2](%/Sub_output_0, %/Add_1_output_0)\n",
            "  return %scores, %boxes\n",
            "}\n",
            "output shape of ort (1, 3000, 3)\n",
            "output shape of torch (1, 3000, 3)\n",
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ]
        }
      ],
      "source": [
        "import onnx\n",
        "import onnxruntime\n",
        "\n",
        "onnx_model = onnx.load(model_onnx_path)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "print(onnx.helper.printable_graph(onnx_model.graph))\n",
        "ort_session = onnxruntime.InferenceSession(model_onnx_path)\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "\n",
        "# PyTorch output prediction\n",
        "torch_out = net(x)\n",
        "torch_out_np = [to_numpy(o) for o in torch_out]\n",
        "\n",
        "print(\"output shape of ort\", ort_outs[0].shape)\n",
        "print(\"output shape of torch\", torch_out_np[0].shape)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "np.testing.assert_allclose(torch_out_np[0], ort_outs[0], rtol=1e-02, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBIj0cijnwsc"
      },
      "source": [
        "output shape of ort (1, 3000, 3)\n",
        "\n",
        "output shape of torch (1, 3000, 3)\n",
        "\n",
        "Exported model has been tested with ONNXRuntime, and the result looks good!\n",
        "\n",
        "The precision used for matching is determined by the rtol and atol parameters:\n",
        "\n",
        "`rtol=1e-02`: This sets the relative tolerance to 1e-02, which is equivalent to 0.01 or 1%. It means that the relative difference between the corresponding elements of the two arrays should be within 1% of each other.\n",
        "\n",
        "`atol=1e-05`: This sets the absolute tolerance to 1e-05, which is equivalent to 0.00001. It means that the absolute difference between the corresponding elements of the two arrays should be within 0.00001.\n",
        "\n",
        "It uses `abs(a - b) <= atol + rtol * abs(b)` to calculate the difference between the two object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zWUqUbWNY05"
      },
      "source": [
        "### 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh6-bEHioNoR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "img_list = ['../data/open_images/train/0002f32727ed756e.jpg',\n",
        "              '../data/open_images/train/000305928f7b43da.jpg']\n",
        "\n",
        "\n",
        "\n",
        "for img_path in img_list:\n",
        "    img = Image.open(img_path)\n",
        "    img.show()\n",
        "\n",
        "    resize = transforms.Resize([224, 224])\n",
        "    img = resize(img)\n",
        "\n",
        "    img_ycbcr = img.convert('YCbCr')\n",
        "    img_y, img_cb, img_cr = img_ycbcr.split()\n",
        "\n",
        "    to_tensor = transforms.ToTensor()\n",
        "    img_y = to_tensor(img_y)\n",
        "    img_y.unsqueeze_(0)\n",
        "    \n",
        "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}\n",
        "    ort_outs = ort_session.run(None, ort_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLzyrGj8oeQO"
      },
      "outputs": [],
      "source": [
        "img_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L')\n",
        "\n",
        "# get the output image follow post-processing step from PyTorch implementation\n",
        "final_img = Image.merge(\n",
        "    \"YCbCr\", [\n",
        "        img_out_y,\n",
        "        img_cb.resize(img_out_y.size, Image.BICUBIC),\n",
        "        img_cr.resize(img_out_y.size, Image.BICUBIC),\n",
        "    ]).convert(\"RGB\")\n",
        "\n",
        "# Save the image\\\n",
        "final_img.save(\"cat_superres_with_ort.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StuHyld1NY05"
      },
      "source": [
        "## Problem 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTZWqxzCNY05"
      },
      "source": [
        "## Problem 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqkmYZ2oNY05"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
