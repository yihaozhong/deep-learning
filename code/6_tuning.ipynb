{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gcYGrUVNY0t"
      },
      "source": [
        "# Homework 6\n",
        "\n",
        "Yihao Zhong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRkGXVu6NY0v"
      },
      "source": [
        "## Problem 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEkWbOI-NY0v"
      },
      "source": [
        "### 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIiCuqHPNY0v"
      },
      "source": [
        "Model interpretability and explainability are important because they enable trust, transparency, and account for robustness for downstream users. Interpretable models allow downstream users to understand how predictions are made, facilitating debugging, improvement, and also compliance with regulations (equality, non-descriminatic etc). Explainability helps detect biases, uncover insights, and enhance user acceptance. Without interpretability, the decision-making process remains a \"black box,\" hindering trust and limiting the model's practical applicability in domains that require clear explanations, such as healthcare and finance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCTODwDHNY0v"
      },
      "source": [
        "### 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFPW9pXeNY0v"
      },
      "outputs": [],
      "source": [
        "!pip install autofeat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFmBM-I4NY0w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from autofeat import FeatureSelector, AutoFeatRegressor\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9hZUmRxNY0w",
        "outputId": "8971138a-a3e5-4525-f219-a2349bc7c047"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original number of features:  10\n"
          ]
        }
      ],
      "source": [
        "# Load the diabetes dataset and get the featues and target\n",
        "X, y = datasets.load_diabetes(return_X_y=True)\n",
        "\n",
        "print(\"Original number of features: \", X.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsEOLKbONY0w",
        "outputId": "97971961-1234-4419-ab99-35c9b696f8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[featsel] Scaling data..."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:15,434 INFO: [featsel] Feature selection run 1/5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:16,154 INFO: [featsel] Feature selection run 2/5\n",
            "2024-04-27 13:37:16,188 INFO: [featsel] Feature selection run 3/5\n",
            "2024-04-27 13:37:16,220 INFO: [featsel] Feature selection run 4/5\n",
            "2024-04-27 13:37:16,251 INFO: [featsel] Feature selection run 5/5\n",
            "2024-04-27 13:37:16,284 INFO: [featsel] 7 features after 5 feature selection runs\n",
            "/Users/zhongyihao/anaconda3/envs/trading/lib/python3.12/site-packages/autofeat/featsel.py:270: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
            "  if np.max(np.abs(correlations[c].ravel()[:i])) < 0.9:\n",
            "2024-04-27 13:37:16,286 INFO: [featsel] 7 features after correlation filtering\n",
            "2024-04-27 13:37:16,295 INFO: [featsel] 6 features after noise filtering\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New number of features:  6\n"
          ]
        }
      ],
      "source": [
        "fsel = FeatureSelector(verbose=1)\n",
        "\n",
        "# Fit it on the train dataset\n",
        "df = fsel.fit_transform(X, y)\n",
        "print(\"New number of features: \", df.shape[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEnyV2E4NY0x"
      },
      "source": [
        "Answer:\n",
        "\n",
        "There are 10 original features, and after features selection there are 6 features, the discarded features is 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOk8qahYNY0x"
      },
      "source": [
        "### 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_wJ924UNY0x",
        "outputId": "d37b5920-c7dc-4650-b8d2-2629186e606d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 score on the training set:  0.5279193863361498\n",
            "R2 score on the test set:  0.45260276297191915\n"
          ]
        }
      ],
      "source": [
        "# Perform a train-test split on your dataset. Select a regression model from skLearn and fit it to the\n",
        "# training dataset. What is the R2 score on the training and test set?\n",
        "\n",
        "# Perform a train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "rreg_model = LinearRegression()\n",
        "result_logistic = rreg_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"R2 score on the training set: \", result_logistic.score(X_train, y_train))\n",
        "print(\"R2 score on the test set: \", result_logistic.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMC9XteoNY0x"
      },
      "source": [
        "We perform a linear regression model. The $R^2$ for training set is 0.53, and the $R^2$ for testing set is 0.45."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srqCYZ3NNY0x"
      },
      "source": [
        "### 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5u30-iWNY0x",
        "outputId": "e296f8d6-e2e6-4f44-8114-a4fd47adc7aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:30,791 INFO: [AutoFeat] The 3 step feature engineering process could generate up to 60445 features.\n",
            "2024-04-27 13:37:30,792 INFO: [AutoFeat] With 353 data points this new feature matrix would use about 0.09 gb of space.\n",
            "2024-04-27 13:37:30,796 INFO: [feateng] Step 1: transformation of original features\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[feateng]               0/             10 features transformed\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:31,819 INFO: [feateng] Generated 45 transformed features from 10 original features - done.\n",
            "2024-04-27 13:37:31,824 INFO: [feateng] Step 2: first combination of features\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[feateng]            1400/           1485 feature tuples combined\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:33,274 INFO: [feateng] Generated 5789 feature combinations from 1485 original feature tuples - done.\n",
            "2024-04-27 13:37:33,279 INFO: [feateng] Step 3: transformation of new features\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[feateng]            5000/           5789 features transformed\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zhongyihao/anaconda3/envs/trading/lib/python3.12/site-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/Users/zhongyihao/anaconda3/envs/trading/lib/python3.12/site-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[feateng]            5600/           5789 features transformed\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:43,013 INFO: [feateng] Generated 24430 transformed features from 5789 original features - done.\n",
            "2024-04-27 13:37:43,053 INFO: [feateng] Generated altogether 32266 new features in 3 steps\n",
            "2024-04-27 13:37:43,053 INFO: [feateng] Removing correlated features, as well as additions at the highest level\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[feateng]            5700/           5789 features transformed\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:43,270 INFO: [feateng] Generated a total of 14871 additional features\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[featsel] Scaling data..."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:37:44,076 INFO: [featsel] Feature selection run 1/5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:38:28,567 INFO: [featsel] Feature selection run 2/5\n",
            "2024-04-27 13:39:09,195 INFO: [featsel] Feature selection run 3/5\n",
            "2024-04-27 13:39:38,424 INFO: [featsel] Feature selection run 4/5\n",
            "2024-04-27 13:40:33,087 INFO: [featsel] Feature selection run 5/5\n",
            "2024-04-27 13:41:01,473 INFO: [featsel] 36 features after 5 feature selection runs\n",
            "/Users/zhongyihao/anaconda3/envs/trading/lib/python3.12/site-packages/autofeat/featsel.py:270: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
            "  if np.max(np.abs(correlations[c].ravel()[:i])) < 0.9:\n",
            "2024-04-27 13:41:01,487 INFO: [featsel] 31 features after correlation filtering\n",
            "2024-04-27 13:41:01,685 INFO: [featsel] 11 features after noise filtering\n",
            "2024-04-27 13:41:01,705 INFO: [AutoFeat] Computing 11 new features.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[AutoFeat]     6/   11 new features\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-27 13:41:02,327 INFO: [AutoFeat]    11/   11 new features ...done.\n",
            "2024-04-27 13:41:02,335 INFO: [AutoFeat] Final dataframe with 21 feature columns (11 new).\n",
            "2024-04-27 13:41:02,335 INFO: [AutoFeat] Training final regression model.\n",
            "2024-04-27 13:41:02,344 INFO: [AutoFeat] Trained model: largest coefficients:\n",
            "2024-04-27 13:41:02,345 INFO: -70.30327923185092\n",
            "2024-04-27 13:41:02,345 INFO: 781094.306607 * x000**3*x001\n",
            "2024-04-27 13:41:02,346 INFO: -3983.086911 * exp(x006)*Abs(x001)\n",
            "2024-04-27 13:41:02,346 INFO: 362.715436 * exp(x002)*exp(x003)\n",
            "2024-04-27 13:41:02,347 INFO: 332.458747 * x000**9/x009**3\n",
            "2024-04-27 13:41:02,347 INFO: 215.883125 * Abs(x002 + Abs(x009))\n",
            "2024-04-27 13:41:02,347 INFO: 37.282823 * exp(x002)*exp(x008)\n",
            "2024-04-27 13:41:02,348 INFO: 24.680193 * Abs(x008)/x008\n",
            "2024-04-27 13:41:02,348 INFO: -4.397543 * x004**2*Abs(1/x003)\n",
            "2024-04-27 13:41:02,348 INFO: -0.854832 * x006/Abs(x002)\n",
            "2024-04-27 13:41:02,349 INFO: 0.037580 * 1/(x003**2 - x008)\n",
            "2024-04-27 13:41:02,349 INFO: -0.010361 * 1/(x008 - Abs(x009))\n",
            "2024-04-27 13:41:02,350 INFO: [AutoFeat] Final score: 0.6100\n",
            "2024-04-27 13:41:02,351 INFO: [AutoFeat] Computing 11 new features.\n",
            "2024-04-27 13:41:02,359 INFO: [AutoFeat]    11/   11 new features ...done.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Final Train R^2: 0.6224 features\n",
            "## Final Test R^2: 0.5172\n"
          ]
        }
      ],
      "source": [
        "# Instantiate an AutoFeatRegressor with 3 steps of feature engineering\n",
        "afreg = AutoFeatRegressor(verbose=1, feateng_steps=3)\n",
        "\n",
        "# Fit it on the train dataset\n",
        "X_train_afreg = afreg.fit_transform(X_train, y_train)\n",
        "X_test_afreg = afreg.transform(X_test)\n",
        "\n",
        "result_afreg = rreg_model.fit(X_train_afreg, y_train)\n",
        "\n",
        "print(\"## Final Train R^2: %.4f\" % result_afreg.score(X_train_afreg, y_train))\n",
        "print(\"## Final Test R^2: %.4f\" %  result_afreg.score(X_test_afreg, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvwy-5DcNY0y",
        "outputId": "9b5bc0a7-623b-4d76-cb12-9f9d458eec61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New Features:  {'x001', 'x004**2*Abs(1/x003)', 'x003', 'x006/Abs(x002)', 'Abs(x008)/x008', 'x004', 'x002', 'exp(x006)*Abs(x001)', 'x000**9/x009**3', 'exp(x002)*exp(x003)', 'Abs(x002 + Abs(x009))', 'x008', 'x009', '1/(x008 - Abs(x009))', 'x005', 'x000', 'x000**3*x001', 'x007', '1/(x003**2 - x008)', 'exp(x002)*exp(x008)', 'x006'}\n",
            "Original Features:  ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
          ]
        }
      ],
      "source": [
        "print(\"New Features: \", set(X_train_afreg.columns))\n",
        "print(\"Original Features: \", datasets.load_diabetes().feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z90Er1k6NY0y"
      },
      "source": [
        "The $R^2$ score on the train data is 0.62, increased by 17%. The $R^2$ score on the test data is 0.45, increased by 14.3%. The performance improve after we use the Autofeat, which introduce more features and hence more complexity and non-linearity to the regression model.\n",
        "\n",
        "Five new features are 'x004**2*Abs(1/x003)', 'x006/Abs(x002)', 'Abs(x008)/x008', 'exp(x006)*Abs(x001)', 'exp(x002)*exp(x003)'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrzVeprdNY0y"
      },
      "source": [
        "## Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-DAMb7vNY0y"
      },
      "source": [
        "### 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GZ7GKpJtNY0y"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import datasets, neighbors, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import uniform\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ViVJ4XvhNY0y"
      },
      "outputs": [],
      "source": [
        "X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
        "X_digits = X_digits / X_digits.max()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits,\n",
        "                                                    test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"pydantic<2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUuFAee74csL",
        "outputId": "f2898cbe-bfd8-444f-f12c-ed46b93cc720"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (1.10.15)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2) (4.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ray[tune]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAXRd8B_4hM4",
        "outputId": "c77a6562-a157-458a-f9ac-c0c5f688cacd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray[tune]\n",
            "  Downloading ray-2.20.0-cp310-cp310-manylinux2014_x86_64.whl (65.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.13.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (24.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.0.3)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (14.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2023.6.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow>=6.0.1->ray[tune]) (1.25.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.16.0)\n",
            "Installing collected packages: tensorboardX, ray\n",
            "Successfully installed ray-2.20.0 tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "from ray import tune\n",
        "from ray.tune.integration.keras import TuneReportCallback"
      ],
      "metadata": {
        "id": "TiQ6FaeW-PQE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"pydantic<2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU--JYCO_ZB3",
        "outputId": "598dd11e-86d6-43b1-d70a-23f328ec2a97"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (1.10.15)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2) (4.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zQmghYiJNY0y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from ray.tune.integration.keras import TuneReportCallback\n",
        "from ray import train\n",
        "from ray.air import session\n",
        "\n",
        "# Define the Lenet Model\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_filters, dropout_prob):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, num_filters, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(num_filters, 50, kernel_size=5)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.fc1 = nn.Linear(800, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 800)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train_mnist(config):\n",
        "    num_epochs = 5\n",
        "    num_classes = 10\n",
        "    #device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Load and transform the MNIST dataset\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "    test_dataset = MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=int(config[\"batch_size\"]), shuffle=True)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=int(config[\"batch_size\"]), shuffle=False)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # Initialize the model\n",
        "    model = LeNet(num_filters=int(config[\"filters\"]), dropout_prob=config[\"dropout\"]).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                outputs = model(data)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += target.size(0)\n",
        "                correct += (predicted == target).sum().item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Accuracy: {accuracy}\")\n",
        "\n",
        "        # Tune report callback\n",
        "        train.report(metrics={\"accuracy\": accuracy})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ray.shutdown()\n",
        "ray.init(log_to_driver=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "SS8t1b3agQ6d",
        "outputId": "e9ae569d-867c-473c-dae2-fdda03b0e2eb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-05-02 01:20:55,226\tINFO worker.py:1749 -- Started a local Ray instance.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RayContext(dashboard_url='', python_version='3.10.12', ray_version='2.20.0', ray_commit='5708e75978413e46c703e44f43fd89769f3c148b')"
            ],
            "text/html": [
              "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
              "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
              "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
              "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
              "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
              "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
              "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
              "    </g>\n",
              "    <defs>\n",
              "        <clipPath id=\"clip0_4338_178347\">\n",
              "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
              "        </clipPath>\n",
              "    </defs>\n",
              "  </svg>\n",
              "</div>\n",
              "\n",
              "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
              "    <tr>\n",
              "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
              "        <td style=\"text-align: left\"><b>3.10.12</b></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
              "        <td style=\"text-align: left\"><b>2.20.0</b></td>\n",
              "    </tr>\n",
              "    \n",
              "</table>\n",
              "\n",
              "    </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import HyperBandScheduler\n",
        "from ray.tune.search.bayesopt import BayesOptSearch\n"
      ],
      "metadata": {
        "id": "oEM-LUDo4y4L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "# Define the search space for hyperparameters\n",
        "search_space = {\n",
        "    \"filters\": tune.choice([64, 128, 256]),\n",
        "    \"lr\": tune.choice([0.001, 0.01, 0.1]),\n",
        "    \"batch_size\": tune.choice([64, 128, 256]),\n",
        "    \"dropout\": tune.uniform(0, 1),\n",
        "}\n",
        "\n",
        "# Set up Ray Tune\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "# Grid search setup\n",
        "grid_search_analysis = tune.run(\n",
        "    train_mnist,\n",
        "    num_samples=6,\n",
        "    config=search_space,\n",
        "    scheduler=None,  # No scheduler needed for grid search\n",
        "    verbose=1,\n",
        "     resources_per_trial={\"cpu\": 12, \"gpu\": 1}\n",
        ")\n",
        "end_time = time.time()\n",
        "print(\"Time taken for grid search:\", end_time - start_time)\n",
        "\n",
        "\n",
        "\n",
        "# Printing best hyperparameters\n",
        "print(\"Best hyperparameters from Grid Search:\", grid_search_analysis.get_best_config(metric=\"accuracy\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "ydmuW433-rjl",
        "outputId": "a8932cdc-4076-42d8-e5b8-84812448e502"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2024-05-01 00:32:30</td></tr>\n",
              "<tr><td>Running for: </td><td>00:16:59.50        </td></tr>\n",
              "<tr><td>Memory:      </td><td>4.6/83.5 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/49.66 GiB heap, 0.0/24.83 GiB objects (0.0/1.0 accelerator_type:A100)\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  filters</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">      loss</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_ebc86_00000</td><td>TERMINATED</td><td>172.28.0.12:23397</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.421286 </td><td style=\"text-align: right;\">      256</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        135.678 </td><td style=\"text-align: right;\">    0.101 </td><td style=\"text-align: right;\">2.2993    </td></tr>\n",
              "<tr><td>train_mnist_ebc86_00001</td><td>TERMINATED</td><td>172.28.0.12:24066</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.368892 </td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        142.187 </td><td style=\"text-align: right;\">    0.9924</td><td style=\"text-align: right;\">0.00704339</td></tr>\n",
              "<tr><td>train_mnist_ebc86_00002</td><td>TERMINATED</td><td>172.28.0.12:24764</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.220018 </td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        102.403 </td><td style=\"text-align: right;\">    0.9904</td><td style=\"text-align: right;\">0.00423376</td></tr>\n",
              "<tr><td>train_mnist_ebc86_00003</td><td>TERMINATED</td><td>172.28.0.12:25288</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.0292552</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         86.1311</td><td style=\"text-align: right;\">    0.9909</td><td style=\"text-align: right;\">0.00310266</td></tr>\n",
              "<tr><td>train_mnist_ebc86_00004</td><td>TERMINATED</td><td>172.28.0.12:25741</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.516196 </td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        433.906 </td><td style=\"text-align: right;\">    0.993 </td><td style=\"text-align: right;\">0.0504564 </td></tr>\n",
              "<tr><td>train_mnist_ebc86_00005</td><td>TERMINATED</td><td>172.28.0.12:27681</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.194319 </td><td style=\"text-align: right;\">      256</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         90.0912</td><td style=\"text-align: right;\">    0.1135</td><td style=\"text-align: right;\">2.32977   </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-05-01 00:32:30,743\tINFO tune.py:762 -- Total run time: 1019.62 seconds (1019.49 seconds for the tuning loop).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for grid search: 1019.6484160423279\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No `mode` has been passed and  `default_mode` has not been set. Please specify the `mode` parameter.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3a2439c2632a>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Printing best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best hyperparameters from Grid Search:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_search_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/analysis/experiment_analysis.py\u001b[0m in \u001b[0;36mget_best_config\u001b[0;34m(self, metric, mode, scope)\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompare\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \"\"\"\n\u001b[0;32m--> 662\u001b[0;31m         \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbest_trial\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/analysis/experiment_analysis.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscope\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"all\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last-5-avg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last-10-avg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/analysis/experiment_analysis.py\u001b[0m in \u001b[0;36m_validate_mode\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    839\u001b[0m                 \u001b[0;34m\"No `mode` has been passed and  `default_mode` has \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                 \u001b[0;34m\"not been set. Please specify the `mode` parameter.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No `mode` has been passed and  `default_mode` has not been set. Please specify the `mode` parameter."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best hyperparameters from Grid Search:\",\n",
        "      grid_search_analysis.get_best_config(\"accuracy\", \"max\", \"last\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF7BHPpEHL8j",
        "outputId": "f8672853-2c0b-48d2-b71f-51e731f26b05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters from Grid Search: {'filters': 64, 'lr': 0.001, 'batch_size': 128, 'dropout': 0.5161961869143823}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "! pip install \"hyperopt==0.2.7\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcnVrWDr48l_",
        "outputId": "1dfe16a1-1db5-4871-ce73-d328fd5c33d1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt==0.2.7 in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (4.66.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bayesian-optimization==1.4.3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6PRCYns23eq",
        "outputId": "c7813929-92fa-411c-b6ed-4b7c1e016cef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesian-optimization==1.4.3\n",
            "  Downloading bayesian_optimization-1.4.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization==1.4.3) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization==1.4.3) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization==1.4.3) (1.2.2)\n",
            "Collecting colorama>=0.4.6 (from bayesian-optimization==1.4.3)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.3) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.3) (3.4.0)\n",
            "Installing collected packages: colorama, bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.4.3 colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ray.tune.search.bayesopt import BayesOptSearch\n",
        "import bayes_opt"
      ],
      "metadata": {
        "id": "bLZmmiv03Ad4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Be53kXgnNY0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d7d603-413a-47b8-923a-83aecac19f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-05-02 01:20:57,639\tWARNING bayesopt_search.py:431 -- BayesOpt does not support specific sampling methods. The LogUniform sampler will be dropped.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     train_mnist_2024-05-02_01-20-57   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator                   |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 8                                 |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/train_mnist_2024-05-02_01-20-57\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-05-02_01-20-53_244041_927/artifacts/2024-05-02_01-20-57/train_mnist_2024-05-02_01-20-57/driver_artifacts`\n",
            "\n",
            "Trial status: 1 PENDING\n",
            "Current time: 2024-05-02 01:20:57. Total running time: 0s\n",
            "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   PENDING      204.543   0.059906        135.912    0.950714 |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_30b6dcd8 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_30b6dcd8 config             |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                            135.912 |\n",
            "| dropout                               0.95071 |\n",
            "| filters                               204.543 |\n",
            "| lr                                    0.05991 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:21:27. Total running time: 30s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   RUNNING     204.543    0.059906       135.912     0.950714 |\n",
            "| train_mnist_a04e5548   PENDING      75.1521   0.086631        93.9556    0.155995 |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:21:57. Total running time: 1min 0s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   RUNNING     204.543    0.059906       135.912     0.950714 |\n",
            "| train_mnist_a04e5548   PENDING      75.1521   0.086631        93.9556    0.155995 |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:22:27. Total running time: 1min 30s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   RUNNING     204.543    0.059906       135.912     0.950714 |\n",
            "| train_mnist_a04e5548   PENDING      75.1521   0.086631        93.9556    0.155995 |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:22:58. Total running time: 2min 0s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   RUNNING     204.543    0.059906       135.912     0.950714 |\n",
            "| train_mnist_a04e5548   PENDING      75.1521   0.086631        93.9556    0.155995 |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:23:28. Total running time: 2min 30s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   RUNNING     204.543    0.059906       135.912     0.950714 |\n",
            "| train_mnist_a04e5548   PENDING      75.1521   0.086631        93.9556    0.155995 |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:23:58. Total running time: 3min 0s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   RUNNING     204.543    0.059906       135.912     0.950714 |\n",
            "| train_mnist_a04e5548   PENDING      75.1521   0.086631        93.9556    0.155995 |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:24:28. Total running time: 3min 30s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   RUNNING     204.543    0.059906       135.912     0.950714 |\n",
            "| train_mnist_a04e5548   PENDING      75.1521   0.086631        93.9556    0.155995 |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:24:58. Total running time: 4min 0s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   RUNNING     204.543    0.059906       135.912     0.950714 |\n",
            "| train_mnist_a04e5548   PENDING      75.1521   0.086631        93.9556    0.155995 |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:25:28. Total running time: 4min 30s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   RUNNING     204.543    0.059906       135.912     0.950714 |\n",
            "| train_mnist_a04e5548   PENDING      75.1521   0.086631        93.9556    0.155995 |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:25:58. Total running time: 5min 0s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   RUNNING     204.543    0.059906       135.912     0.950714 |\n",
            "| train_mnist_a04e5548   PENDING      75.1521   0.086631        93.9556    0.155995 |\n",
            "+-----------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:26:28. Total running time: 5min 30s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+----------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+----------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   RUNNING     204.543    0.059906       135.912     0.950714        1             317.86       0.1028 |\n",
            "| train_mnist_a04e5548   PENDING      75.1521   0.086631        93.9556    0.155995                                          |\n",
            "+----------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:26:58. Total running time: 6min 1s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+----------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status       filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+----------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   RUNNING     204.543    0.059906       135.912     0.950714        3            347.491       0.1009 |\n",
            "| train_mnist_a04e5548   PENDING      75.1521   0.086631        93.9556    0.155995                                          |\n",
            "+----------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_30b6dcd8 completed after 5 iterations at 2024-05-02 01:27:19. Total running time: 6min 22s\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_30b6dcd8 result             |\n",
            "+-----------------------------------------------+\n",
            "| checkpoint_dir_name                           |\n",
            "| time_this_iter_s                      15.2221 |\n",
            "| time_total_s                          377.637 |\n",
            "| training_iteration                          5 |\n",
            "| accuracy                               0.1135 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial train_mnist_a04e5548 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_a04e5548 config             |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                            93.9556 |\n",
            "| dropout                               0.15599 |\n",
            "| filters                               75.1521 |\n",
            "| lr                                    0.08663 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:27:28. Total running time: 6min 31s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:27:58. Total running time: 7min 1s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:28:28. Total running time: 7min 31s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:28:58. Total running time: 8min 1s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:29:29. Total running time: 8min 31s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:29:59. Total running time: 9min 1s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:30:29. Total running time: 9min 31s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:30:59. Total running time: 10min 1s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:31:29. Total running time: 10min 31s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:31:59. Total running time: 11min 1s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:32:29. Total running time: 11min 31s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:32:59. Total running time: 12min 1s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995        1            319.59        0.1135 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:33:29. Total running time: 12min 31s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters         lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_a04e5548   RUNNING        75.1521   0.086631        93.9556    0.155995        3            350.214       0.1135 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906       135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_02877374   PENDING        67.9522   0.096994       179.414     0.708073                                          |\n",
            "+------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_a04e5548 completed after 5 iterations at 2024-05-02 01:33:45. Total running time: 12min 48s\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_a04e5548 result             |\n",
            "+-----------------------------------------------+\n",
            "| checkpoint_dir_name                           |\n",
            "| time_this_iter_s                      15.3661 |\n",
            "| time_total_s                          380.885 |\n",
            "| training_iteration                          5 |\n",
            "| accuracy                               0.1135 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial train_mnist_02877374 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_02877374 config             |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                            179.414 |\n",
            "| dropout                               0.70807 |\n",
            "| filters                               67.9522 |\n",
            "| lr                                    0.09699 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:33:59. Total running time: 13min 1s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_02877374   RUNNING        67.9522   0.096994        179.414     0.708073                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5            377.637       0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5            380.885       0.1135 |\n",
            "| train_mnist_bc3b8c5a   PENDING        98.9104   0.0184221       223.829     0.212339                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:34:29. Total running time: 13min 32s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_02877374   RUNNING        67.9522   0.096994        179.414     0.708073        2            31.2894       0.1028 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5           380.885        0.1135 |\n",
            "| train_mnist_bc3b8c5a   PENDING        98.9104   0.0184221       223.829     0.212339                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:34:59. Total running time: 14min 2s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_02877374   RUNNING        67.9522   0.096994        179.414     0.708073        4            60.2602       0.1028 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5           380.885        0.1135 |\n",
            "| train_mnist_bc3b8c5a   PENDING        98.9104   0.0184221       223.829     0.212339                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_02877374 completed after 5 iterations at 2024-05-02 01:35:05. Total running time: 14min 8s\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_02877374 result             |\n",
            "+-----------------------------------------------+\n",
            "| checkpoint_dir_name                           |\n",
            "| time_this_iter_s                      14.4323 |\n",
            "| time_total_s                          74.6925 |\n",
            "| training_iteration                          5 |\n",
            "| accuracy                               0.1028 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial train_mnist_bc3b8c5a started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_bc3b8c5a config             |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                            223.829 |\n",
            "| dropout                               0.21234 |\n",
            "| filters                               98.9104 |\n",
            "| lr                                    0.01842 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:35:29. Total running time: 14min 32s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_bc3b8c5a   RUNNING        98.9104   0.0184221       223.829     0.212339                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414     0.708073        5            74.6925       0.1028 |\n",
            "| train_mnist_790a33ee   PENDING       146.933    0.0291938       122.415     0.524756                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:35:59. Total running time: 15min 2s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_bc3b8c5a   RUNNING        98.9104   0.0184221       223.829     0.212339                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414     0.708073        5            74.6925       0.1028 |\n",
            "| train_mnist_790a33ee   PENDING       146.933    0.0291938       122.415     0.524756                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:36:30. Total running time: 15min 32s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_bc3b8c5a   RUNNING        98.9104   0.0184221       223.829     0.212339        1            66.0047       0.1135 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414     0.708073        5            74.6925       0.1028 |\n",
            "| train_mnist_790a33ee   PENDING       146.933    0.0291938       122.415     0.524756                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:37:00. Total running time: 16min 2s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_bc3b8c5a   RUNNING        98.9104   0.0184221       223.829     0.212339        4           108.789        0.1135 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414     0.708073        5            74.6925       0.1028 |\n",
            "| train_mnist_790a33ee   PENDING       146.933    0.0291938       122.415     0.524756                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_bc3b8c5a completed after 5 iterations at 2024-05-02 01:37:14. Total running time: 16min 16s\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_bc3b8c5a result             |\n",
            "+-----------------------------------------------+\n",
            "| checkpoint_dir_name                           |\n",
            "| time_this_iter_s                      14.3457 |\n",
            "| time_total_s                          123.135 |\n",
            "| training_iteration                          5 |\n",
            "| accuracy                               0.1135 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial train_mnist_790a33ee started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_790a33ee config             |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                            122.415 |\n",
            "| dropout                               0.52476 |\n",
            "| filters                               146.933 |\n",
            "| lr                                    0.02919 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:37:30. Total running time: 16min 32s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_790a33ee   RUNNING       146.933    0.0291938       122.415     0.524756                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414     0.708073        5            74.6925       0.1028 |\n",
            "| train_mnist_bc3b8c5a   TERMINATED     98.9104   0.0184221       223.829     0.212339        5           123.135        0.1135 |\n",
            "| train_mnist_56660d38   PENDING       120.092    0.0366995       181.476     0.139494                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:38:00. Total running time: 17min 2s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_790a33ee   RUNNING       146.933    0.0291938       122.415     0.524756        2            33.4884       0.1135 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414     0.708073        5            74.6925       0.1028 |\n",
            "| train_mnist_bc3b8c5a   TERMINATED     98.9104   0.0184221       223.829     0.212339        5           123.135        0.1135 |\n",
            "| train_mnist_56660d38   PENDING       120.092    0.0366995       181.476     0.139494                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:38:30. Total running time: 17min 32s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_790a33ee   RUNNING       146.933    0.0291938       122.415     0.524756        4            63.2957       0.1135 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414     0.708073        5            74.6925       0.1028 |\n",
            "| train_mnist_bc3b8c5a   TERMINATED     98.9104   0.0184221       223.829     0.212339        5           123.135        0.1135 |\n",
            "| train_mnist_56660d38   PENDING       120.092    0.0366995       181.476     0.139494                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_790a33ee completed after 5 iterations at 2024-05-02 01:38:37. Total running time: 17min 39s\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_790a33ee result             |\n",
            "+-----------------------------------------------+\n",
            "| checkpoint_dir_name                           |\n",
            "| time_this_iter_s                      14.9304 |\n",
            "| time_total_s                          78.2261 |\n",
            "| training_iteration                          5 |\n",
            "| accuracy                               0.1135 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial train_mnist_56660d38 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_56660d38 config             |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                            181.476 |\n",
            "| dropout                               0.13949 |\n",
            "| filters                               120.092 |\n",
            "| lr                                     0.0367 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial status: 5 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:39:00. Total running time: 18min 2s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_56660d38   RUNNING       120.092    0.0366995       181.476     0.139494        1            16.9402       0.101  |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414     0.708073        5            74.6925       0.1028 |\n",
            "| train_mnist_bc3b8c5a   TERMINATED     98.9104   0.0184221       223.829     0.212339        5           123.135        0.1135 |\n",
            "| train_mnist_790a33ee   TERMINATED    146.933    0.0291938       122.415     0.524756        5            78.226        0.1135 |\n",
            "| train_mnist_02cf6146   PENDING       102.337    0.051472        151.565     0.785176                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 5 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:39:30. Total running time: 18min 32s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_56660d38   RUNNING       120.092    0.0366995       181.476     0.139494        3            45.9437       0.1135 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414     0.708073        5            74.6925       0.1028 |\n",
            "| train_mnist_bc3b8c5a   TERMINATED     98.9104   0.0184221       223.829     0.212339        5           123.135        0.1135 |\n",
            "| train_mnist_790a33ee   TERMINATED    146.933    0.0291938       122.415     0.524756        5            78.226        0.1135 |\n",
            "| train_mnist_02cf6146   PENDING       102.337    0.051472        151.565     0.785176                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_56660d38 completed after 5 iterations at 2024-05-02 01:39:56. Total running time: 18min 59s\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_56660d38 result             |\n",
            "+-----------------------------------------------+\n",
            "| checkpoint_dir_name                           |\n",
            "| time_this_iter_s                      14.4753 |\n",
            "| time_total_s                          74.9343 |\n",
            "| training_iteration                          5 |\n",
            "| accuracy                               0.1135 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial status: 6 TERMINATED | 1 PENDING\n",
            "Current time: 2024-05-02 01:40:00. Total running time: 19min 2s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912     0.950714        5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556    0.155995        5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414     0.708073        5            74.6925       0.1028 |\n",
            "| train_mnist_bc3b8c5a   TERMINATED     98.9104   0.0184221       223.829     0.212339        5           123.135        0.1135 |\n",
            "| train_mnist_790a33ee   TERMINATED    146.933    0.0291938       122.415     0.524756        5            78.226        0.1135 |\n",
            "| train_mnist_56660d38   TERMINATED    120.092    0.0366995       181.476     0.139494        5            74.9343       0.1135 |\n",
            "| train_mnist_02cf6146   PENDING       102.337    0.051472        151.565     0.785176                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_02cf6146 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_02cf6146 config             |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                            151.565 |\n",
            "| dropout                               0.78518 |\n",
            "| filters                               102.337 |\n",
            "| lr                                    0.05147 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial status: 6 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:40:30. Total running time: 19min 32s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_02cf6146   RUNNING       102.337    0.051472        151.565    0.785176         1            17.1773       0.1135 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912    0.950714         5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556   0.155995         5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414    0.708073         5            74.6925       0.1028 |\n",
            "| train_mnist_bc3b8c5a   TERMINATED     98.9104   0.0184221       223.829    0.212339         5           123.135        0.1135 |\n",
            "| train_mnist_790a33ee   TERMINATED    146.933    0.0291938       122.415    0.524756         5            78.226        0.1135 |\n",
            "| train_mnist_56660d38   TERMINATED    120.092    0.0366995       181.476    0.139494         5            74.9343       0.1135 |\n",
            "| train_mnist_6fd9a37e   PENDING       180.649    0.0171354       177.744    0.0464504                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 6 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 01:41:00. Total running time: 20min 2s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_02cf6146   RUNNING       102.337    0.051472        151.565    0.785176         3            46.5787       0.1135 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912    0.950714         5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556   0.155995         5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414    0.708073         5            74.6925       0.1028 |\n",
            "| train_mnist_bc3b8c5a   TERMINATED     98.9104   0.0184221       223.829    0.212339         5           123.135        0.1135 |\n",
            "| train_mnist_790a33ee   TERMINATED    146.933    0.0291938       122.415    0.524756         5            78.226        0.1135 |\n",
            "| train_mnist_56660d38   TERMINATED    120.092    0.0366995       181.476    0.139494         5            74.9343       0.1135 |\n",
            "| train_mnist_6fd9a37e   PENDING       180.649    0.0171354       177.744    0.0464504                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_02cf6146 completed after 5 iterations at 2024-05-02 01:41:17. Total running time: 20min 20s\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_02cf6146 result             |\n",
            "+-----------------------------------------------+\n",
            "| checkpoint_dir_name                           |\n",
            "| time_this_iter_s                      14.6154 |\n",
            "| time_total_s                           75.784 |\n",
            "| training_iteration                          5 |\n",
            "| accuracy                               0.1028 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial train_mnist_6fd9a37e started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_6fd9a37e config             |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                            177.744 |\n",
            "| dropout                               0.04645 |\n",
            "| filters                               180.649 |\n",
            "| lr                                    0.01714 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial status: 7 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-05-02 01:41:30. Total running time: 20min 32s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_6fd9a37e   RUNNING       180.649    0.0171354       177.744    0.0464504                                          |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912    0.950714         5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556   0.155995         5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414    0.708073         5            74.6925       0.1028 |\n",
            "| train_mnist_bc3b8c5a   TERMINATED     98.9104   0.0184221       223.829    0.212339         5           123.135        0.1135 |\n",
            "| train_mnist_790a33ee   TERMINATED    146.933    0.0291938       122.415    0.524756         5            78.226        0.1135 |\n",
            "| train_mnist_56660d38   TERMINATED    120.092    0.0366995       181.476    0.139494         5            74.9343       0.1135 |\n",
            "| train_mnist_02cf6146   TERMINATED    102.337    0.051472        151.565    0.785176         5            75.784        0.1028 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-05-02 01:42:00. Total running time: 21min 2s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_6fd9a37e   RUNNING       180.649    0.0171354       177.744    0.0464504        2            31.1749       0.1135 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912    0.950714         5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556   0.155995         5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414    0.708073         5            74.6925       0.1028 |\n",
            "| train_mnist_bc3b8c5a   TERMINATED     98.9104   0.0184221       223.829    0.212339         5           123.135        0.1135 |\n",
            "| train_mnist_790a33ee   TERMINATED    146.933    0.0291938       122.415    0.524756         5            78.226        0.1135 |\n",
            "| train_mnist_56660d38   TERMINATED    120.092    0.0366995       181.476    0.139494         5            74.9343       0.1135 |\n",
            "| train_mnist_02cf6146   TERMINATED    102.337    0.051472        151.565    0.785176         5            75.784        0.1028 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-05-02 01:42:30. Total running time: 21min 32s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_6fd9a37e   RUNNING       180.649    0.0171354       177.744    0.0464504        4            60.0856       0.1135 |\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912    0.950714         5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556   0.155995         5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414    0.708073         5            74.6925       0.1028 |\n",
            "| train_mnist_bc3b8c5a   TERMINATED     98.9104   0.0184221       223.829    0.212339         5           123.135        0.1135 |\n",
            "| train_mnist_790a33ee   TERMINATED    146.933    0.0291938       122.415    0.524756         5            78.226        0.1135 |\n",
            "| train_mnist_56660d38   TERMINATED    120.092    0.0366995       181.476    0.139494         5            74.9343       0.1135 |\n",
            "| train_mnist_02cf6146   TERMINATED    102.337    0.051472        151.565    0.785176         5            75.784        0.1028 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-05-02 01:42:37,621\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n",
            "You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n",
            "You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n",
            "2024-05-02 01:42:37,623\tINFO tune.py:1007 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_mnist_2024-05-02_01-20-57' in 0.0063s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_mnist_6fd9a37e completed after 5 iterations at 2024-05-02 01:42:37. Total running time: 21min 39s\n",
            "+-----------------------------------------------+\n",
            "| Trial train_mnist_6fd9a37e result             |\n",
            "+-----------------------------------------------+\n",
            "| checkpoint_dir_name                           |\n",
            "| time_this_iter_s                      14.4848 |\n",
            "| time_total_s                          74.5704 |\n",
            "| training_iteration                          5 |\n",
            "| accuracy                               0.1135 |\n",
            "+-----------------------------------------------+\n",
            "\n",
            "Trial status: 8 TERMINATED\n",
            "Current time: 2024-05-02 01:42:37. Total running time: 21min 39s\n",
            "Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name             status         filters          lr     batch_size     dropout     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_30b6dcd8   TERMINATED    204.543    0.059906        135.912    0.950714         5           377.637        0.1135 |\n",
            "| train_mnist_a04e5548   TERMINATED     75.1521   0.086631         93.9556   0.155995         5           380.885        0.1135 |\n",
            "| train_mnist_02877374   TERMINATED     67.9522   0.096994        179.414    0.708073         5            74.6925       0.1028 |\n",
            "| train_mnist_bc3b8c5a   TERMINATED     98.9104   0.0184221       223.829    0.212339         5           123.135        0.1135 |\n",
            "| train_mnist_790a33ee   TERMINATED    146.933    0.0291938       122.415    0.524756         5            78.226        0.1135 |\n",
            "| train_mnist_56660d38   TERMINATED    120.092    0.0366995       181.476    0.139494         5            74.9343       0.1135 |\n",
            "| train_mnist_02cf6146   TERMINATED    102.337    0.051472        151.565    0.785176         5            75.784        0.1028 |\n",
            "| train_mnist_6fd9a37e   TERMINATED    180.649    0.0171354       177.744    0.0464504        5            74.5704       0.1135 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Time taken for Bayesian Search: 1300.0236146450043\n",
            "Best hyperparameters from Bayesian Search: {'filters': 204.54283682778978, 'lr': 0.05990598257128396, 'batch_size': 135.91170281869358, 'dropout': 0.9507143064099162}\n"
          ]
        }
      ],
      "source": [
        "# Bayesian search setup\n",
        "import time\n",
        "bayes_search_space = {\n",
        "   \"filters\": tune.uniform(64, 256),\n",
        "   \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "   \"batch_size\": tune.uniform(64, 256),\n",
        "   \"dropout\": tune.uniform(0, 1)\n",
        "}\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "bayesopt_search = BayesOptSearch(metric=\"accuracy\", mode=\"max\")\n",
        "bayesian_search_analysis = tune.run(\n",
        "    train_mnist,\n",
        "    num_samples=8,\n",
        "    config=bayes_search_space,\n",
        "    search_alg=bayesopt_search,\n",
        "    verbose=1,\n",
        "    resources_per_trial={\"cpu\": 12, \"gpu\": 1}\n",
        ")\n",
        "end_time = time.time()\n",
        "print(\"Time taken for Bayesian Search:\", end_time - start_time)\n",
        "print(\"Best hyperparameters from Bayesian Search:\", bayesian_search_analysis.get_best_config(\"accuracy\", \"max\", \"last\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time taken for Bayesian Search: 1300.0236146450043\n",
        "\n",
        "Best hyperparameters from Bayesian Search: {'filters': 204.54283682778978, 'lr': 0.05990598257128396, 'batch_size': 135.91170281869358, 'dropout': 0.9507143064099162}"
      ],
      "metadata": {
        "id": "rGny12TE_nOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# time it\n",
        "start_time = time.time()\n",
        "# Hyperband setup\n",
        "hyperband_scheduler = HyperBandScheduler(metric=\"accuracy\", mode=\"max\")\n",
        "hyperband_analysis = tune.run(\n",
        "    train_mnist,\n",
        "    num_samples=8,\n",
        "    config=search_space,\n",
        "    scheduler=hyperband_scheduler,\n",
        "    verbose=1,\n",
        "    resources_per_trial={\"cpu\": 12, \"gpu\": 1}\n",
        ")\n",
        "end_time = time.time()\n",
        "print(\"Time taken for Hyperband:\", end_time - start_time)\n",
        "print(\"Best hyperparameters from Hyperband:\", hyperband_analysis.get_best_config(\"accuracy\", \"max\", \"last\"))\n",
        "ray.shutdown()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "Q_Fvd74SDUWp",
        "outputId": "a00fbcb4-0023-4414-9a60-dcb9ec695574"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2024-05-01 01:17:07</td></tr>\n",
              "<tr><td>Running for: </td><td>00:25:18.41        </td></tr>\n",
              "<tr><td>Memory:      </td><td>4.7/83.5 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using HyperBand: num_stopped=0 total_brackets=2<br>Round #0:<br>  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} <br>  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 3} <br>Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/49.66 GiB heap, 0.0/24.83 GiB objects (0.0/1.0 accelerator_type:A100)\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  filters</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">     loss</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_fdea0_00000</td><td>TERMINATED</td><td>172.28.0.12:33902</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.364006 </td><td style=\"text-align: right;\">      256</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        429.04  </td><td style=\"text-align: right;\">    0.1135</td><td style=\"text-align: right;\">2.30214  </td></tr>\n",
              "<tr><td>train_mnist_fdea0_00001</td><td>TERMINATED</td><td>172.28.0.12:36321</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.80248  </td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         89.8216</td><td style=\"text-align: right;\">    0.9525</td><td style=\"text-align: right;\">0.302565 </td></tr>\n",
              "<tr><td>train_mnist_fdea0_00002</td><td>TERMINATED</td><td>172.28.0.12:37468</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.520865 </td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        100.223 </td><td style=\"text-align: right;\">    0.0958</td><td style=\"text-align: right;\">2.31089  </td></tr>\n",
              "<tr><td>train_mnist_fdea0_00003</td><td>TERMINATED</td><td>172.28.0.12:38488</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.484386 </td><td style=\"text-align: right;\">      256</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        109.158 </td><td style=\"text-align: right;\">    0.1135</td><td style=\"text-align: right;\">2.30709  </td></tr>\n",
              "<tr><td>train_mnist_fdea0_00004</td><td>TERMINATED</td><td>172.28.0.12:39043</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.0794718</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        426.727 </td><td style=\"text-align: right;\">    0.9908</td><td style=\"text-align: right;\">0.0563973</td></tr>\n",
              "<tr><td>train_mnist_fdea0_00005</td><td>TERMINATED</td><td>172.28.0.12:35831</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.142433 </td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         94.3899</td><td style=\"text-align: right;\">    0.101 </td><td style=\"text-align: right;\">2.29036  </td></tr>\n",
              "<tr><td>train_mnist_fdea0_00006</td><td>TERMINATED</td><td>172.28.0.12:36796</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.602652 </td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        136.179 </td><td style=\"text-align: right;\">    0.993 </td><td style=\"text-align: right;\">0.0190594</td></tr>\n",
              "<tr><td>train_mnist_fdea0_00007</td><td>TERMINATED</td><td>172.28.0.12:37995</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.102368 </td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         94.2561</td><td style=\"text-align: right;\">    0.1135</td><td style=\"text-align: right;\">2.27733  </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-05-01 01:17:07,564\tINFO tune.py:762 -- Total run time: 1518.54 seconds (1518.41 seconds for the tuning loop).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for Hyperband: 1518.5629179477692\n",
            "Best hyperparameters from Hyperband: {'filters': 64, 'lr': 0.001, 'batch_size': 128, 'dropout': 0.6026518587327778}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time taken for Hyperband: 1518.5629179477692\n",
        "\n",
        "Best hyperparameters from Hyperband: {'filters': 64, 'lr': 0.001, 'batch_size': 128, 'dropout': 0.6026518587327778}"
      ],
      "metadata": {
        "id": "CJm9vNEb_xma"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWVZSAMFNY0y"
      },
      "source": [
        "### 2."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time taken for Bayesian Search: 1300s = 20 minutes\n",
        "\n",
        "Best hyperparameters from Bayesian Search: {'filters': 204.54283682778978, 'lr': 0.05990598257128396, 'batch_size': 135.91170281869358, 'dropout': 0.9507143064099162}\n",
        "\n",
        "Time taken for Hyperband: 1518s = 25 minutes\n",
        "\n",
        "Best hyperparameters from Hyperband: {'filters': 64, 'lr': 0.001, 'batch_size': 128, 'dropout': 0.6026518587327778}\n",
        "\n",
        "Time taken for Grid Search: 1019s = 17 minutes\n",
        "\n",
        "Best hyperparameters from Grid Search: {'filters': 64, 'lr': 0.001, 'batch_size': 128, 'dropout': 0.5161961869143823}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZbRTF8N8AsfA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALPNdbV9NY0y"
      },
      "source": [
        "### 3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Time Efficiency**:\n",
        "   - **Bayesian Search** took the longest 20 minutes.\n",
        "   - **Hyperband** was slightly slower than Bayesian (about 25 minutes).\n",
        "   - **Grid Search** was the fastest (about 17 minutes).\n",
        "\n",
        "2. **Hyperparameter Values**:\n",
        "   - **Bayesian Search** and **Hyperband** led to different best hyperparameters. Bayesian Search suggested much higher values for 'filters' and 'dropout' and a higher learning rate compared to Hyperband. This imply that Bayesian Search explored more varied parts of the parameter space.\n",
        "\n",
        "   - **Grid Search** and **Hyperband** found similar hyperparameters, particularly for 'filters', 'lr', and 'batch_size'. This consistency could suggest these values are relatively stable choices within the explored grid or range.\n",
        "\n",
        "3. **Performance Considerations**:\n",
        "   - **Bayesian Search** might have explored more extreme values (e.g., very high dropout and filters), which can sometimes lead to other methods might miss due to their more conservative strategies.\n",
        "\n",
        "   - **Hyperband** adapt the resources allocated to promising configurations. The similarity in parameters found by Hyperband and Grid Search, however, might indicate that the parameter space has a well-defined optimal region or that the range of parameters tested in these methods was somewhat limited.\n"
      ],
      "metadata": {
        "id": "iqW11fMZiEKo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjaEsmdWNY0y"
      },
      "source": [
        "## Problem 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTMZYDFwNY0y"
      },
      "source": [
        "Learner 1 is 2.5x faster than learner 2\n",
        "\n",
        "The staleness as follows:\n",
        "\n",
        "$g[L_1,2]$: 0, this is the start and first of the calculation, of both learner 1 and 2\n",
        "\n",
        "$g[L_1,2]$: 0, still there is no updated gradient from other learner during computation.\n",
        "\n",
        "$g[L_1,3]$: 1, it fail to pick up learner 2 g[L_2, 2] which happen at 2.5s, while learner 1 is running from 2s to 3s.\n",
        "\n",
        "$g[L_1,4]$: 0, there is no updated gradient from other learner during computation.\n",
        "\n",
        "$g[L_2,1]$: 0, this is the start and first of the calculation, of both learner 1 and 2\n",
        "\n",
        "$g[L_2,2]$: 2, there are 2 results from learn 1 updated during 2.5 s to 5 s: $g[L_1,3]$ and $g[L_1,4]$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoOrG3e3NY0y"
      },
      "source": [
        "## Problem 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gJIAXMkNY0z"
      },
      "source": [
        "### 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFKuOQnK6Q78",
        "outputId": "36a88acc-806f-49a6-c744-a15e4a9b7d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /ext3/miniconda3/lib/python3.12/site-packages (0.18.0)\n",
            "Requirement already satisfied: numpy in /ext3/miniconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.3.0 in /ext3/miniconda3/lib/python3.12/site-packages (from torchvision) (2.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /ext3/miniconda3/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: filelock in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (2024.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /ext3/miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /ext3/miniconda3/lib/python3.12/site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /ext3/miniconda3/lib/python3.12/site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-QJwyt46Q78",
        "outputId": "7b337c76-d0c7-4ee7-9a54-f38bf5e37e11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "'''ResNet in PyTorch.\n",
        "\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89iEVk506Q78"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''Train CIFAR10 with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.parallel import DataParallel\n",
        "\n",
        "import time\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKo-CNWi6Q78",
        "outputId": "e174090f-97da-4055-cbdb-f049410dcff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For batch size 32: 19.23 sec\n",
            "For batch size 128: 13.30 sec\n",
            "For batch size 512: 15.41 sec\n",
            "For batch size 2048: 18.11 sec\n",
            "For batch size 8192: 20.23 sec\n",
            "Out of memory with batch size 32768.\n"
          ]
        }
      ],
      "source": [
        "net = ResNet18()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=args.lr,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "# Training\n",
        "def train(epoch, trainloader):\n",
        "    # print('\\nEpoch: %d' % epoch)\n",
        "\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        # print('Loss: %.3f | Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return end_time - start_time\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        trainloader = DataLoader(trainset, batch_size, shuffle=True, num_workers=2)\n",
        "        train(1, trainloader)\n",
        "        start_time = time.time()  # Start timing here\n",
        "        train(1, trainloader)\n",
        "        end_time = time.time()  # Start timing here\n",
        "        print('For batch size ', batch_size, ': ', end_time - start_time, ' sec')\n",
        "        batch_size *= 4\n",
        "    except RuntimeError as e:\n",
        "            if 'Out of memory' in str(e):\n",
        "                print(f\"Out of memory with batch size {batch_size}.\")\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O4LESp16Q78"
      },
      "source": [
        "When batch size increases, training time increases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIAH51nzNY0z"
      },
      "source": [
        "### 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63inZGf96Q78",
        "outputId": "572eec2a-6951-47e5-be82-d210ab6a2492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For batch size 32 on 1 GPUs: 19.58 sec\n",
            "For batch size 32 on 2 GPUs: 49.35 sec\n",
            "For batch size 32 on 4 GPUs: 68.65 sec\n",
            "For batch size 128 on 1 GPUs: 19.09 sec\n",
            "For batch size 128 on 2 GPUs: 23.23 sec\n",
            "For batch size 128 on 4 GPUs: 22.26 sec\n",
            "For batch size 512 on 1 GPUs: 12.77 sec\n",
            "For batch size 512 on 2 GPUs: 8.76 sec\n",
            "For batch size 512 on 4 GPUs: 7.56 sec\n",
            "For batch size 2048 on 1 GPUs: 22.26 sec\n",
            "For batch size 2048 on 2 GPUs: 14.56 sec\n",
            "For batch size 2048 on 4 GPUs: 12.43 sec\n",
            "For batch size 8192 on 1 GPUs: 23.65 sec\n",
            "For batch size 8192 on 2 GPUs: 15.42 sec\n",
            "For batch size 8192 on 4 GPUs: 11.34 sec\n",
            "Out of memory with batch size 32768 on 1 GPUs.\n"
          ]
        }
      ],
      "source": [
        "net = ResNet18()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Training\n",
        "def train(epoch, trainloader):\n",
        "    # print('\\nEpoch: %d' % epoch)\n",
        "\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        # print('Loss: %.3f | Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return end_time - start_time\n",
        "\n",
        "batch_size = 32\n",
        "gpu = [1, 2, 4]  # Configurations for 1, 2, and 4 GPUs\n",
        "batch_size = 32\n",
        "while True:\n",
        "    try:\n",
        "        for num_gpu in gpu:\n",
        "\n",
        "            if num_gpu > 1:\n",
        "                    model = DataParallel(model, device_ids=list(range(num_gpu)))\n",
        "            optimizer = optim.SGD(net.parameters(), lr=args.lr,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "            trainloader = DataLoader(trainset, batchsize, shuffle=True, num_workers=2)\n",
        "            train(1, trainloader) # warm up\n",
        "            start_time = time.time()  # Start timing here\n",
        "            train(1, trainloader)\n",
        "            end_time = time.time()  # Start timing here\n",
        "            print('For batch size ', batchsize, ' on ', num_gpu, ' GPUs: ', end_time - start_time, ' sec')\n",
        "            batch_size *= 4\n",
        "    except RuntimeError as e:\n",
        "            if 'out of memory' in str(e):\n",
        "                print(f\"Out of memory with batch size {batch_size}.\")\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Fqyu7Qj6Q78"
      },
      "source": [
        "| Batch-size per GPU |           | Batch-size 32 |            | Batch-size 128 |           | Batch-size 512 |            | Batch-size 2048 |           | Batch-size 8192 |           |\n",
        "|--------------------|-----------|---------------|------------|----------------|-----------|----------------|------------|-----------------|-----------|-----------------|-----------|\n",
        "|                    | Time(sec) | Speedup       | Time(sec)  | Speedup        | Time(sec) | Speedup        | Time(sec)  | Speedup         | Time(sec) | Speedup         |\n",
        "| **1-GPU**          | 19.58     | 1             | 19.09      | 1              | 12.77     | 1              | 22.26      | 1               | 23.65     | 1               |\n",
        "| **2-GPU**          | 49.35     | 0.397         | 23.23      | 0.822          | 8.76      | 1.457          | 14.56      | 1.529           | 15.42     | 1.534           |\n",
        "| **4-GPU**          | 68.65     | 0.285         | 22.26      | 0.858          | 7.56      | 1.689          | 12.43      | 1.791           | 11.34     | 2.085           |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5SZIQAP6Q79"
      },
      "source": [
        "we are measuring strong-scaling. Strong-scaling focuses on how the problem size remains constant while the number of processing elements (in this case, GPUs) is increased. The primary goal of strong-scaling is to reduce the time to solution by using more computational resources.\n",
        "\n",
        "If Weak-Scaling Was Used:\n",
        "\n",
        "Weak-scaling measures the scalability of the system by increasing the size of the problem proportionally as more processing units are added, aiming to keep the workload per processing unit constant.\n",
        "\n",
        "the time for computation might not degrade as it does currently with smaller batch sizes on more GPUs. This would likely result in a more linear scaling, which means the speedup would be closer to the ideal since each GPU would have enough work to perform efficiently. So, **we would expect to see less dramatic increases in time or even reductions in time with more GPUs for smaller batch sizes, and possibly even better performance improvements for larger batch sizes.**\n",
        "\n",
        "for smaller batch sizes, strong-scaling is not very effective due to overheads outweighing benefits. For larger batch sizes, strong-scaling shows better performance improvements as the computational load justifies the communication and synchronization overhead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQS0ROtJNY0z"
      },
      "source": [
        "### 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmZGmfEB6Q8F"
      },
      "source": [
        "Compute time for a multi-GPU setup is estimated by dividing the 1 GPU training time by the number of GPUs. This assumes perfect scaling from 1 GPU to multiple GPUs, i.e., zero communication overhead.\n",
        "\n",
        "Communication time is the excess time taken for training on multiple GPUs over the calculated compute time. So, Communication Time=Total Time on N GPUs−Compute Time on N GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f78QmDNG6Q8F"
      },
      "source": [
        "| Batch-size per GPU |              | Batch-size 32 |                | Batch-size 128 |               | Batch-size 512 |                | Batch-size 2048 |               | Batch-size 8192 |               |\n",
        "|--------------------|--------------|---------------|----------------|----------------|---------------|----------------|----------------|-----------------|---------------|-----------------|---------------|\n",
        "|                    | Compute(sec) | Comm(sec)     | Compute(sec)   | Comm(sec)      | Compute(sec)  | Comm(sec)      | Compute(sec)   | Comm(sec)      | Compute(sec)  | Comm(sec)      |\n",
        "| **2-GPU**          | 9.79         | 39.56         | 9.545          | 13.685         | 6.385         | 2.375          | 11.13          | 3.43            | 11.825        | 3.595          |\n",
        "| **4-GPU**          | 4.895        | 63.755        | 4.7725         | 17.4875        | 3.1925        | 4.3675         | 5.565          | 6.865           | 5.9125        | 5.4275         |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_BPUHu1NY0z"
      },
      "source": [
        "### 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdWv4_i_6Q8F"
      },
      "source": [
        "Formula:\n",
        "\n",
        "$T_{all_reduce} = 2(P — 1)* S/B$\n",
        "\n",
        "where P is the number of GPUs participating in the all-reduce.\n",
        "\n",
        "S is the total size of the data to be reduced across all GPUs, usually in bytes. This is model param for ResNet, which is 11689512\n",
        "\n",
        "B is the communication bandwidth per link between GPUs, usually in bytes per second.\n",
        "\n",
        "each GPU sends and receives data of size S to/from its neighbors and does this for P−1 rounds.\n",
        "\n",
        "Formula for Bandwidth Utilization:\n",
        "\n",
        "U=  Actual Data Transferred / time\n",
        "​\n",
        "Actual Data Transferred is 2×(P−1)×S (since each GPU sends and receives S byte P−1 times).\n",
        "\n",
        "So, for 2 GPU, the ADT = 2*(2 — 1)*11689512 = 11689512 = 0.045GB\n",
        "\n",
        "for 4 GPU, the ADT = 2*(4 — 1)*11689512 = 17534268 = 0.065GB\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MBWzOfR6Q8G"
      },
      "source": [
        "| Batch-size-per-GPU | Bandwidth Utilization(GB/s)  | Bandwidth Utilization(GB/s) | Bandwidth Utilization(GB/s) | Bandwidth Utilization(GB/s) | Bandwidth Utilization(GB/s) |\n",
        "|--------------------|------------------------------|------------------------------|------------------------------|-----------------------------|------------------------------|\n",
        "|                    | Batch-size 32                | Batch-size 128               | Batch-size 512               | Batch-size 2048             | Batch-size 8192              |\n",
        "| **2-GPU**          | 0.000912                     | 0.001937                     | 0.005137                     | 0.003089                    | 0.002918                     |\n",
        "| **4-GPU**          | 0.000947                     | 0.00292                      | 0.008598                     | 0.005231                    | 0.005731                     |\n",
        "\n",
        "\n",
        "\n",
        "As the batch size increases, bandwidth utilization becomes more efficient due to the larger amount of data being transferred relative to the communication overhead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJYFjjUGNY0z"
      },
      "source": [
        "## Problem 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYR-4b3mNY0z"
      },
      "source": [
        "### 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEJnTiLjNY0z",
        "outputId": "3a6228d4-6025-4fac-96b1-f02222eceafc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-ssd'...\n",
            "remote: Enumerating objects: 819, done.\u001b[K\n",
            "remote: Counting objects: 100% (437/437), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 819 (delta 411), reused 405 (delta 405), pack-reused 382\u001b[K\n",
            "Receiving objects: 100% (819/819), 1.05 MiB | 3.51 MiB/s, done.\n",
            "Resolving deltas: 100% (552/552), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/qfgaohao/pytorch-ssd.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWONHBG5NY0z",
        "outputId": "d99915c8-ded1-4312-b48e-8e7f81be1bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages (4.9.0.80)\n",
            "Requirement already satisfied: tqdm in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages (4.66.2)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages (from opencv-python) (1.24.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFPKS130NY0z"
      },
      "outputs": [],
      "source": [
        "!python pytorch-ssd/eval_ssd.py --net mb1-ssd  --dataset data/VOCdevkit/VOC2007 --trained_model pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth --label_file pytorch-ssd/models/voc-model-labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9Qbet6BNY0z"
      },
      "source": [
        "The result is as follow, (copy and paste from hpc from above command)\n",
        "\n",
        "Average Precision Per-class:\n",
        "\n",
        "aeroplane: 0.6843271224059599\n",
        "\n",
        "bicycle: 0.7911140237662206\n",
        "\n",
        "bird: 0.6171819168583986\n",
        "\n",
        "boat: 0.5612220055063379\n",
        "\n",
        "bottle: 0.3485216621466003\n",
        "\n",
        "bus: 0.7677814849265677\n",
        "\n",
        "car: 0.7280986468467315\n",
        "\n",
        "cat: 0.8369208203985581\n",
        "\n",
        "chair: 0.5169138632991064\n",
        "\n",
        "cow: 0.6238697603075337\n",
        "\n",
        "diningtable: 0.7062172972736019\n",
        "\n",
        "dog: 0.7872868219961326\n",
        "\n",
        "horse: 0.819446325939355\n",
        "\n",
        "motorbike: 0.7918539457195842\n",
        "\n",
        "person: 0.702363739134837\n",
        "\n",
        "pottedplant: 0.39852951468542563\n",
        "\n",
        "sheep: 0.6066678298227772\n",
        "\n",
        "sofa: 0.7573083661544429\n",
        "\n",
        "train: 0.8262441264750008\n",
        "\n",
        "tvmonitor: 0.6461898726506375\n",
        "\n",
        "Average Precision Across All Classes: 0.6759029573156905"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyF81VhpNY04"
      },
      "source": [
        "### 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHfOCEuXNY04",
        "outputId": "4a98545d-ceb5-4061-ed50-e344cb9a1f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.34.93-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.35.0,>=1.34.93 (from boto3)\n",
            "  Downloading botocore-1.34.93-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.93->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.93->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.93->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.34.93 botocore-1.34.93 jmespath-1.0.1 s3transfer-0.10.1\n"
          ]
        }
      ],
      "source": [
        "pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hULA94MINY05",
        "outputId": "c7b6b61e-7c85-4107-b473-4b5ec002ae61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-28 19:50:21,730 - root - Download https://storage.googleapis.com/openimages/2018_04/class-descriptions-boxable.csv.\n",
            "2024-04-28 19:50:21,842 - root - Download https://storage.googleapis.com/openimages/2018_04/train/train-annotations-bbox.csv.\n",
            "2024-04-28 19:50:26,623 - root - Read annotation file data/open_images/train-annotations-bbox.csv\n",
            "2024-04-28 19:50:43,293 - root - train bounding boxes size: 1307\n",
            "2024-04-28 19:50:43,293 - root - Approximate Image Stats: \n",
            "2024-04-28 19:50:43,297 - root - Handgun: 561/990 = 0.57.\n",
            "2024-04-28 19:50:43,297 - root - Shotgun: 429/990 = 0.43.\n",
            "2024-04-28 19:50:43,297 - root - Label distribution: \n",
            "2024-04-28 19:50:43,297 - root - Handgun: 727/1307 = 0.56.\n",
            "2024-04-28 19:50:43,297 - root - Shotgun: 580/1307 = 0.44.\n",
            "2024-04-28 19:50:43,297 - root - Shuffle dataset.\n",
            "2024-04-28 19:50:43,297 - root - Save train data to data/open_images/sub-train-annotations-bbox.csv.\n",
            "2024-04-28 19:50:43,307 - root - Download https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-bbox.csv.\n",
            "2024-04-28 19:50:43,582 - root - Read annotation file data/open_images/validation-annotations-bbox.csv\n",
            "2024-04-28 19:50:43,852 - root - validation bounding boxes size: 50\n",
            "2024-04-28 19:50:43,852 - root - Approximate Image Stats: \n",
            "2024-04-28 19:50:43,854 - root - Handgun: 20/39 = 0.51.\n",
            "2024-04-28 19:50:43,854 - root - Shotgun: 19/39 = 0.49.\n",
            "2024-04-28 19:50:43,854 - root - Label distribution: \n",
            "2024-04-28 19:50:43,854 - root - Shotgun: 26/50 = 0.52.\n",
            "2024-04-28 19:50:43,855 - root - Handgun: 24/50 = 0.48.\n",
            "2024-04-28 19:50:43,855 - root - Shuffle dataset.\n",
            "2024-04-28 19:50:43,855 - root - Save validation data to data/open_images/sub-validation-annotations-bbox.csv.\n",
            "2024-04-28 19:50:43,856 - root - Download https://storage.googleapis.com/openimages/2018_04/test/test-annotations-bbox.csv.\n",
            "2024-04-28 19:50:44,258 - root - Read annotation file data/open_images/test-annotations-bbox.csv\n",
            "2024-04-28 19:50:45,003 - root - test bounding boxes size: 147\n",
            "2024-04-28 19:50:45,003 - root - Approximate Image Stats: \n",
            "2024-04-28 19:50:45,005 - root - Handgun: 72/130 = 0.55.\n",
            "2024-04-28 19:50:45,005 - root - Shotgun: 58/130 = 0.45.\n",
            "2024-04-28 19:50:45,005 - root - Label distribution: \n",
            "2024-04-28 19:50:45,005 - root - Handgun: 81/147 = 0.55.\n",
            "2024-04-28 19:50:45,005 - root - Shotgun: 66/147 = 0.45.\n",
            "2024-04-28 19:50:45,005 - root - Shuffle dataset.\n",
            "2024-04-28 19:50:45,005 - root - Save test data to data/open_images/sub-test-annotations-bbox.csv.\n",
            "2024-04-28 19:50:45,007 - root - Start downloading 1121 images.\n",
            "2024-04-28 19:50:46,831 - root - Downloaded 100 images.\n",
            "2024-04-28 19:50:47,866 - root - Downloaded 200 images.\n",
            "2024-04-28 19:50:48,956 - root - Downloaded 300 images.\n",
            "2024-04-28 19:50:49,941 - root - Downloaded 400 images.\n",
            "2024-04-28 19:50:50,941 - root - Downloaded 500 images.\n",
            "2024-04-28 19:50:51,937 - root - Downloaded 600 images.\n",
            "2024-04-28 19:50:52,904 - root - Downloaded 700 images.\n",
            "2024-04-28 19:50:53,892 - root - Downloaded 800 images.\n",
            "2024-04-28 19:50:54,852 - root - Downloaded 900 images.\n",
            "2024-04-28 19:50:56,253 - root - Downloaded 1000 images.\n",
            "2024-04-28 19:50:57,513 - root - Downloaded 1100 images.\n",
            "2024-04-28 19:50:58,169 - root - Task Done.\n"
          ]
        }
      ],
      "source": [
        "!python pytorch-ssd/open_images_downloader.py --root data/open_images --class_names \"Handgun,Shotgun\" --num_workers 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw0ZSGlfNY05"
      },
      "source": [
        "Download successfully, I choose Handguns and Shotguns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPYgW0KZt4fi",
        "outputId": "fed700e8-7561-4beb-94b0-7fb2659dd62a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/pytorch-ssd\n"
          ]
        }
      ],
      "source": [
        "%cd pytorch-ssd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzIOCSWQNY05",
        "outputId": "fffec4c8-7a9a-4820-f75f-b7820b5ba320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-28 19:52:05,584 - root - INFO - Use Cuda.\n",
            "2024-04-28 19:52:05,584 - root - INFO - Namespace(dataset_type='open_images', datasets=['../data/open_images'], validation_dataset=None, balance_data=False, net='mb1-ssd', freeze_base_net=False, freeze_net=False, mb2_width_mult=1.0, lr=0.01, momentum=0.9, weight_decay=0.0005, gamma=0.1, base_net_lr=0.001, extra_layers_lr=None, base_net=None, pretrained_ssd='models/mobilenet-v1-ssd-mp-0_675.pth', resume=None, scheduler='cosine', milestones='80,100', t_max=100.0, batch_size=5, num_epochs=100, num_workers=4, validation_epochs=5, debug_steps=100, use_cuda=True, checkpoint_folder='models/')\n",
            "2024-04-28 19:52:05,618 - root - INFO - Prepare training datasets.\n",
            "2024-04-28 19:52:06,164 - root - INFO - Dataset Summary:Number of Images: 961\n",
            "Minimum Number of Images for a Class: -1\n",
            "Label Distribution:\n",
            "\tHandgun: 727\n",
            "\tShotgun: 580\n",
            "2024-04-28 19:52:06,165 - root - INFO - Stored labels into file models/open-images-model-labels.txt.\n",
            "2024-04-28 19:52:06,166 - root - INFO - Train dataset size: 961\n",
            "2024-04-28 19:52:06,166 - root - INFO - Prepare Validation datasets.\n",
            "2024-04-28 19:52:06,235 - root - INFO - Dataset Summary:Number of Images: 123\n",
            "Minimum Number of Images for a Class: -1\n",
            "Label Distribution:\n",
            "\tHandgun: 81\n",
            "\tShotgun: 66\n",
            "2024-04-28 19:52:06,235 - root - INFO - validation dataset size: 123\n",
            "2024-04-28 19:52:06,235 - root - INFO - Build network.\n",
            "2024-04-28 19:52:06,318 - root - INFO - Init from pretrained ssd models/mobilenet-v1-ssd-mp-0_675.pth\n",
            "2024-04-28 19:52:06,366 - root - INFO - Took 0.05 sec to load the model.\n",
            "2024-04-28 19:52:06,503 - root - INFO - Learning rate: 0.01, Base net learning rate: 0.001, Extra Layers learning rate: 0.01.\n",
            "2024-04-28 19:52:06,503 - root - INFO - Uses CosineAnnealingLR scheduler.\n",
            "2024-04-28 19:52:06,503 - root - INFO - Start training from epoch 0.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "2024-04-28 19:52:20,628 - root - INFO - Epoch: 0, Step: 100, Average Loss: 5.8176, Average Regression Loss 2.3205, Average Classification Loss: 3.4972\n",
            "2024-04-28 19:52:32,217 - root - INFO - Epoch: 0, Validation Loss: 3.7129, Validation Regression Loss 1.3253, Validation Classification Loss: 2.3876\n",
            "2024-04-28 19:52:32,275 - root - INFO - Saved model models/mb1-ssd-Epoch-0-Loss-3.7128826236724852.pth\n",
            "2024-04-28 19:52:44,038 - root - INFO - Epoch: 1, Step: 100, Average Loss: 4.4184, Average Regression Loss 1.6226, Average Classification Loss: 2.7957\n",
            "2024-04-28 19:53:05,887 - root - INFO - Epoch: 2, Step: 100, Average Loss: 3.9290, Average Regression Loss 1.3654, Average Classification Loss: 2.5635\n",
            "2024-04-28 19:53:27,733 - root - INFO - Epoch: 3, Step: 100, Average Loss: 3.8789, Average Regression Loss 1.3391, Average Classification Loss: 2.5398\n",
            "2024-04-28 19:53:47,590 - root - INFO - Epoch: 4, Step: 100, Average Loss: 3.7963, Average Regression Loss 1.2713, Average Classification Loss: 2.5250\n",
            "2024-04-28 19:54:09,574 - root - INFO - Epoch: 5, Step: 100, Average Loss: 3.5804, Average Regression Loss 1.2162, Average Classification Loss: 2.3642\n",
            "2024-04-28 19:54:20,449 - root - INFO - Epoch: 5, Validation Loss: 3.2142, Validation Regression Loss 1.0485, Validation Classification Loss: 2.1657\n",
            "2024-04-28 19:54:20,507 - root - INFO - Saved model models/mb1-ssd-Epoch-5-Loss-3.214212374687195.pth\n",
            "2024-04-28 19:54:32,085 - root - INFO - Epoch: 6, Step: 100, Average Loss: 3.5306, Average Regression Loss 1.1841, Average Classification Loss: 2.3464\n",
            "2024-04-28 19:54:52,789 - root - INFO - Epoch: 7, Step: 100, Average Loss: 3.4804, Average Regression Loss 1.1304, Average Classification Loss: 2.3500\n",
            "2024-04-28 19:55:14,136 - root - INFO - Epoch: 8, Step: 100, Average Loss: 3.7923, Average Regression Loss 1.2432, Average Classification Loss: 2.5491\n",
            "2024-04-28 19:55:35,123 - root - INFO - Epoch: 9, Step: 100, Average Loss: 3.5430, Average Regression Loss 1.1451, Average Classification Loss: 2.3979\n",
            "2024-04-28 19:55:55,672 - root - INFO - Epoch: 10, Step: 100, Average Loss: 3.2505, Average Regression Loss 1.0468, Average Classification Loss: 2.2037\n",
            "2024-04-28 19:56:06,490 - root - INFO - Epoch: 10, Validation Loss: 3.0161, Validation Regression Loss 0.9907, Validation Classification Loss: 2.0255\n",
            "2024-04-28 19:56:06,547 - root - INFO - Saved model models/mb1-ssd-Epoch-10-Loss-3.0161177825927736.pth\n",
            "2024-04-28 19:56:18,184 - root - INFO - Epoch: 11, Step: 100, Average Loss: 3.2630, Average Regression Loss 1.0369, Average Classification Loss: 2.2261\n",
            "2024-04-28 19:56:39,678 - root - INFO - Epoch: 12, Step: 100, Average Loss: 3.2754, Average Regression Loss 1.0446, Average Classification Loss: 2.2308\n",
            "2024-04-28 19:57:01,559 - root - INFO - Epoch: 13, Step: 100, Average Loss: 3.2263, Average Regression Loss 1.0358, Average Classification Loss: 2.1905\n",
            "2024-04-28 19:57:22,606 - root - INFO - Epoch: 14, Step: 100, Average Loss: 3.2880, Average Regression Loss 1.0769, Average Classification Loss: 2.2111\n",
            "2024-04-28 19:57:44,088 - root - INFO - Epoch: 15, Step: 100, Average Loss: 3.0621, Average Regression Loss 0.9794, Average Classification Loss: 2.0827\n",
            "2024-04-28 19:57:54,400 - root - INFO - Epoch: 15, Validation Loss: 2.8506, Validation Regression Loss 0.9328, Validation Classification Loss: 1.9178\n",
            "2024-04-28 19:57:54,455 - root - INFO - Saved model models/mb1-ssd-Epoch-15-Loss-2.8505722808837892.pth\n",
            "2024-04-28 19:58:05,165 - root - INFO - Epoch: 16, Step: 100, Average Loss: 3.2838, Average Regression Loss 1.0643, Average Classification Loss: 2.2195\n",
            "2024-04-28 19:58:26,135 - root - INFO - Epoch: 17, Step: 100, Average Loss: 3.0942, Average Regression Loss 0.9811, Average Classification Loss: 2.1132\n",
            "2024-04-28 19:58:47,113 - root - INFO - Epoch: 18, Step: 100, Average Loss: 3.1558, Average Regression Loss 0.9963, Average Classification Loss: 2.1595\n",
            "2024-04-28 19:59:09,386 - root - INFO - Epoch: 19, Step: 100, Average Loss: 3.1333, Average Regression Loss 1.0351, Average Classification Loss: 2.0981\n",
            "2024-04-28 19:59:30,316 - root - INFO - Epoch: 20, Step: 100, Average Loss: 3.0170, Average Regression Loss 0.9488, Average Classification Loss: 2.0682\n",
            "2024-04-28 19:59:40,514 - root - INFO - Epoch: 20, Validation Loss: 2.8006, Validation Regression Loss 0.8711, Validation Classification Loss: 1.9295\n",
            "2024-04-28 19:59:40,569 - root - INFO - Saved model models/mb1-ssd-Epoch-20-Loss-2.8006146574020385.pth\n",
            "2024-04-28 19:59:52,645 - root - INFO - Epoch: 21, Step: 100, Average Loss: 3.1201, Average Regression Loss 1.0393, Average Classification Loss: 2.0809\n",
            "2024-04-28 20:00:12,661 - root - INFO - Epoch: 22, Step: 100, Average Loss: 3.0573, Average Regression Loss 0.9784, Average Classification Loss: 2.0788\n",
            "2024-04-28 20:00:34,062 - root - INFO - Epoch: 23, Step: 100, Average Loss: 3.0724, Average Regression Loss 1.0117, Average Classification Loss: 2.0607\n",
            "2024-04-28 20:00:55,306 - root - INFO - Epoch: 24, Step: 100, Average Loss: 3.0503, Average Regression Loss 0.9730, Average Classification Loss: 2.0773\n",
            "2024-04-28 20:01:14,870 - root - INFO - Epoch: 25, Step: 100, Average Loss: 2.9372, Average Regression Loss 0.9282, Average Classification Loss: 2.0091\n",
            "2024-04-28 20:01:25,679 - root - INFO - Epoch: 25, Validation Loss: 3.0601, Validation Regression Loss 0.9503, Validation Classification Loss: 2.1098\n",
            "2024-04-28 20:01:25,737 - root - INFO - Saved model models/mb1-ssd-Epoch-25-Loss-3.0601189947128296.pth\n",
            "2024-04-28 20:01:37,011 - root - INFO - Epoch: 26, Step: 100, Average Loss: 3.0041, Average Regression Loss 0.9443, Average Classification Loss: 2.0598\n",
            "2024-04-28 20:01:56,705 - root - INFO - Epoch: 27, Step: 100, Average Loss: 2.7009, Average Regression Loss 0.8349, Average Classification Loss: 1.8661\n",
            "2024-04-28 20:02:16,417 - root - INFO - Epoch: 28, Step: 100, Average Loss: 2.7956, Average Regression Loss 0.8798, Average Classification Loss: 1.9157\n",
            "2024-04-28 20:02:37,349 - root - INFO - Epoch: 29, Step: 100, Average Loss: 2.7595, Average Regression Loss 0.8434, Average Classification Loss: 1.9161\n",
            "2024-04-28 20:02:57,332 - root - INFO - Epoch: 30, Step: 100, Average Loss: 2.9520, Average Regression Loss 0.9232, Average Classification Loss: 2.0288\n",
            "2024-04-28 20:03:07,830 - root - INFO - Epoch: 30, Validation Loss: 2.8361, Validation Regression Loss 0.8649, Validation Classification Loss: 1.9712\n",
            "2024-04-28 20:03:07,886 - root - INFO - Saved model models/mb1-ssd-Epoch-30-Loss-2.8361488676071165.pth\n",
            "2024-04-28 20:03:19,597 - root - INFO - Epoch: 31, Step: 100, Average Loss: 2.8739, Average Regression Loss 0.9232, Average Classification Loss: 1.9507\n",
            "2024-04-28 20:03:41,036 - root - INFO - Epoch: 32, Step: 100, Average Loss: 2.8507, Average Regression Loss 0.8805, Average Classification Loss: 1.9702\n",
            "2024-04-28 20:04:02,618 - root - INFO - Epoch: 33, Step: 100, Average Loss: 3.0188, Average Regression Loss 0.9553, Average Classification Loss: 2.0635\n",
            "2024-04-28 20:04:24,365 - root - INFO - Epoch: 34, Step: 100, Average Loss: 2.6404, Average Regression Loss 0.8078, Average Classification Loss: 1.8326\n",
            "2024-04-28 20:04:44,483 - root - INFO - Epoch: 35, Step: 100, Average Loss: 2.6446, Average Regression Loss 0.7780, Average Classification Loss: 1.8666\n",
            "2024-04-28 20:04:55,323 - root - INFO - Epoch: 35, Validation Loss: 2.8666, Validation Regression Loss 0.8609, Validation Classification Loss: 2.0057\n",
            "2024-04-28 20:04:55,379 - root - INFO - Saved model models/mb1-ssd-Epoch-35-Loss-2.8666466808319093.pth\n",
            "2024-04-28 20:05:06,295 - root - INFO - Epoch: 36, Step: 100, Average Loss: 2.7712, Average Regression Loss 0.8643, Average Classification Loss: 1.9069\n",
            "2024-04-28 20:05:28,607 - root - INFO - Epoch: 37, Step: 100, Average Loss: 2.6759, Average Regression Loss 0.8160, Average Classification Loss: 1.8599\n",
            "2024-04-28 20:05:49,259 - root - INFO - Epoch: 38, Step: 100, Average Loss: 2.6556, Average Regression Loss 0.7650, Average Classification Loss: 1.8906\n",
            "2024-04-28 20:06:10,445 - root - INFO - Epoch: 39, Step: 100, Average Loss: 2.5961, Average Regression Loss 0.7813, Average Classification Loss: 1.8148\n",
            "2024-04-28 20:06:30,520 - root - INFO - Epoch: 40, Step: 100, Average Loss: 2.5207, Average Regression Loss 0.7832, Average Classification Loss: 1.7375\n",
            "2024-04-28 20:06:42,450 - root - INFO - Epoch: 40, Validation Loss: 2.9387, Validation Regression Loss 0.8615, Validation Classification Loss: 2.0771\n",
            "2024-04-28 20:06:42,504 - root - INFO - Saved model models/mb1-ssd-Epoch-40-Loss-2.9386500453948976.pth\n",
            "2024-04-28 20:06:53,895 - root - INFO - Epoch: 41, Step: 100, Average Loss: 2.5645, Average Regression Loss 0.7900, Average Classification Loss: 1.7746\n",
            "2024-04-28 20:07:14,747 - root - INFO - Epoch: 42, Step: 100, Average Loss: 2.5849, Average Regression Loss 0.7885, Average Classification Loss: 1.7963\n",
            "2024-04-28 20:07:36,661 - root - INFO - Epoch: 43, Step: 100, Average Loss: 2.5135, Average Regression Loss 0.7340, Average Classification Loss: 1.7796\n",
            "2024-04-28 20:07:57,258 - root - INFO - Epoch: 44, Step: 100, Average Loss: 2.6205, Average Regression Loss 0.7945, Average Classification Loss: 1.8260\n",
            "2024-04-28 20:08:19,295 - root - INFO - Epoch: 45, Step: 100, Average Loss: 2.6885, Average Regression Loss 0.8399, Average Classification Loss: 1.8486\n",
            "2024-04-28 20:08:29,821 - root - INFO - Epoch: 45, Validation Loss: 2.9144, Validation Regression Loss 0.8908, Validation Classification Loss: 2.0235\n",
            "2024-04-28 20:08:29,876 - root - INFO - Saved model models/mb1-ssd-Epoch-45-Loss-2.914350161552429.pth\n",
            "2024-04-28 20:08:41,105 - root - INFO - Epoch: 46, Step: 100, Average Loss: 2.5371, Average Regression Loss 0.7667, Average Classification Loss: 1.7703\n",
            "2024-04-28 20:09:01,279 - root - INFO - Epoch: 47, Step: 100, Average Loss: 2.5299, Average Regression Loss 0.7607, Average Classification Loss: 1.7692\n",
            "2024-04-28 20:09:22,214 - root - INFO - Epoch: 48, Step: 100, Average Loss: 2.4885, Average Regression Loss 0.7478, Average Classification Loss: 1.7406\n",
            "2024-04-28 20:09:43,589 - root - INFO - Epoch: 49, Step: 100, Average Loss: 2.4867, Average Regression Loss 0.7355, Average Classification Loss: 1.7513\n",
            "2024-04-28 20:10:06,023 - root - INFO - Epoch: 50, Step: 100, Average Loss: 2.6343, Average Regression Loss 0.7799, Average Classification Loss: 1.8544\n",
            "2024-04-28 20:10:16,378 - root - INFO - Epoch: 50, Validation Loss: 2.6916, Validation Regression Loss 0.8054, Validation Classification Loss: 1.8862\n",
            "2024-04-28 20:10:16,438 - root - INFO - Saved model models/mb1-ssd-Epoch-50-Loss-2.691582536697388.pth\n",
            "2024-04-28 20:10:27,051 - root - INFO - Epoch: 51, Step: 100, Average Loss: 2.3904, Average Regression Loss 0.7231, Average Classification Loss: 1.6673\n",
            "2024-04-28 20:10:48,472 - root - INFO - Epoch: 52, Step: 100, Average Loss: 2.4145, Average Regression Loss 0.7325, Average Classification Loss: 1.6821\n",
            "2024-04-28 20:11:10,376 - root - INFO - Epoch: 53, Step: 100, Average Loss: 2.4207, Average Regression Loss 0.7302, Average Classification Loss: 1.6904\n",
            "2024-04-28 20:11:31,308 - root - INFO - Epoch: 54, Step: 100, Average Loss: 2.4244, Average Regression Loss 0.6835, Average Classification Loss: 1.7409\n",
            "2024-04-28 20:11:51,648 - root - INFO - Epoch: 55, Step: 100, Average Loss: 2.4461, Average Regression Loss 0.7273, Average Classification Loss: 1.7187\n",
            "2024-04-28 20:12:02,020 - root - INFO - Epoch: 55, Validation Loss: 2.8336, Validation Regression Loss 0.8591, Validation Classification Loss: 1.9745\n",
            "2024-04-28 20:12:02,075 - root - INFO - Saved model models/mb1-ssd-Epoch-55-Loss-2.83359605550766.pth\n",
            "2024-04-28 20:12:13,425 - root - INFO - Epoch: 56, Step: 100, Average Loss: 2.3049, Average Regression Loss 0.6922, Average Classification Loss: 1.6127\n",
            "2024-04-28 20:12:35,460 - root - INFO - Epoch: 57, Step: 100, Average Loss: 2.2609, Average Regression Loss 0.6709, Average Classification Loss: 1.5900\n",
            "2024-04-28 20:12:55,958 - root - INFO - Epoch: 58, Step: 100, Average Loss: 2.1768, Average Regression Loss 0.6243, Average Classification Loss: 1.5525\n",
            "2024-04-28 20:13:17,783 - root - INFO - Epoch: 59, Step: 100, Average Loss: 2.2426, Average Regression Loss 0.6650, Average Classification Loss: 1.5776\n",
            "2024-04-28 20:13:38,110 - root - INFO - Epoch: 60, Step: 100, Average Loss: 2.3188, Average Regression Loss 0.6672, Average Classification Loss: 1.6516\n",
            "2024-04-28 20:13:49,995 - root - INFO - Epoch: 60, Validation Loss: 2.8544, Validation Regression Loss 0.8584, Validation Classification Loss: 1.9960\n",
            "2024-04-28 20:13:50,050 - root - INFO - Saved model models/mb1-ssd-Epoch-60-Loss-2.8543707227706907.pth\n",
            "2024-04-28 20:14:01,540 - root - INFO - Epoch: 61, Step: 100, Average Loss: 2.1394, Average Regression Loss 0.5778, Average Classification Loss: 1.5616\n",
            "2024-04-28 20:14:22,413 - root - INFO - Epoch: 62, Step: 100, Average Loss: 2.3198, Average Regression Loss 0.7032, Average Classification Loss: 1.6166\n",
            "2024-04-28 20:14:44,713 - root - INFO - Epoch: 63, Step: 100, Average Loss: 2.2402, Average Regression Loss 0.6404, Average Classification Loss: 1.5999\n",
            "2024-04-28 20:15:05,631 - root - INFO - Epoch: 64, Step: 100, Average Loss: 2.1520, Average Regression Loss 0.6126, Average Classification Loss: 1.5394\n",
            "2024-04-28 20:15:27,343 - root - INFO - Epoch: 65, Step: 100, Average Loss: 2.1156, Average Regression Loss 0.6107, Average Classification Loss: 1.5049\n",
            "2024-04-28 20:15:37,455 - root - INFO - Epoch: 65, Validation Loss: 2.8353, Validation Regression Loss 0.8152, Validation Classification Loss: 2.0201\n",
            "2024-04-28 20:15:37,511 - root - INFO - Saved model models/mb1-ssd-Epoch-65-Loss-2.8352642965316774.pth\n",
            "2024-04-28 20:15:48,326 - root - INFO - Epoch: 66, Step: 100, Average Loss: 2.1175, Average Regression Loss 0.5948, Average Classification Loss: 1.5227\n",
            "2024-04-28 20:16:09,612 - root - INFO - Epoch: 67, Step: 100, Average Loss: 2.2051, Average Regression Loss 0.6211, Average Classification Loss: 1.5840\n",
            "2024-04-28 20:16:31,255 - root - INFO - Epoch: 68, Step: 100, Average Loss: 2.1673, Average Regression Loss 0.6244, Average Classification Loss: 1.5429\n",
            "2024-04-28 20:16:51,545 - root - INFO - Epoch: 69, Step: 100, Average Loss: 1.9746, Average Regression Loss 0.5488, Average Classification Loss: 1.4258\n",
            "2024-04-28 20:17:12,853 - root - INFO - Epoch: 70, Step: 100, Average Loss: 2.0724, Average Regression Loss 0.5997, Average Classification Loss: 1.4727\n",
            "2024-04-28 20:17:23,551 - root - INFO - Epoch: 70, Validation Loss: 2.7660, Validation Regression Loss 0.8307, Validation Classification Loss: 1.9353\n",
            "2024-04-28 20:17:23,606 - root - INFO - Saved model models/mb1-ssd-Epoch-70-Loss-2.766000008583069.pth\n",
            "2024-04-28 20:17:34,337 - root - INFO - Epoch: 71, Step: 100, Average Loss: 2.1681, Average Regression Loss 0.6033, Average Classification Loss: 1.5649\n",
            "2024-04-28 20:17:54,523 - root - INFO - Epoch: 72, Step: 100, Average Loss: 2.0184, Average Regression Loss 0.5644, Average Classification Loss: 1.4541\n",
            "2024-04-28 20:18:15,313 - root - INFO - Epoch: 73, Step: 100, Average Loss: 2.0370, Average Regression Loss 0.5684, Average Classification Loss: 1.4686\n",
            "2024-04-28 20:18:37,296 - root - INFO - Epoch: 74, Step: 100, Average Loss: 1.9966, Average Regression Loss 0.5802, Average Classification Loss: 1.4164\n",
            "2024-04-28 20:18:59,501 - root - INFO - Epoch: 75, Step: 100, Average Loss: 1.9734, Average Regression Loss 0.5660, Average Classification Loss: 1.4074\n",
            "2024-04-28 20:19:11,021 - root - INFO - Epoch: 75, Validation Loss: 2.7819, Validation Regression Loss 0.8029, Validation Classification Loss: 1.9790\n",
            "2024-04-28 20:19:11,076 - root - INFO - Saved model models/mb1-ssd-Epoch-75-Loss-2.7818708539009096.pth\n",
            "2024-04-28 20:19:23,115 - root - INFO - Epoch: 76, Step: 100, Average Loss: 1.9664, Average Regression Loss 0.5475, Average Classification Loss: 1.4188\n",
            "2024-04-28 20:19:45,655 - root - INFO - Epoch: 77, Step: 100, Average Loss: 1.9685, Average Regression Loss 0.5792, Average Classification Loss: 1.3893\n",
            "2024-04-28 20:20:07,288 - root - INFO - Epoch: 78, Step: 100, Average Loss: 1.9713, Average Regression Loss 0.5474, Average Classification Loss: 1.4238\n",
            "2024-04-28 20:20:28,557 - root - INFO - Epoch: 79, Step: 100, Average Loss: 1.9344, Average Regression Loss 0.5434, Average Classification Loss: 1.3910\n",
            "2024-04-28 20:20:49,053 - root - INFO - Epoch: 80, Step: 100, Average Loss: 1.9415, Average Regression Loss 0.5291, Average Classification Loss: 1.4123\n",
            "2024-04-28 20:20:59,656 - root - INFO - Epoch: 80, Validation Loss: 2.7982, Validation Regression Loss 0.8030, Validation Classification Loss: 1.9952\n",
            "2024-04-28 20:20:59,713 - root - INFO - Saved model models/mb1-ssd-Epoch-80-Loss-2.798204951286316.pth\n",
            "2024-04-28 20:21:11,372 - root - INFO - Epoch: 81, Step: 100, Average Loss: 1.8959, Average Regression Loss 0.5364, Average Classification Loss: 1.3595\n",
            "2024-04-28 20:21:31,141 - root - INFO - Epoch: 82, Step: 100, Average Loss: 1.9275, Average Regression Loss 0.5530, Average Classification Loss: 1.3745\n",
            "2024-04-28 20:21:53,100 - root - INFO - Epoch: 83, Step: 100, Average Loss: 2.0129, Average Regression Loss 0.5566, Average Classification Loss: 1.4563\n",
            "2024-04-28 20:22:14,457 - root - INFO - Epoch: 84, Step: 100, Average Loss: 1.9458, Average Regression Loss 0.5689, Average Classification Loss: 1.3769\n",
            "2024-04-28 20:22:35,950 - root - INFO - Epoch: 85, Step: 100, Average Loss: 1.9860, Average Regression Loss 0.5498, Average Classification Loss: 1.4362\n",
            "2024-04-28 20:22:46,891 - root - INFO - Epoch: 85, Validation Loss: 2.8108, Validation Regression Loss 0.8064, Validation Classification Loss: 2.0044\n",
            "2024-04-28 20:22:46,947 - root - INFO - Saved model models/mb1-ssd-Epoch-85-Loss-2.8108258962631227.pth\n",
            "2024-04-28 20:22:57,457 - root - INFO - Epoch: 86, Step: 100, Average Loss: 1.9118, Average Regression Loss 0.5229, Average Classification Loss: 1.3890\n",
            "2024-04-28 20:23:19,342 - root - INFO - Epoch: 87, Step: 100, Average Loss: 2.0057, Average Regression Loss 0.5782, Average Classification Loss: 1.4275\n",
            "2024-04-28 20:23:41,506 - root - INFO - Epoch: 88, Step: 100, Average Loss: 1.9402, Average Regression Loss 0.5778, Average Classification Loss: 1.3624\n",
            "2024-04-28 20:24:01,882 - root - INFO - Epoch: 89, Step: 100, Average Loss: 1.9133, Average Regression Loss 0.5202, Average Classification Loss: 1.3931\n",
            "2024-04-28 20:24:23,074 - root - INFO - Epoch: 90, Step: 100, Average Loss: 1.8872, Average Regression Loss 0.5254, Average Classification Loss: 1.3618\n",
            "2024-04-28 20:24:33,120 - root - INFO - Epoch: 90, Validation Loss: 2.7820, Validation Regression Loss 0.7858, Validation Classification Loss: 1.9962\n",
            "2024-04-28 20:24:33,175 - root - INFO - Saved model models/mb1-ssd-Epoch-90-Loss-2.7819643449783324.pth\n",
            "2024-04-28 20:24:44,209 - root - INFO - Epoch: 91, Step: 100, Average Loss: 2.0057, Average Regression Loss 0.5671, Average Classification Loss: 1.4386\n",
            "2024-04-28 20:25:04,816 - root - INFO - Epoch: 92, Step: 100, Average Loss: 1.9282, Average Regression Loss 0.5434, Average Classification Loss: 1.3847\n",
            "2024-04-28 20:25:26,142 - root - INFO - Epoch: 93, Step: 100, Average Loss: 2.0357, Average Regression Loss 0.6114, Average Classification Loss: 1.4243\n",
            "2024-04-28 20:25:46,738 - root - INFO - Epoch: 94, Step: 100, Average Loss: 1.9018, Average Regression Loss 0.4998, Average Classification Loss: 1.4019\n",
            "2024-04-28 20:26:07,269 - root - INFO - Epoch: 95, Step: 100, Average Loss: 1.8166, Average Regression Loss 0.5104, Average Classification Loss: 1.3062\n",
            "2024-04-28 20:26:17,217 - root - INFO - Epoch: 95, Validation Loss: 2.7526, Validation Regression Loss 0.7781, Validation Classification Loss: 1.9745\n",
            "2024-04-28 20:26:17,272 - root - INFO - Saved model models/mb1-ssd-Epoch-95-Loss-2.7526174116134645.pth\n",
            "2024-04-28 20:26:29,160 - root - INFO - Epoch: 96, Step: 100, Average Loss: 1.9313, Average Regression Loss 0.5328, Average Classification Loss: 1.3986\n",
            "2024-04-28 20:26:50,075 - root - INFO - Epoch: 97, Step: 100, Average Loss: 1.8057, Average Regression Loss 0.5037, Average Classification Loss: 1.3020\n",
            "2024-04-28 20:27:12,816 - root - INFO - Epoch: 98, Step: 100, Average Loss: 1.9176, Average Regression Loss 0.5251, Average Classification Loss: 1.3925\n",
            "2024-04-28 20:27:34,098 - root - INFO - Epoch: 99, Step: 100, Average Loss: 1.9512, Average Regression Loss 0.5389, Average Classification Loss: 1.4123\n",
            "2024-04-28 20:27:44,356 - root - INFO - Epoch: 99, Validation Loss: 2.7985, Validation Regression Loss 0.7985, Validation Classification Loss: 2.0000\n",
            "2024-04-28 20:27:44,411 - root - INFO - Saved model models/mb1-ssd-Epoch-99-Loss-2.798509557247162.pth\n"
          ]
        }
      ],
      "source": [
        "!python train_ssd.py --dataset_type open_images --datasets ../data/open_images --net mb1-ssd --pretrained_ssd models/mobilenet-v1-ssd-mp-0_675.pth --scheduler cosine --lr 0.01 --t_max 100 --validation_epochs 5 --num_epochs 100 --base_net_lr 0.001  --batch_size 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_MurjQgRaFA",
        "outputId": "7340a917-b34f-4bbb-d0bb-e58c285044be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/pytorch-ssd/eval_ssd.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  all_gt_boxes[class_index][image_id] = torch.tensor(all_gt_boxes[class_index][image_id])\n",
            "It took 0.04636216163635254 sec to load the model.\n",
            "process image 0\n",
            "Load Image: 0.019361 sec.\n",
            "Inference time:  0.6022565364837646\n",
            "Prediction: 0.611756 sec.\n",
            "process image 1\n",
            "Load Image: 0.009265 sec.\n",
            "Inference time:  0.005998373031616211\n",
            "Prediction: 0.016124 sec.\n",
            "process image 2\n",
            "Load Image: 0.007794 sec.\n",
            "Inference time:  0.00577545166015625\n",
            "Prediction: 0.014228 sec.\n",
            "process image 3\n",
            "Load Image: 0.010273 sec.\n",
            "Inference time:  0.006129026412963867\n",
            "Prediction: 0.010442 sec.\n",
            "process image 4\n",
            "Load Image: 0.014009 sec.\n",
            "Inference time:  0.0057332515716552734\n",
            "Prediction: 0.011431 sec.\n",
            "process image 5\n",
            "Load Image: 0.008108 sec.\n",
            "Inference time:  0.006911754608154297\n",
            "Prediction: 0.019938 sec.\n",
            "process image 6\n",
            "Load Image: 0.007970 sec.\n",
            "Inference time:  0.006722927093505859\n",
            "Prediction: 0.014618 sec.\n",
            "process image 7\n",
            "Load Image: 0.010936 sec.\n",
            "Inference time:  0.0061948299407958984\n",
            "Prediction: 0.017478 sec.\n",
            "process image 8\n",
            "Load Image: 0.012516 sec.\n",
            "Inference time:  0.0062906742095947266\n",
            "Prediction: 0.014324 sec.\n",
            "process image 9\n",
            "Load Image: 0.014498 sec.\n",
            "Inference time:  0.0061779022216796875\n",
            "Prediction: 0.018897 sec.\n",
            "process image 10\n",
            "Load Image: 0.015007 sec.\n",
            "Inference time:  0.0059299468994140625\n",
            "Prediction: 0.024511 sec.\n",
            "process image 11\n",
            "Load Image: 0.004669 sec.\n",
            "Inference time:  0.005816936492919922\n",
            "Prediction: 0.010463 sec.\n",
            "process image 12\n",
            "Load Image: 0.008841 sec.\n",
            "Inference time:  0.0057220458984375\n",
            "Prediction: 0.008897 sec.\n",
            "process image 13\n",
            "Load Image: 0.008770 sec.\n",
            "Inference time:  0.005789518356323242\n",
            "Prediction: 0.017917 sec.\n",
            "process image 14\n",
            "Load Image: 0.015273 sec.\n",
            "Inference time:  0.005759477615356445\n",
            "Prediction: 0.017855 sec.\n",
            "process image 15\n",
            "Load Image: 0.010657 sec.\n",
            "Inference time:  0.005661487579345703\n",
            "Prediction: 0.008473 sec.\n",
            "process image 16\n",
            "Load Image: 0.013266 sec.\n",
            "Inference time:  0.005590915679931641\n",
            "Prediction: 0.017372 sec.\n",
            "process image 17\n",
            "Load Image: 0.014255 sec.\n",
            "Inference time:  0.0056610107421875\n",
            "Prediction: 0.008930 sec.\n",
            "process image 18\n",
            "Load Image: 0.014851 sec.\n",
            "Inference time:  0.005680084228515625\n",
            "Prediction: 0.010995 sec.\n",
            "process image 19\n",
            "Load Image: 0.006201 sec.\n",
            "Inference time:  0.005585432052612305\n",
            "Prediction: 0.009145 sec.\n",
            "process image 20\n",
            "Load Image: 0.010387 sec.\n",
            "Inference time:  0.00566864013671875\n",
            "Prediction: 0.008500 sec.\n",
            "process image 21\n",
            "Load Image: 0.006579 sec.\n",
            "Inference time:  0.005603313446044922\n",
            "Prediction: 0.012940 sec.\n",
            "process image 22\n",
            "Load Image: 0.010368 sec.\n",
            "Inference time:  0.0055887699127197266\n",
            "Prediction: 0.014454 sec.\n",
            "process image 23\n",
            "Load Image: 0.008499 sec.\n",
            "Inference time:  0.0055620670318603516\n",
            "Prediction: 0.009843 sec.\n",
            "process image 24\n",
            "Load Image: 0.023427 sec.\n",
            "Inference time:  0.005944728851318359\n",
            "Prediction: 0.017305 sec.\n",
            "process image 25\n",
            "Load Image: 0.016585 sec.\n",
            "Inference time:  0.0057833194732666016\n",
            "Prediction: 0.012592 sec.\n",
            "process image 26\n",
            "Load Image: 0.010315 sec.\n",
            "Inference time:  0.0056803226470947266\n",
            "Prediction: 0.017360 sec.\n",
            "process image 27\n",
            "Load Image: 0.009214 sec.\n",
            "Inference time:  0.005602359771728516\n",
            "Prediction: 0.008522 sec.\n",
            "process image 28\n",
            "Load Image: 0.012424 sec.\n",
            "Inference time:  0.00558161735534668\n",
            "Prediction: 0.016105 sec.\n",
            "process image 29\n",
            "Load Image: 0.006059 sec.\n",
            "Inference time:  0.005510807037353516\n",
            "Prediction: 0.008761 sec.\n",
            "process image 30\n",
            "Load Image: 0.020822 sec.\n",
            "Inference time:  0.0056324005126953125\n",
            "Prediction: 0.013140 sec.\n",
            "process image 31\n",
            "Load Image: 0.006612 sec.\n",
            "Inference time:  0.005584239959716797\n",
            "Prediction: 0.010285 sec.\n",
            "process image 32\n",
            "Load Image: 0.010479 sec.\n",
            "Inference time:  0.005621910095214844\n",
            "Prediction: 0.008634 sec.\n",
            "process image 33\n",
            "Load Image: 0.014161 sec.\n",
            "Inference time:  0.0056035518646240234\n",
            "Prediction: 0.010755 sec.\n",
            "process image 34\n",
            "Load Image: 0.010069 sec.\n",
            "Inference time:  0.005600690841674805\n",
            "Prediction: 0.016415 sec.\n",
            "process image 35\n",
            "Load Image: 0.007985 sec.\n",
            "Inference time:  0.0065424442291259766\n",
            "Prediction: 0.009806 sec.\n",
            "process image 36\n",
            "Load Image: 0.018013 sec.\n",
            "Inference time:  0.005602836608886719\n",
            "Prediction: 0.018601 sec.\n",
            "process image 37\n",
            "Load Image: 0.008391 sec.\n",
            "Inference time:  0.005507707595825195\n",
            "Prediction: 0.009322 sec.\n",
            "process image 38\n",
            "Load Image: 0.013516 sec.\n",
            "Inference time:  0.005442619323730469\n",
            "Prediction: 0.014659 sec.\n",
            "process image 39\n",
            "Load Image: 0.010496 sec.\n",
            "Inference time:  0.0054912567138671875\n",
            "Prediction: 0.015320 sec.\n",
            "process image 40\n",
            "Load Image: 0.009610 sec.\n",
            "Inference time:  0.005455732345581055\n",
            "Prediction: 0.014722 sec.\n",
            "process image 41\n",
            "Load Image: 0.012322 sec.\n",
            "Inference time:  0.0053863525390625\n",
            "Prediction: 0.014555 sec.\n",
            "process image 42\n",
            "Load Image: 0.007933 sec.\n",
            "Inference time:  0.007459163665771484\n",
            "Prediction: 0.012822 sec.\n",
            "process image 43\n",
            "Load Image: 0.016605 sec.\n",
            "Inference time:  0.00574946403503418\n",
            "Prediction: 0.023191 sec.\n",
            "process image 44\n",
            "Load Image: 0.021562 sec.\n",
            "Inference time:  0.005612373352050781\n",
            "Prediction: 0.017360 sec.\n",
            "process image 45\n",
            "Load Image: 0.010674 sec.\n",
            "Inference time:  0.005560159683227539\n",
            "Prediction: 0.017718 sec.\n",
            "process image 46\n",
            "Load Image: 0.004007 sec.\n",
            "Inference time:  0.005530357360839844\n",
            "Prediction: 0.009105 sec.\n",
            "process image 47\n",
            "Load Image: 0.025445 sec.\n",
            "Inference time:  0.005586385726928711\n",
            "Prediction: 0.008716 sec.\n",
            "process image 48\n",
            "Load Image: 0.008518 sec.\n",
            "Inference time:  0.005469083786010742\n",
            "Prediction: 0.018467 sec.\n",
            "process image 49\n",
            "Load Image: 0.013253 sec.\n",
            "Inference time:  0.005556583404541016\n",
            "Prediction: 0.016437 sec.\n",
            "process image 50\n",
            "Load Image: 0.013320 sec.\n",
            "Inference time:  0.0055119991302490234\n",
            "Prediction: 0.008308 sec.\n",
            "process image 51\n",
            "Load Image: 0.007652 sec.\n",
            "Inference time:  0.005510091781616211\n",
            "Prediction: 0.010423 sec.\n",
            "process image 52\n",
            "Load Image: 0.005326 sec.\n",
            "Inference time:  0.005506753921508789\n",
            "Prediction: 0.009340 sec.\n",
            "process image 53\n",
            "Load Image: 0.014857 sec.\n",
            "Inference time:  0.005524158477783203\n",
            "Prediction: 0.018805 sec.\n",
            "process image 54\n",
            "Load Image: 0.008840 sec.\n",
            "Inference time:  0.005490779876708984\n",
            "Prediction: 0.011850 sec.\n",
            "process image 55\n",
            "Load Image: 0.009527 sec.\n",
            "Inference time:  0.0055310726165771484\n",
            "Prediction: 0.015410 sec.\n",
            "process image 56\n",
            "Load Image: 0.009954 sec.\n",
            "Inference time:  0.005515098571777344\n",
            "Prediction: 0.019545 sec.\n",
            "process image 57\n",
            "Load Image: 0.022233 sec.\n",
            "Inference time:  0.005723714828491211\n",
            "Prediction: 0.016567 sec.\n",
            "process image 58\n",
            "Load Image: 0.013635 sec.\n",
            "Inference time:  0.005540132522583008\n",
            "Prediction: 0.008262 sec.\n",
            "process image 59\n",
            "Load Image: 0.007250 sec.\n",
            "Inference time:  0.005485057830810547\n",
            "Prediction: 0.008663 sec.\n",
            "process image 60\n",
            "Load Image: 0.010399 sec.\n",
            "Inference time:  0.005458831787109375\n",
            "Prediction: 0.021004 sec.\n",
            "process image 61\n",
            "Load Image: 0.011458 sec.\n",
            "Inference time:  0.005507707595825195\n",
            "Prediction: 0.008550 sec.\n",
            "process image 62\n",
            "Load Image: 0.015986 sec.\n",
            "Inference time:  0.005634784698486328\n",
            "Prediction: 0.014394 sec.\n",
            "process image 63\n",
            "Load Image: 0.019022 sec.\n",
            "Inference time:  0.005829811096191406\n",
            "Prediction: 0.011706 sec.\n",
            "process image 64\n",
            "Load Image: 0.008809 sec.\n",
            "Inference time:  0.0056133270263671875\n",
            "Prediction: 0.008698 sec.\n",
            "process image 65\n",
            "Load Image: 0.011003 sec.\n",
            "Inference time:  0.0056149959564208984\n",
            "Prediction: 0.009947 sec.\n",
            "process image 66\n",
            "Load Image: 0.011717 sec.\n",
            "Inference time:  0.005641460418701172\n",
            "Prediction: 0.015750 sec.\n",
            "process image 67\n",
            "Load Image: 0.013659 sec.\n",
            "Inference time:  0.006078243255615234\n",
            "Prediction: 0.024309 sec.\n",
            "process image 68\n",
            "Load Image: 0.012439 sec.\n",
            "Inference time:  0.005553007125854492\n",
            "Prediction: 0.017620 sec.\n",
            "process image 69\n",
            "Load Image: 0.007342 sec.\n",
            "Inference time:  0.005566835403442383\n",
            "Prediction: 0.008289 sec.\n",
            "process image 70\n",
            "Load Image: 0.003895 sec.\n",
            "Inference time:  0.005587339401245117\n",
            "Prediction: 0.010273 sec.\n",
            "process image 71\n",
            "Load Image: 0.007659 sec.\n",
            "Inference time:  0.005505561828613281\n",
            "Prediction: 0.020171 sec.\n",
            "process image 72\n",
            "Load Image: 0.012206 sec.\n",
            "Inference time:  0.0054950714111328125\n",
            "Prediction: 0.008484 sec.\n",
            "process image 73\n",
            "Load Image: 0.006198 sec.\n",
            "Inference time:  0.005594730377197266\n",
            "Prediction: 0.010447 sec.\n",
            "process image 74\n",
            "Load Image: 0.008861 sec.\n",
            "Inference time:  0.0056629180908203125\n",
            "Prediction: 0.020107 sec.\n",
            "process image 75\n",
            "Load Image: 0.009273 sec.\n",
            "Inference time:  0.005518198013305664\n",
            "Prediction: 0.011106 sec.\n",
            "process image 76\n",
            "Load Image: 0.012307 sec.\n",
            "Inference time:  0.005787849426269531\n",
            "Prediction: 0.014997 sec.\n",
            "process image 77\n",
            "Load Image: 0.011390 sec.\n",
            "Inference time:  0.0056378841400146484\n",
            "Prediction: 0.017378 sec.\n",
            "process image 78\n",
            "Load Image: 0.012706 sec.\n",
            "Inference time:  0.00568699836730957\n",
            "Prediction: 0.009788 sec.\n",
            "process image 79\n",
            "Load Image: 0.012681 sec.\n",
            "Inference time:  0.005563497543334961\n",
            "Prediction: 0.008947 sec.\n",
            "process image 80\n",
            "Load Image: 0.008761 sec.\n",
            "Inference time:  0.005522966384887695\n",
            "Prediction: 0.020480 sec.\n",
            "process image 81\n",
            "Load Image: 0.007888 sec.\n",
            "Inference time:  0.005488157272338867\n",
            "Prediction: 0.022079 sec.\n",
            "process image 82\n",
            "Load Image: 0.009518 sec.\n",
            "Inference time:  0.0055048465728759766\n",
            "Prediction: 0.012023 sec.\n",
            "process image 83\n",
            "Load Image: 0.007867 sec.\n",
            "Inference time:  0.0054895877838134766\n",
            "Prediction: 0.015184 sec.\n",
            "process image 84\n",
            "Load Image: 0.014687 sec.\n",
            "Inference time:  0.005507469177246094\n",
            "Prediction: 0.012887 sec.\n",
            "process image 85\n",
            "Load Image: 0.009990 sec.\n",
            "Inference time:  0.005863189697265625\n",
            "Prediction: 0.009228 sec.\n",
            "process image 86\n",
            "Load Image: 0.012968 sec.\n",
            "Inference time:  0.0055353641510009766\n",
            "Prediction: 0.008718 sec.\n",
            "process image 87\n",
            "Load Image: 0.010342 sec.\n",
            "Inference time:  0.005429506301879883\n",
            "Prediction: 0.010005 sec.\n",
            "process image 88\n",
            "Load Image: 0.012463 sec.\n",
            "Inference time:  0.005455970764160156\n",
            "Prediction: 0.008492 sec.\n",
            "process image 89\n",
            "Load Image: 0.012027 sec.\n",
            "Inference time:  0.0053501129150390625\n",
            "Prediction: 0.010922 sec.\n",
            "process image 90\n",
            "Load Image: 0.009887 sec.\n",
            "Inference time:  0.005410909652709961\n",
            "Prediction: 0.008825 sec.\n",
            "process image 91\n",
            "Load Image: 0.010885 sec.\n",
            "Inference time:  0.005457162857055664\n",
            "Prediction: 0.015326 sec.\n",
            "process image 92\n",
            "Load Image: 0.013090 sec.\n",
            "Inference time:  0.0054585933685302734\n",
            "Prediction: 0.008828 sec.\n",
            "process image 93\n",
            "Load Image: 0.006182 sec.\n",
            "Inference time:  0.005478620529174805\n",
            "Prediction: 0.010460 sec.\n",
            "process image 94\n",
            "Load Image: 0.009521 sec.\n",
            "Inference time:  0.00545501708984375\n",
            "Prediction: 0.009561 sec.\n",
            "process image 95\n",
            "Load Image: 0.014307 sec.\n",
            "Inference time:  0.005511760711669922\n",
            "Prediction: 0.009993 sec.\n",
            "process image 96\n",
            "Load Image: 0.008644 sec.\n",
            "Inference time:  0.005620479583740234\n",
            "Prediction: 0.008809 sec.\n",
            "process image 97\n",
            "Load Image: 0.006521 sec.\n",
            "Inference time:  0.005504131317138672\n",
            "Prediction: 0.011497 sec.\n",
            "process image 98\n",
            "Load Image: 0.014155 sec.\n",
            "Inference time:  0.0055980682373046875\n",
            "Prediction: 0.014478 sec.\n",
            "process image 99\n",
            "Load Image: 0.009221 sec.\n",
            "Inference time:  0.0056645870208740234\n",
            "Prediction: 0.017628 sec.\n",
            "process image 100\n",
            "Load Image: 0.015313 sec.\n",
            "Inference time:  0.0059053897857666016\n",
            "Prediction: 0.013660 sec.\n",
            "process image 101\n",
            "Load Image: 0.015333 sec.\n",
            "Inference time:  0.006344795227050781\n",
            "Prediction: 0.009671 sec.\n",
            "process image 102\n",
            "Load Image: 0.019382 sec.\n",
            "Inference time:  0.005825042724609375\n",
            "Prediction: 0.020910 sec.\n",
            "process image 103\n",
            "Load Image: 0.007635 sec.\n",
            "Inference time:  0.005738258361816406\n",
            "Prediction: 0.008931 sec.\n",
            "process image 104\n",
            "Load Image: 0.009387 sec.\n",
            "Inference time:  0.006105184555053711\n",
            "Prediction: 0.011163 sec.\n",
            "process image 105\n",
            "Load Image: 0.010317 sec.\n",
            "Inference time:  0.005541086196899414\n",
            "Prediction: 0.017181 sec.\n",
            "process image 106\n",
            "Load Image: 0.017449 sec.\n",
            "Inference time:  0.005680084228515625\n",
            "Prediction: 0.022858 sec.\n",
            "process image 107\n",
            "Load Image: 0.010067 sec.\n",
            "Inference time:  0.005636692047119141\n",
            "Prediction: 0.013284 sec.\n",
            "process image 108\n",
            "Load Image: 0.008175 sec.\n",
            "Inference time:  0.005581855773925781\n",
            "Prediction: 0.013520 sec.\n",
            "process image 109\n",
            "Load Image: 0.012822 sec.\n",
            "Inference time:  0.006629467010498047\n",
            "Prediction: 0.025965 sec.\n",
            "process image 110\n",
            "Load Image: 0.011739 sec.\n",
            "Inference time:  0.0056879520416259766\n",
            "Prediction: 0.012069 sec.\n",
            "process image 111\n",
            "Load Image: 0.010424 sec.\n",
            "Inference time:  0.005532264709472656\n",
            "Prediction: 0.018092 sec.\n",
            "process image 112\n",
            "Load Image: 0.011016 sec.\n",
            "Inference time:  0.005518198013305664\n",
            "Prediction: 0.014100 sec.\n",
            "process image 113\n",
            "Load Image: 0.009897 sec.\n",
            "Inference time:  0.005626678466796875\n",
            "Prediction: 0.008441 sec.\n",
            "process image 114\n",
            "Load Image: 0.004057 sec.\n",
            "Inference time:  0.005621194839477539\n",
            "Prediction: 0.012759 sec.\n",
            "process image 115\n",
            "Load Image: 0.026023 sec.\n",
            "Inference time:  0.0058782100677490234\n",
            "Prediction: 0.018692 sec.\n",
            "process image 116\n",
            "Load Image: 0.015449 sec.\n",
            "Inference time:  0.005523681640625\n",
            "Prediction: 0.008708 sec.\n",
            "process image 117\n",
            "Load Image: 0.013683 sec.\n",
            "Inference time:  0.005530357360839844\n",
            "Prediction: 0.010473 sec.\n",
            "process image 118\n",
            "Load Image: 0.013325 sec.\n",
            "Inference time:  0.005500316619873047\n",
            "Prediction: 0.012305 sec.\n",
            "process image 119\n",
            "Load Image: 0.005954 sec.\n",
            "Inference time:  0.005466938018798828\n",
            "Prediction: 0.008344 sec.\n",
            "process image 120\n",
            "Load Image: 0.023803 sec.\n",
            "Inference time:  0.0056192874908447266\n",
            "Prediction: 0.025286 sec.\n",
            "process image 121\n",
            "Load Image: 0.025271 sec.\n",
            "Inference time:  0.005753040313720703\n",
            "Prediction: 0.016384 sec.\n",
            "process image 122\n",
            "Load Image: 0.014363 sec.\n",
            "Inference time:  0.005610227584838867\n",
            "Prediction: 0.011684 sec.\n",
            "\n",
            "\n",
            "Average Precision Per-class:\n",
            "Handgun: 0.8292257251879146\n",
            "Shotgun: 0.5969613222703153\n",
            "\n",
            "Average Precision Across All Classes:0.7130935237291149\n"
          ]
        }
      ],
      "source": [
        "!python eval_ssd.py --dataset_type open_images --net mb1-ssd --dataset ../data/open_images --trained_model models/mb1-ssd-Epoch-99-Loss-2.798509557247162.pth --label_file models/open-images-model-labels.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJlLfE8sQQcN",
        "outputId": "fbef9fad-6839-460d-a7cc-1e9dcc376859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/pytorch-ssd/eval_ssd.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  all_gt_boxes[class_index][image_id] = torch.tensor(all_gt_boxes[class_index][image_id])\n",
            "It took 0.04904580116271973 sec to load the model.\n",
            "process image 0\n",
            "Load Image: 0.019377 sec.\n",
            "Inference time:  0.5990192890167236\n",
            "Prediction: 0.621946 sec.\n",
            "process image 1\n",
            "Load Image: 0.009439 sec.\n",
            "Inference time:  0.0062274932861328125\n",
            "Prediction: 0.025332 sec.\n",
            "process image 2\n",
            "Load Image: 0.007796 sec.\n",
            "Inference time:  0.005885124206542969\n",
            "Prediction: 0.026655 sec.\n",
            "process image 3\n",
            "Load Image: 0.010315 sec.\n",
            "Inference time:  0.006087541580200195\n",
            "Prediction: 0.030978 sec.\n",
            "process image 4\n",
            "Load Image: 0.014173 sec.\n",
            "Inference time:  0.006224393844604492\n",
            "Prediction: 0.025230 sec.\n",
            "process image 5\n",
            "Load Image: 0.008260 sec.\n",
            "Inference time:  0.005950450897216797\n",
            "Prediction: 0.026568 sec.\n",
            "process image 6\n",
            "Load Image: 0.007965 sec.\n",
            "Inference time:  0.005731105804443359\n",
            "Prediction: 0.023701 sec.\n",
            "process image 7\n",
            "Load Image: 0.010275 sec.\n",
            "Inference time:  0.005829334259033203\n",
            "Prediction: 0.024758 sec.\n",
            "process image 8\n",
            "Load Image: 0.012490 sec.\n",
            "Inference time:  0.007245063781738281\n",
            "Prediction: 0.040067 sec.\n",
            "process image 9\n",
            "Load Image: 0.014065 sec.\n",
            "Inference time:  0.007149696350097656\n",
            "Prediction: 0.037764 sec.\n",
            "process image 10\n",
            "Load Image: 0.014911 sec.\n",
            "Inference time:  0.007551431655883789\n",
            "Prediction: 0.029785 sec.\n",
            "process image 11\n",
            "Load Image: 0.004659 sec.\n",
            "Inference time:  0.0057027339935302734\n",
            "Prediction: 0.035077 sec.\n",
            "process image 12\n",
            "Load Image: 0.009014 sec.\n",
            "Inference time:  0.007334470748901367\n",
            "Prediction: 0.035892 sec.\n",
            "process image 13\n",
            "Load Image: 0.008675 sec.\n",
            "Inference time:  0.00792384147644043\n",
            "Prediction: 0.045032 sec.\n",
            "process image 14\n",
            "Load Image: 0.015594 sec.\n",
            "Inference time:  0.007376432418823242\n",
            "Prediction: 0.035907 sec.\n",
            "process image 15\n",
            "Load Image: 0.010667 sec.\n",
            "Inference time:  0.0077741146087646484\n",
            "Prediction: 0.032754 sec.\n",
            "process image 16\n",
            "Load Image: 0.013415 sec.\n",
            "Inference time:  0.007284879684448242\n",
            "Prediction: 0.038746 sec.\n",
            "process image 17\n",
            "Load Image: 0.014313 sec.\n",
            "Inference time:  0.0071446895599365234\n",
            "Prediction: 0.039330 sec.\n",
            "process image 18\n",
            "Load Image: 0.014885 sec.\n",
            "Inference time:  0.007699489593505859\n",
            "Prediction: 0.036072 sec.\n",
            "process image 19\n",
            "Load Image: 0.009404 sec.\n",
            "Inference time:  0.0073735713958740234\n",
            "Prediction: 0.042000 sec.\n",
            "process image 20\n",
            "Load Image: 0.010504 sec.\n",
            "Inference time:  0.007170677185058594\n",
            "Prediction: 0.037564 sec.\n",
            "process image 21\n",
            "Load Image: 0.006900 sec.\n",
            "Inference time:  0.006098270416259766\n",
            "Prediction: 0.024993 sec.\n",
            "process image 22\n",
            "Load Image: 0.010479 sec.\n",
            "Inference time:  0.005893230438232422\n",
            "Prediction: 0.028460 sec.\n",
            "process image 23\n",
            "Load Image: 0.008644 sec.\n",
            "Inference time:  0.005902528762817383\n",
            "Prediction: 0.023287 sec.\n",
            "process image 24\n",
            "Load Image: 0.023308 sec.\n",
            "Inference time:  0.005982398986816406\n",
            "Prediction: 0.022315 sec.\n",
            "process image 25\n",
            "Load Image: 0.016642 sec.\n",
            "Inference time:  0.005913496017456055\n",
            "Prediction: 0.022724 sec.\n",
            "process image 26\n",
            "Load Image: 0.010437 sec.\n",
            "Inference time:  0.006234169006347656\n",
            "Prediction: 0.027879 sec.\n",
            "process image 27\n",
            "Load Image: 0.009892 sec.\n",
            "Inference time:  0.006471157073974609\n",
            "Prediction: 0.029521 sec.\n",
            "process image 28\n",
            "Load Image: 0.012768 sec.\n",
            "Inference time:  0.005925178527832031\n",
            "Prediction: 0.025414 sec.\n",
            "process image 29\n",
            "Load Image: 0.006143 sec.\n",
            "Inference time:  0.00569605827331543\n",
            "Prediction: 0.033775 sec.\n",
            "process image 30\n",
            "Load Image: 0.020757 sec.\n",
            "Inference time:  0.00588536262512207\n",
            "Prediction: 0.021018 sec.\n",
            "process image 31\n",
            "Load Image: 0.006727 sec.\n",
            "Inference time:  0.005778074264526367\n",
            "Prediction: 0.027662 sec.\n",
            "process image 32\n",
            "Load Image: 0.010537 sec.\n",
            "Inference time:  0.005807161331176758\n",
            "Prediction: 0.021615 sec.\n",
            "process image 33\n",
            "Load Image: 0.014222 sec.\n",
            "Inference time:  0.005898952484130859\n",
            "Prediction: 0.026574 sec.\n",
            "process image 34\n",
            "Load Image: 0.010050 sec.\n",
            "Inference time:  0.005815267562866211\n",
            "Prediction: 0.023291 sec.\n",
            "process image 35\n",
            "Load Image: 0.007935 sec.\n",
            "Inference time:  0.005919456481933594\n",
            "Prediction: 0.029809 sec.\n",
            "process image 36\n",
            "Load Image: 0.017869 sec.\n",
            "Inference time:  0.005902767181396484\n",
            "Prediction: 0.022938 sec.\n",
            "process image 37\n",
            "Load Image: 0.008725 sec.\n",
            "Inference time:  0.006048917770385742\n",
            "Prediction: 0.024144 sec.\n",
            "process image 38\n",
            "Load Image: 0.013427 sec.\n",
            "Inference time:  0.005742073059082031\n",
            "Prediction: 0.028528 sec.\n",
            "process image 39\n",
            "Load Image: 0.010731 sec.\n",
            "Inference time:  0.005848884582519531\n",
            "Prediction: 0.022177 sec.\n",
            "process image 40\n",
            "Load Image: 0.009657 sec.\n",
            "Inference time:  0.005768299102783203\n",
            "Prediction: 0.024675 sec.\n",
            "process image 41\n",
            "Load Image: 0.012420 sec.\n",
            "Inference time:  0.005809783935546875\n",
            "Prediction: 0.027980 sec.\n",
            "process image 42\n",
            "Load Image: 0.008101 sec.\n",
            "Inference time:  0.00580906867980957\n",
            "Prediction: 0.026456 sec.\n",
            "process image 43\n",
            "Load Image: 0.016353 sec.\n",
            "Inference time:  0.005858182907104492\n",
            "Prediction: 0.021670 sec.\n",
            "process image 44\n",
            "Load Image: 0.021877 sec.\n",
            "Inference time:  0.005908966064453125\n",
            "Prediction: 0.025530 sec.\n",
            "process image 45\n",
            "Load Image: 0.010610 sec.\n",
            "Inference time:  0.005780935287475586\n",
            "Prediction: 0.022381 sec.\n",
            "process image 46\n",
            "Load Image: 0.003950 sec.\n",
            "Inference time:  0.0058248043060302734\n",
            "Prediction: 0.029196 sec.\n",
            "process image 47\n",
            "Load Image: 0.024825 sec.\n",
            "Inference time:  0.005957126617431641\n",
            "Prediction: 0.030362 sec.\n",
            "process image 48\n",
            "Load Image: 0.008658 sec.\n",
            "Inference time:  0.005742788314819336\n",
            "Prediction: 0.022561 sec.\n",
            "process image 49\n",
            "Load Image: 0.013284 sec.\n",
            "Inference time:  0.0064542293548583984\n",
            "Prediction: 0.026086 sec.\n",
            "process image 50\n",
            "Load Image: 0.013306 sec.\n",
            "Inference time:  0.005826234817504883\n",
            "Prediction: 0.029164 sec.\n",
            "process image 51\n",
            "Load Image: 0.007806 sec.\n",
            "Inference time:  0.005881786346435547\n",
            "Prediction: 0.027853 sec.\n",
            "process image 52\n",
            "Load Image: 0.005406 sec.\n",
            "Inference time:  0.006157636642456055\n",
            "Prediction: 0.031538 sec.\n",
            "process image 53\n",
            "Load Image: 0.014699 sec.\n",
            "Inference time:  0.005924224853515625\n",
            "Prediction: 0.028661 sec.\n",
            "process image 54\n",
            "Load Image: 0.009301 sec.\n",
            "Inference time:  0.007605552673339844\n",
            "Prediction: 0.028813 sec.\n",
            "process image 55\n",
            "Load Image: 0.009636 sec.\n",
            "Inference time:  0.005845785140991211\n",
            "Prediction: 0.021136 sec.\n",
            "process image 56\n",
            "Load Image: 0.010045 sec.\n",
            "Inference time:  0.005735635757446289\n",
            "Prediction: 0.028338 sec.\n",
            "process image 57\n",
            "Load Image: 0.022531 sec.\n",
            "Inference time:  0.005843400955200195\n",
            "Prediction: 0.024904 sec.\n",
            "process image 58\n",
            "Load Image: 0.013688 sec.\n",
            "Inference time:  0.0057659149169921875\n",
            "Prediction: 0.030287 sec.\n",
            "process image 59\n",
            "Load Image: 0.007332 sec.\n",
            "Inference time:  0.006001710891723633\n",
            "Prediction: 0.028890 sec.\n",
            "process image 60\n",
            "Load Image: 0.010551 sec.\n",
            "Inference time:  0.005917072296142578\n",
            "Prediction: 0.028988 sec.\n",
            "process image 61\n",
            "Load Image: 0.011680 sec.\n",
            "Inference time:  0.005860567092895508\n",
            "Prediction: 0.022056 sec.\n",
            "process image 62\n",
            "Load Image: 0.016072 sec.\n",
            "Inference time:  0.00601959228515625\n",
            "Prediction: 0.023376 sec.\n",
            "process image 63\n",
            "Load Image: 0.019540 sec.\n",
            "Inference time:  0.006315469741821289\n",
            "Prediction: 0.030522 sec.\n",
            "process image 64\n",
            "Load Image: 0.008838 sec.\n",
            "Inference time:  0.005881071090698242\n",
            "Prediction: 0.023298 sec.\n",
            "process image 65\n",
            "Load Image: 0.010942 sec.\n",
            "Inference time:  0.005777120590209961\n",
            "Prediction: 0.022953 sec.\n",
            "process image 66\n",
            "Load Image: 0.011580 sec.\n",
            "Inference time:  0.005689382553100586\n",
            "Prediction: 0.024735 sec.\n",
            "process image 67\n",
            "Load Image: 0.013867 sec.\n",
            "Inference time:  0.005875825881958008\n",
            "Prediction: 0.025014 sec.\n",
            "process image 68\n",
            "Load Image: 0.012465 sec.\n",
            "Inference time:  0.005635499954223633\n",
            "Prediction: 0.023658 sec.\n",
            "process image 69\n",
            "Load Image: 0.007296 sec.\n",
            "Inference time:  0.005595207214355469\n",
            "Prediction: 0.022855 sec.\n",
            "process image 70\n",
            "Load Image: 0.003937 sec.\n",
            "Inference time:  0.00565338134765625\n",
            "Prediction: 0.026317 sec.\n",
            "process image 71\n",
            "Load Image: 0.007695 sec.\n",
            "Inference time:  0.005610466003417969\n",
            "Prediction: 0.022215 sec.\n",
            "process image 72\n",
            "Load Image: 0.012104 sec.\n",
            "Inference time:  0.00565791130065918\n",
            "Prediction: 0.039521 sec.\n",
            "process image 73\n",
            "Load Image: 0.006134 sec.\n",
            "Inference time:  0.0067899227142333984\n",
            "Prediction: 0.025480 sec.\n",
            "process image 74\n",
            "Load Image: 0.008979 sec.\n",
            "Inference time:  0.005704641342163086\n",
            "Prediction: 0.023925 sec.\n",
            "process image 75\n",
            "Load Image: 0.009234 sec.\n",
            "Inference time:  0.005537986755371094\n",
            "Prediction: 0.029145 sec.\n",
            "process image 76\n",
            "Load Image: 0.012897 sec.\n",
            "Inference time:  0.005707263946533203\n",
            "Prediction: 0.022834 sec.\n",
            "process image 77\n",
            "Load Image: 0.011217 sec.\n",
            "Inference time:  0.005608320236206055\n",
            "Prediction: 0.027416 sec.\n",
            "process image 78\n",
            "Load Image: 0.012358 sec.\n",
            "Inference time:  0.00570225715637207\n",
            "Prediction: 0.026894 sec.\n",
            "process image 79\n",
            "Load Image: 0.012755 sec.\n",
            "Inference time:  0.005771636962890625\n",
            "Prediction: 0.025057 sec.\n",
            "process image 80\n",
            "Load Image: 0.008875 sec.\n",
            "Inference time:  0.005779266357421875\n",
            "Prediction: 0.026735 sec.\n",
            "process image 81\n",
            "Load Image: 0.008126 sec.\n",
            "Inference time:  0.006161689758300781\n",
            "Prediction: 0.025680 sec.\n",
            "process image 82\n",
            "Load Image: 0.009743 sec.\n",
            "Inference time:  0.0058116912841796875\n",
            "Prediction: 0.025651 sec.\n",
            "process image 83\n",
            "Load Image: 0.007890 sec.\n",
            "Inference time:  0.005655527114868164\n",
            "Prediction: 0.019990 sec.\n",
            "process image 84\n",
            "Load Image: 0.014658 sec.\n",
            "Inference time:  0.005692005157470703\n",
            "Prediction: 0.021536 sec.\n",
            "process image 85\n",
            "Load Image: 0.010326 sec.\n",
            "Inference time:  0.0063474178314208984\n",
            "Prediction: 0.028338 sec.\n",
            "process image 86\n",
            "Load Image: 0.013291 sec.\n",
            "Inference time:  0.005906105041503906\n",
            "Prediction: 0.027794 sec.\n",
            "process image 87\n",
            "Load Image: 0.010395 sec.\n",
            "Inference time:  0.005595684051513672\n",
            "Prediction: 0.021500 sec.\n",
            "process image 88\n",
            "Load Image: 0.012444 sec.\n",
            "Inference time:  0.005708217620849609\n",
            "Prediction: 0.027385 sec.\n",
            "process image 89\n",
            "Load Image: 0.012157 sec.\n",
            "Inference time:  0.005656242370605469\n",
            "Prediction: 0.024570 sec.\n",
            "process image 90\n",
            "Load Image: 0.009896 sec.\n",
            "Inference time:  0.0059893131256103516\n",
            "Prediction: 0.025962 sec.\n",
            "process image 91\n",
            "Load Image: 0.011056 sec.\n",
            "Inference time:  0.005672931671142578\n",
            "Prediction: 0.025873 sec.\n",
            "process image 92\n",
            "Load Image: 0.013004 sec.\n",
            "Inference time:  0.005593538284301758\n",
            "Prediction: 0.024816 sec.\n",
            "process image 93\n",
            "Load Image: 0.006206 sec.\n",
            "Inference time:  0.0055675506591796875\n",
            "Prediction: 0.026633 sec.\n",
            "process image 94\n",
            "Load Image: 0.009541 sec.\n",
            "Inference time:  0.005568027496337891\n",
            "Prediction: 0.027487 sec.\n",
            "process image 95\n",
            "Load Image: 0.014815 sec.\n",
            "Inference time:  0.005580902099609375\n",
            "Prediction: 0.031598 sec.\n",
            "process image 96\n",
            "Load Image: 0.007976 sec.\n",
            "Inference time:  0.005517721176147461\n",
            "Prediction: 0.028512 sec.\n",
            "process image 97\n",
            "Load Image: 0.006556 sec.\n",
            "Inference time:  0.005627870559692383\n",
            "Prediction: 0.021495 sec.\n",
            "process image 98\n",
            "Load Image: 0.014592 sec.\n",
            "Inference time:  0.005629539489746094\n",
            "Prediction: 0.026728 sec.\n",
            "process image 99\n",
            "Load Image: 0.009101 sec.\n",
            "Inference time:  0.005730867385864258\n",
            "Prediction: 0.026719 sec.\n",
            "process image 100\n",
            "Load Image: 0.019877 sec.\n",
            "Inference time:  0.005972385406494141\n",
            "Prediction: 0.023783 sec.\n",
            "process image 101\n",
            "Load Image: 0.013811 sec.\n",
            "Inference time:  0.005509138107299805\n",
            "Prediction: 0.031446 sec.\n",
            "process image 102\n",
            "Load Image: 0.019178 sec.\n",
            "Inference time:  0.006930828094482422\n",
            "Prediction: 0.040697 sec.\n",
            "process image 103\n",
            "Load Image: 0.007453 sec.\n",
            "Inference time:  0.005569934844970703\n",
            "Prediction: 0.023928 sec.\n",
            "process image 104\n",
            "Load Image: 0.009274 sec.\n",
            "Inference time:  0.0054585933685302734\n",
            "Prediction: 0.022176 sec.\n",
            "process image 105\n",
            "Load Image: 0.010231 sec.\n",
            "Inference time:  0.005590200424194336\n",
            "Prediction: 0.026443 sec.\n",
            "process image 106\n",
            "Load Image: 0.017536 sec.\n",
            "Inference time:  0.005802631378173828\n",
            "Prediction: 0.020873 sec.\n",
            "process image 107\n",
            "Load Image: 0.009920 sec.\n",
            "Inference time:  0.005803346633911133\n",
            "Prediction: 0.021821 sec.\n",
            "process image 108\n",
            "Load Image: 0.008962 sec.\n",
            "Inference time:  0.0061719417572021484\n",
            "Prediction: 0.023616 sec.\n",
            "process image 109\n",
            "Load Image: 0.012820 sec.\n",
            "Inference time:  0.005721569061279297\n",
            "Prediction: 0.027035 sec.\n",
            "process image 110\n",
            "Load Image: 0.011672 sec.\n",
            "Inference time:  0.005581855773925781\n",
            "Prediction: 0.026194 sec.\n",
            "process image 111\n",
            "Load Image: 0.010428 sec.\n",
            "Inference time:  0.005672454833984375\n",
            "Prediction: 0.027993 sec.\n",
            "process image 112\n",
            "Load Image: 0.010935 sec.\n",
            "Inference time:  0.005661725997924805\n",
            "Prediction: 0.021683 sec.\n",
            "process image 113\n",
            "Load Image: 0.009964 sec.\n",
            "Inference time:  0.005612850189208984\n",
            "Prediction: 0.023841 sec.\n",
            "process image 114\n",
            "Load Image: 0.004121 sec.\n",
            "Inference time:  0.00558781623840332\n",
            "Prediction: 0.025048 sec.\n",
            "process image 115\n",
            "Load Image: 0.025396 sec.\n",
            "Inference time:  0.005629062652587891\n",
            "Prediction: 0.027009 sec.\n",
            "process image 116\n",
            "Load Image: 0.015516 sec.\n",
            "Inference time:  0.006060123443603516\n",
            "Prediction: 0.032388 sec.\n",
            "process image 117\n",
            "Load Image: 0.013853 sec.\n",
            "Inference time:  0.006007671356201172\n",
            "Prediction: 0.027710 sec.\n",
            "process image 118\n",
            "Load Image: 0.013345 sec.\n",
            "Inference time:  0.00572967529296875\n",
            "Prediction: 0.024964 sec.\n",
            "process image 119\n",
            "Load Image: 0.006085 sec.\n",
            "Inference time:  0.005755186080932617\n",
            "Prediction: 0.032252 sec.\n",
            "process image 120\n",
            "Load Image: 0.023952 sec.\n",
            "Inference time:  0.005688190460205078\n",
            "Prediction: 0.026186 sec.\n",
            "process image 121\n",
            "Load Image: 0.025103 sec.\n",
            "Inference time:  0.005669593811035156\n",
            "Prediction: 0.024213 sec.\n",
            "process image 122\n",
            "Load Image: 0.014386 sec.\n",
            "Inference time:  0.005750179290771484\n",
            "Prediction: 0.027771 sec.\n",
            "\n",
            "\n",
            "Average Precision Per-class:\n",
            "Handgun: 0.7103875229654111\n",
            "Shotgun: 0.28310441747307086\n",
            "\n",
            "Average Precision Across All Classes:0.49674597021924094\n"
          ]
        }
      ],
      "source": [
        "!python eval_ssd.py --dataset_type open_images --net mb1-ssd --dataset ../data/open_images --trained_model models/mb1-ssd-Epoch-0-Loss-3.7128826236724852.pth --label_file models/open-images-model-labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2YJk8n2NY05"
      },
      "source": [
        "### 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAnrkmMGaRJb",
        "outputId": "ee95f157-5c58-4a76-d399-c38997c35cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.0-cp310-cp310-macosx_10_15_universal2.whl (16.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-macosx_11_0_universal2.whl (14.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting netron\n",
            "  Downloading netron-7.6.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting protobuf>=3.20.2\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-macosx_10_9_universal2.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.0/404.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages (from onnx) (1.24.3)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages (from onnxruntime) (23.0)\n",
            "Collecting flatbuffers\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: sympy in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages (from onnxruntime) (1.11.1)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->onnxruntime) (1.2.1)\n",
            "Installing collected packages: netron, flatbuffers, protobuf, humanfriendly, onnx, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 flatbuffers-24.3.25 humanfriendly-10.0 netron-7.6.3 onnx-1.16.0 onnxruntime-1.17.3 protobuf-5.26.1\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx onnxruntime netron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Od1Oci7K6Q8H",
        "outputId": "1717c78a-a3b5-47d8-bb34-179df56ec855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/zhongyihao/Downloads/DS301 Advance ML/deep-learning/code/pytorch-ssd\n"
          ]
        }
      ],
      "source": [
        "%cd pytorch-ssd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctBOtULqaS6e",
        "outputId": "e8fd5cf9-f476-473b-c69c-aa07058f1456"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zhongyihao/anaconda3/envs/torch_nightly_env/lib/python3.10/site-packages/torch/onnx/utils.py:2029: UserWarning: Provided key output for dynamic axes is not a valid input/output name\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "File saved: models/mb1-ssd-10.onnx.\n"
          ]
        }
      ],
      "source": [
        "# Some standard imports\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.onnx\n",
        "\n",
        "from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd\n",
        "import torch.onnx\n",
        "import onnx\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "# Parameters\n",
        "\n",
        "model_path = 'models/mb1-ssd-Epoch-99-Loss-2.798509557247162.pth'\n",
        "label_path = 'models/open-images-model-labels.txt'\n",
        "\n",
        "class_names = [name.strip() for name in open(label_path).readlines()]\n",
        "\n",
        "\n",
        "net = create_mobilenetv1_ssd(len(class_names), is_test=True)\n",
        "net.load(model_path)\n",
        "net.eval()\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "model_onnx_path = f\"models/mb1-ssd-10.onnx\"\n",
        "\n",
        "x = torch.randn(1, 3, 300, 300, requires_grad=True).to(device)\n",
        "\n",
        "torch.onnx.export(net,\n",
        "                  x,\n",
        "                  model_onnx_path,\n",
        "                  verbose=False,\n",
        "                  export_params=True,\n",
        "                  output_names=['scores', 'boxes'],\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                                'output' : {0 : 'batch_size'}})\n",
        "\n",
        "# Load the ONNX model and print a message\n",
        "model = onnx.load(model_onnx_path)\n",
        "print(f\"File saved: {model_onnx_path}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DijaeTkONY05"
      },
      "source": [
        "### 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmHZ0rB8mOMJ",
        "outputId": "1e4c3f7a-5aaa-4f0e-eb89-3dd311009a7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Check\n"
          ]
        }
      ],
      "source": [
        "\n",
        "onnx_model = onnx.load(\"models/mb1-ssd-10.onnx\")\n",
        "\n",
        "# Check\n",
        "onnx.checker.check_model(onnx_model)\n",
        "print(\"Check\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ujf8NqyNY05"
      },
      "source": [
        "### 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppOR6EW9meY3",
        "outputId": "bfe58dc8-bb96-47b6-ca3f-2ed10cd91ab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "graph torch_jit (\n",
            "  %input[FLOAT, batch_sizex3x300x300]\n",
            ") initializers (\n",
            "  %extras.0.0.weight[FLOAT, 256x1024x1x1]\n",
            "  %extras.0.0.bias[FLOAT, 256]\n",
            "  %extras.0.2.weight[FLOAT, 512x256x3x3]\n",
            "  %extras.0.2.bias[FLOAT, 512]\n",
            "  %extras.1.0.weight[FLOAT, 128x512x1x1]\n",
            "  %extras.1.0.bias[FLOAT, 128]\n",
            "  %extras.1.2.weight[FLOAT, 256x128x3x3]\n",
            "  %extras.1.2.bias[FLOAT, 256]\n",
            "  %extras.2.0.weight[FLOAT, 128x256x1x1]\n",
            "  %extras.2.0.bias[FLOAT, 128]\n",
            "  %extras.2.2.weight[FLOAT, 256x128x3x3]\n",
            "  %extras.2.2.bias[FLOAT, 256]\n",
            "  %extras.3.0.weight[FLOAT, 128x256x1x1]\n",
            "  %extras.3.0.bias[FLOAT, 128]\n",
            "  %extras.3.2.weight[FLOAT, 256x128x3x3]\n",
            "  %extras.3.2.bias[FLOAT, 256]\n",
            "  %classification_headers.0.weight[FLOAT, 18x512x3x3]\n",
            "  %classification_headers.0.bias[FLOAT, 18]\n",
            "  %classification_headers.1.weight[FLOAT, 18x1024x3x3]\n",
            "  %classification_headers.1.bias[FLOAT, 18]\n",
            "  %classification_headers.2.weight[FLOAT, 18x512x3x3]\n",
            "  %classification_headers.2.bias[FLOAT, 18]\n",
            "  %classification_headers.3.weight[FLOAT, 18x256x3x3]\n",
            "  %classification_headers.3.bias[FLOAT, 18]\n",
            "  %classification_headers.4.weight[FLOAT, 18x256x3x3]\n",
            "  %classification_headers.4.bias[FLOAT, 18]\n",
            "  %classification_headers.5.weight[FLOAT, 18x256x3x3]\n",
            "  %classification_headers.5.bias[FLOAT, 18]\n",
            "  %regression_headers.0.weight[FLOAT, 24x512x3x3]\n",
            "  %regression_headers.0.bias[FLOAT, 24]\n",
            "  %regression_headers.1.weight[FLOAT, 24x1024x3x3]\n",
            "  %regression_headers.1.bias[FLOAT, 24]\n",
            "  %regression_headers.2.weight[FLOAT, 24x512x3x3]\n",
            "  %regression_headers.2.bias[FLOAT, 24]\n",
            "  %regression_headers.3.weight[FLOAT, 24x256x3x3]\n",
            "  %regression_headers.3.bias[FLOAT, 24]\n",
            "  %regression_headers.4.weight[FLOAT, 24x256x3x3]\n",
            "  %regression_headers.4.bias[FLOAT, 24]\n",
            "  %regression_headers.5.weight[FLOAT, 24x256x3x3]\n",
            "  %regression_headers.5.bias[FLOAT, 24]\n",
            "  %onnx::Conv_500[FLOAT, 32x3x3x3]\n",
            "  %onnx::Conv_501[FLOAT, 32]\n",
            "  %onnx::Conv_503[FLOAT, 32x1x3x3]\n",
            "  %onnx::Conv_504[FLOAT, 32]\n",
            "  %onnx::Conv_506[FLOAT, 64x32x1x1]\n",
            "  %onnx::Conv_507[FLOAT, 64]\n",
            "  %onnx::Conv_509[FLOAT, 64x1x3x3]\n",
            "  %onnx::Conv_510[FLOAT, 64]\n",
            "  %onnx::Conv_512[FLOAT, 128x64x1x1]\n",
            "  %onnx::Conv_513[FLOAT, 128]\n",
            "  %onnx::Conv_515[FLOAT, 128x1x3x3]\n",
            "  %onnx::Conv_516[FLOAT, 128]\n",
            "  %onnx::Conv_518[FLOAT, 128x128x1x1]\n",
            "  %onnx::Conv_519[FLOAT, 128]\n",
            "  %onnx::Conv_521[FLOAT, 128x1x3x3]\n",
            "  %onnx::Conv_522[FLOAT, 128]\n",
            "  %onnx::Conv_524[FLOAT, 256x128x1x1]\n",
            "  %onnx::Conv_525[FLOAT, 256]\n",
            "  %onnx::Conv_527[FLOAT, 256x1x3x3]\n",
            "  %onnx::Conv_528[FLOAT, 256]\n",
            "  %onnx::Conv_530[FLOAT, 256x256x1x1]\n",
            "  %onnx::Conv_531[FLOAT, 256]\n",
            "  %onnx::Conv_533[FLOAT, 256x1x3x3]\n",
            "  %onnx::Conv_534[FLOAT, 256]\n",
            "  %onnx::Conv_536[FLOAT, 512x256x1x1]\n",
            "  %onnx::Conv_537[FLOAT, 512]\n",
            "  %onnx::Conv_539[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_540[FLOAT, 512]\n",
            "  %onnx::Conv_542[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_543[FLOAT, 512]\n",
            "  %onnx::Conv_545[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_546[FLOAT, 512]\n",
            "  %onnx::Conv_548[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_549[FLOAT, 512]\n",
            "  %onnx::Conv_551[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_552[FLOAT, 512]\n",
            "  %onnx::Conv_554[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_555[FLOAT, 512]\n",
            "  %onnx::Conv_557[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_558[FLOAT, 512]\n",
            "  %onnx::Conv_560[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_561[FLOAT, 512]\n",
            "  %onnx::Conv_563[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_564[FLOAT, 512]\n",
            "  %onnx::Conv_566[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_567[FLOAT, 512]\n",
            "  %onnx::Conv_569[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_570[FLOAT, 512]\n",
            "  %onnx::Conv_572[FLOAT, 1024x512x1x1]\n",
            "  %onnx::Conv_573[FLOAT, 1024]\n",
            "  %onnx::Conv_575[FLOAT, 1024x1x3x3]\n",
            "  %onnx::Conv_576[FLOAT, 1024]\n",
            "  %onnx::Conv_578[FLOAT, 1024x1024x1x1]\n",
            "  %onnx::Conv_579[FLOAT, 1024]\n",
            ") {\n",
            "  %/base_net.0/base_net.0.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%input, %onnx::Conv_500, %onnx::Conv_501)\n",
            "  %/base_net.0/base_net.0.2/Relu_output_0 = Relu(%/base_net.0/base_net.0.0/Conv_output_0)\n",
            "  %/base_net.1/base_net.1.0/Conv_output_0 = Conv[dilations = [1, 1], group = 32, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.0/base_net.0.2/Relu_output_0, %onnx::Conv_503, %onnx::Conv_504)\n",
            "  %/base_net.1/base_net.1.2/Relu_output_0 = Relu(%/base_net.1/base_net.1.0/Conv_output_0)\n",
            "  %/base_net.1/base_net.1.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.1/base_net.1.2/Relu_output_0, %onnx::Conv_506, %onnx::Conv_507)\n",
            "  %/base_net.1/base_net.1.5/Relu_output_0 = Relu(%/base_net.1/base_net.1.3/Conv_output_0)\n",
            "  %/base_net.2/base_net.2.0/Conv_output_0 = Conv[dilations = [1, 1], group = 64, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.1/base_net.1.5/Relu_output_0, %onnx::Conv_509, %onnx::Conv_510)\n",
            "  %/base_net.2/base_net.2.2/Relu_output_0 = Relu(%/base_net.2/base_net.2.0/Conv_output_0)\n",
            "  %/base_net.2/base_net.2.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.2/base_net.2.2/Relu_output_0, %onnx::Conv_512, %onnx::Conv_513)\n",
            "  %/base_net.2/base_net.2.5/Relu_output_0 = Relu(%/base_net.2/base_net.2.3/Conv_output_0)\n",
            "  %/base_net.3/base_net.3.0/Conv_output_0 = Conv[dilations = [1, 1], group = 128, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.2/base_net.2.5/Relu_output_0, %onnx::Conv_515, %onnx::Conv_516)\n",
            "  %/base_net.3/base_net.3.2/Relu_output_0 = Relu(%/base_net.3/base_net.3.0/Conv_output_0)\n",
            "  %/base_net.3/base_net.3.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.3/base_net.3.2/Relu_output_0, %onnx::Conv_518, %onnx::Conv_519)\n",
            "  %/base_net.3/base_net.3.5/Relu_output_0 = Relu(%/base_net.3/base_net.3.3/Conv_output_0)\n",
            "  %/base_net.4/base_net.4.0/Conv_output_0 = Conv[dilations = [1, 1], group = 128, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.3/base_net.3.5/Relu_output_0, %onnx::Conv_521, %onnx::Conv_522)\n",
            "  %/base_net.4/base_net.4.2/Relu_output_0 = Relu(%/base_net.4/base_net.4.0/Conv_output_0)\n",
            "  %/base_net.4/base_net.4.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.4/base_net.4.2/Relu_output_0, %onnx::Conv_524, %onnx::Conv_525)\n",
            "  %/base_net.4/base_net.4.5/Relu_output_0 = Relu(%/base_net.4/base_net.4.3/Conv_output_0)\n",
            "  %/base_net.5/base_net.5.0/Conv_output_0 = Conv[dilations = [1, 1], group = 256, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.4/base_net.4.5/Relu_output_0, %onnx::Conv_527, %onnx::Conv_528)\n",
            "  %/base_net.5/base_net.5.2/Relu_output_0 = Relu(%/base_net.5/base_net.5.0/Conv_output_0)\n",
            "  %/base_net.5/base_net.5.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.5/base_net.5.2/Relu_output_0, %onnx::Conv_530, %onnx::Conv_531)\n",
            "  %/base_net.5/base_net.5.5/Relu_output_0 = Relu(%/base_net.5/base_net.5.3/Conv_output_0)\n",
            "  %/base_net.6/base_net.6.0/Conv_output_0 = Conv[dilations = [1, 1], group = 256, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.5/base_net.5.5/Relu_output_0, %onnx::Conv_533, %onnx::Conv_534)\n",
            "  %/base_net.6/base_net.6.2/Relu_output_0 = Relu(%/base_net.6/base_net.6.0/Conv_output_0)\n",
            "  %/base_net.6/base_net.6.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.6/base_net.6.2/Relu_output_0, %onnx::Conv_536, %onnx::Conv_537)\n",
            "  %/base_net.6/base_net.6.5/Relu_output_0 = Relu(%/base_net.6/base_net.6.3/Conv_output_0)\n",
            "  %/base_net.7/base_net.7.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.6/base_net.6.5/Relu_output_0, %onnx::Conv_539, %onnx::Conv_540)\n",
            "  %/base_net.7/base_net.7.2/Relu_output_0 = Relu(%/base_net.7/base_net.7.0/Conv_output_0)\n",
            "  %/base_net.7/base_net.7.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.7/base_net.7.2/Relu_output_0, %onnx::Conv_542, %onnx::Conv_543)\n",
            "  %/base_net.7/base_net.7.5/Relu_output_0 = Relu(%/base_net.7/base_net.7.3/Conv_output_0)\n",
            "  %/base_net.8/base_net.8.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.7/base_net.7.5/Relu_output_0, %onnx::Conv_545, %onnx::Conv_546)\n",
            "  %/base_net.8/base_net.8.2/Relu_output_0 = Relu(%/base_net.8/base_net.8.0/Conv_output_0)\n",
            "  %/base_net.8/base_net.8.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.8/base_net.8.2/Relu_output_0, %onnx::Conv_548, %onnx::Conv_549)\n",
            "  %/base_net.8/base_net.8.5/Relu_output_0 = Relu(%/base_net.8/base_net.8.3/Conv_output_0)\n",
            "  %/base_net.9/base_net.9.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.8/base_net.8.5/Relu_output_0, %onnx::Conv_551, %onnx::Conv_552)\n",
            "  %/base_net.9/base_net.9.2/Relu_output_0 = Relu(%/base_net.9/base_net.9.0/Conv_output_0)\n",
            "  %/base_net.9/base_net.9.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.9/base_net.9.2/Relu_output_0, %onnx::Conv_554, %onnx::Conv_555)\n",
            "  %/base_net.9/base_net.9.5/Relu_output_0 = Relu(%/base_net.9/base_net.9.3/Conv_output_0)\n",
            "  %/base_net.10/base_net.10.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.9/base_net.9.5/Relu_output_0, %onnx::Conv_557, %onnx::Conv_558)\n",
            "  %/base_net.10/base_net.10.2/Relu_output_0 = Relu(%/base_net.10/base_net.10.0/Conv_output_0)\n",
            "  %/base_net.10/base_net.10.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.10/base_net.10.2/Relu_output_0, %onnx::Conv_560, %onnx::Conv_561)\n",
            "  %/base_net.10/base_net.10.5/Relu_output_0 = Relu(%/base_net.10/base_net.10.3/Conv_output_0)\n",
            "  %/base_net.11/base_net.11.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.10/base_net.10.5/Relu_output_0, %onnx::Conv_563, %onnx::Conv_564)\n",
            "  %/base_net.11/base_net.11.2/Relu_output_0 = Relu(%/base_net.11/base_net.11.0/Conv_output_0)\n",
            "  %/base_net.11/base_net.11.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.11/base_net.11.2/Relu_output_0, %onnx::Conv_566, %onnx::Conv_567)\n",
            "  %/base_net.11/base_net.11.5/Relu_output_0 = Relu(%/base_net.11/base_net.11.3/Conv_output_0)\n",
            "  %/classification_headers.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.11/base_net.11.5/Relu_output_0, %classification_headers.0.weight, %classification_headers.0.bias)\n",
            "  %/Transpose_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.0/Conv_output_0)\n",
            "  %/Shape_output_0 = Shape(%/Transpose_output_0)\n",
            "  %/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_output_0 = Gather[axis = 0](%/Shape_output_0, %/Constant_output_0)\n",
            "  %onnx::Unsqueeze_279 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_output_0 = Unsqueeze(%/Gather_output_0, %onnx::Unsqueeze_279)\n",
            "  %/Constant_1_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_2_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_output_0 = Concat[axis = 0](%/Unsqueeze_output_0, %/Constant_1_output_0, %/Constant_2_output_0)\n",
            "  %/Reshape_output_0 = Reshape[allowzero = 0](%/Transpose_output_0, %/Concat_output_0)\n",
            "  %/regression_headers.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.11/base_net.11.5/Relu_output_0, %regression_headers.0.weight, %regression_headers.0.bias)\n",
            "  %/Transpose_1_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.0/Conv_output_0)\n",
            "  %/Shape_1_output_0 = Shape(%/Transpose_1_output_0)\n",
            "  %/Constant_3_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_1_output_0 = Gather[axis = 0](%/Shape_1_output_0, %/Constant_3_output_0)\n",
            "  %onnx::Unsqueeze_293 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_1_output_0 = Unsqueeze(%/Gather_1_output_0, %onnx::Unsqueeze_293)\n",
            "  %/Constant_4_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_5_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_1_output_0 = Concat[axis = 0](%/Unsqueeze_1_output_0, %/Constant_4_output_0, %/Constant_5_output_0)\n",
            "  %/Reshape_1_output_0 = Reshape[allowzero = 0](%/Transpose_1_output_0, %/Concat_1_output_0)\n",
            "  %/base_net.12/base_net.12.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.11/base_net.11.5/Relu_output_0, %onnx::Conv_569, %onnx::Conv_570)\n",
            "  %/base_net.12/base_net.12.2/Relu_output_0 = Relu(%/base_net.12/base_net.12.0/Conv_output_0)\n",
            "  %/base_net.12/base_net.12.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.12/base_net.12.2/Relu_output_0, %onnx::Conv_572, %onnx::Conv_573)\n",
            "  %/base_net.12/base_net.12.5/Relu_output_0 = Relu(%/base_net.12/base_net.12.3/Conv_output_0)\n",
            "  %/base_net.13/base_net.13.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1024, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.12/base_net.12.5/Relu_output_0, %onnx::Conv_575, %onnx::Conv_576)\n",
            "  %/base_net.13/base_net.13.2/Relu_output_0 = Relu(%/base_net.13/base_net.13.0/Conv_output_0)\n",
            "  %/base_net.13/base_net.13.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.13/base_net.13.2/Relu_output_0, %onnx::Conv_578, %onnx::Conv_579)\n",
            "  %/base_net.13/base_net.13.5/Relu_output_0 = Relu(%/base_net.13/base_net.13.3/Conv_output_0)\n",
            "  %/classification_headers.1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.13/base_net.13.5/Relu_output_0, %classification_headers.1.weight, %classification_headers.1.bias)\n",
            "  %/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.1/Conv_output_0)\n",
            "  %/Shape_2_output_0 = Shape(%/Transpose_2_output_0)\n",
            "  %/Constant_6_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_2_output_0 = Gather[axis = 0](%/Shape_2_output_0, %/Constant_6_output_0)\n",
            "  %onnx::Unsqueeze_318 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_2_output_0 = Unsqueeze(%/Gather_2_output_0, %onnx::Unsqueeze_318)\n",
            "  %/Constant_7_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_8_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_2_output_0 = Concat[axis = 0](%/Unsqueeze_2_output_0, %/Constant_7_output_0, %/Constant_8_output_0)\n",
            "  %/Reshape_2_output_0 = Reshape[allowzero = 0](%/Transpose_2_output_0, %/Concat_2_output_0)\n",
            "  %/regression_headers.1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.13/base_net.13.5/Relu_output_0, %regression_headers.1.weight, %regression_headers.1.bias)\n",
            "  %/Transpose_3_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.1/Conv_output_0)\n",
            "  %/Shape_3_output_0 = Shape(%/Transpose_3_output_0)\n",
            "  %/Constant_9_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_3_output_0 = Gather[axis = 0](%/Shape_3_output_0, %/Constant_9_output_0)\n",
            "  %onnx::Unsqueeze_331 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_3_output_0 = Unsqueeze(%/Gather_3_output_0, %onnx::Unsqueeze_331)\n",
            "  %/Constant_10_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_11_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_3_output_0 = Concat[axis = 0](%/Unsqueeze_3_output_0, %/Constant_10_output_0, %/Constant_11_output_0)\n",
            "  %/Reshape_3_output_0 = Reshape[allowzero = 0](%/Transpose_3_output_0, %/Concat_3_output_0)\n",
            "  %/extras.0/extras.0.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.13/base_net.13.5/Relu_output_0, %extras.0.0.weight, %extras.0.0.bias)\n",
            "  %/extras.0/extras.0.1/Relu_output_0 = Relu(%/extras.0/extras.0.0/Conv_output_0)\n",
            "  %/extras.0/extras.0.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.0/extras.0.1/Relu_output_0, %extras.0.2.weight, %extras.0.2.bias)\n",
            "  %/extras.0/extras.0.3/Relu_output_0 = Relu(%/extras.0/extras.0.2/Conv_output_0)\n",
            "  %/classification_headers.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.0/extras.0.3/Relu_output_0, %classification_headers.2.weight, %classification_headers.2.bias)\n",
            "  %/Transpose_4_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.2/Conv_output_0)\n",
            "  %/Shape_4_output_0 = Shape(%/Transpose_4_output_0)\n",
            "  %/Constant_12_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_4_output_0 = Gather[axis = 0](%/Shape_4_output_0, %/Constant_12_output_0)\n",
            "  %onnx::Unsqueeze_348 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_4_output_0 = Unsqueeze(%/Gather_4_output_0, %onnx::Unsqueeze_348)\n",
            "  %/Constant_13_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_14_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_4_output_0 = Concat[axis = 0](%/Unsqueeze_4_output_0, %/Constant_13_output_0, %/Constant_14_output_0)\n",
            "  %/Reshape_4_output_0 = Reshape[allowzero = 0](%/Transpose_4_output_0, %/Concat_4_output_0)\n",
            "  %/regression_headers.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.0/extras.0.3/Relu_output_0, %regression_headers.2.weight, %regression_headers.2.bias)\n",
            "  %/Transpose_5_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.2/Conv_output_0)\n",
            "  %/Shape_5_output_0 = Shape(%/Transpose_5_output_0)\n",
            "  %/Constant_15_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_5_output_0 = Gather[axis = 0](%/Shape_5_output_0, %/Constant_15_output_0)\n",
            "  %onnx::Unsqueeze_361 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_5_output_0 = Unsqueeze(%/Gather_5_output_0, %onnx::Unsqueeze_361)\n",
            "  %/Constant_16_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_17_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_5_output_0 = Concat[axis = 0](%/Unsqueeze_5_output_0, %/Constant_16_output_0, %/Constant_17_output_0)\n",
            "  %/Reshape_5_output_0 = Reshape[allowzero = 0](%/Transpose_5_output_0, %/Concat_5_output_0)\n",
            "  %/extras.1/extras.1.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/extras.0/extras.0.3/Relu_output_0, %extras.1.0.weight, %extras.1.0.bias)\n",
            "  %/extras.1/extras.1.1/Relu_output_0 = Relu(%/extras.1/extras.1.0/Conv_output_0)\n",
            "  %/extras.1/extras.1.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.1/extras.1.1/Relu_output_0, %extras.1.2.weight, %extras.1.2.bias)\n",
            "  %/extras.1/extras.1.3/Relu_output_0 = Relu(%/extras.1/extras.1.2/Conv_output_0)\n",
            "  %/classification_headers.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.1/extras.1.3/Relu_output_0, %classification_headers.3.weight, %classification_headers.3.bias)\n",
            "  %/Transpose_6_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.3/Conv_output_0)\n",
            "  %/Shape_6_output_0 = Shape(%/Transpose_6_output_0)\n",
            "  %/Constant_18_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_6_output_0 = Gather[axis = 0](%/Shape_6_output_0, %/Constant_18_output_0)\n",
            "  %onnx::Unsqueeze_378 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_6_output_0 = Unsqueeze(%/Gather_6_output_0, %onnx::Unsqueeze_378)\n",
            "  %/Constant_19_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_20_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_6_output_0 = Concat[axis = 0](%/Unsqueeze_6_output_0, %/Constant_19_output_0, %/Constant_20_output_0)\n",
            "  %/Reshape_6_output_0 = Reshape[allowzero = 0](%/Transpose_6_output_0, %/Concat_6_output_0)\n",
            "  %/regression_headers.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.1/extras.1.3/Relu_output_0, %regression_headers.3.weight, %regression_headers.3.bias)\n",
            "  %/Transpose_7_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.3/Conv_output_0)\n",
            "  %/Shape_7_output_0 = Shape(%/Transpose_7_output_0)\n",
            "  %/Constant_21_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_7_output_0 = Gather[axis = 0](%/Shape_7_output_0, %/Constant_21_output_0)\n",
            "  %onnx::Unsqueeze_391 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_7_output_0 = Unsqueeze(%/Gather_7_output_0, %onnx::Unsqueeze_391)\n",
            "  %/Constant_22_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_23_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_7_output_0 = Concat[axis = 0](%/Unsqueeze_7_output_0, %/Constant_22_output_0, %/Constant_23_output_0)\n",
            "  %/Reshape_7_output_0 = Reshape[allowzero = 0](%/Transpose_7_output_0, %/Concat_7_output_0)\n",
            "  %/extras.2/extras.2.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/extras.1/extras.1.3/Relu_output_0, %extras.2.0.weight, %extras.2.0.bias)\n",
            "  %/extras.2/extras.2.1/Relu_output_0 = Relu(%/extras.2/extras.2.0/Conv_output_0)\n",
            "  %/extras.2/extras.2.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.2/extras.2.1/Relu_output_0, %extras.2.2.weight, %extras.2.2.bias)\n",
            "  %/extras.2/extras.2.3/Relu_output_0 = Relu(%/extras.2/extras.2.2/Conv_output_0)\n",
            "  %/classification_headers.4/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.2/extras.2.3/Relu_output_0, %classification_headers.4.weight, %classification_headers.4.bias)\n",
            "  %/Transpose_8_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.4/Conv_output_0)\n",
            "  %/Shape_8_output_0 = Shape(%/Transpose_8_output_0)\n",
            "  %/Constant_24_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_8_output_0 = Gather[axis = 0](%/Shape_8_output_0, %/Constant_24_output_0)\n",
            "  %onnx::Unsqueeze_408 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_8_output_0 = Unsqueeze(%/Gather_8_output_0, %onnx::Unsqueeze_408)\n",
            "  %/Constant_25_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_26_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_8_output_0 = Concat[axis = 0](%/Unsqueeze_8_output_0, %/Constant_25_output_0, %/Constant_26_output_0)\n",
            "  %/Reshape_8_output_0 = Reshape[allowzero = 0](%/Transpose_8_output_0, %/Concat_8_output_0)\n",
            "  %/regression_headers.4/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.2/extras.2.3/Relu_output_0, %regression_headers.4.weight, %regression_headers.4.bias)\n",
            "  %/Transpose_9_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.4/Conv_output_0)\n",
            "  %/Shape_9_output_0 = Shape(%/Transpose_9_output_0)\n",
            "  %/Constant_27_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_9_output_0 = Gather[axis = 0](%/Shape_9_output_0, %/Constant_27_output_0)\n",
            "  %onnx::Unsqueeze_421 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_9_output_0 = Unsqueeze(%/Gather_9_output_0, %onnx::Unsqueeze_421)\n",
            "  %/Constant_28_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_29_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_9_output_0 = Concat[axis = 0](%/Unsqueeze_9_output_0, %/Constant_28_output_0, %/Constant_29_output_0)\n",
            "  %/Reshape_9_output_0 = Reshape[allowzero = 0](%/Transpose_9_output_0, %/Concat_9_output_0)\n",
            "  %/extras.3/extras.3.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/extras.2/extras.2.3/Relu_output_0, %extras.3.0.weight, %extras.3.0.bias)\n",
            "  %/extras.3/extras.3.1/Relu_output_0 = Relu(%/extras.3/extras.3.0/Conv_output_0)\n",
            "  %/extras.3/extras.3.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.3/extras.3.1/Relu_output_0, %extras.3.2.weight, %extras.3.2.bias)\n",
            "  %/extras.3/extras.3.3/Relu_output_0 = Relu(%/extras.3/extras.3.2/Conv_output_0)\n",
            "  %/classification_headers.5/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.3/extras.3.3/Relu_output_0, %classification_headers.5.weight, %classification_headers.5.bias)\n",
            "  %/Transpose_10_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.5/Conv_output_0)\n",
            "  %/Shape_10_output_0 = Shape(%/Transpose_10_output_0)\n",
            "  %/Constant_30_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_10_output_0 = Gather[axis = 0](%/Shape_10_output_0, %/Constant_30_output_0)\n",
            "  %onnx::Unsqueeze_438 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_10_output_0 = Unsqueeze(%/Gather_10_output_0, %onnx::Unsqueeze_438)\n",
            "  %/Constant_31_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_32_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_10_output_0 = Concat[axis = 0](%/Unsqueeze_10_output_0, %/Constant_31_output_0, %/Constant_32_output_0)\n",
            "  %/Reshape_10_output_0 = Reshape[allowzero = 0](%/Transpose_10_output_0, %/Concat_10_output_0)\n",
            "  %/regression_headers.5/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.3/extras.3.3/Relu_output_0, %regression_headers.5.weight, %regression_headers.5.bias)\n",
            "  %/Transpose_11_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.5/Conv_output_0)\n",
            "  %/Shape_11_output_0 = Shape(%/Transpose_11_output_0)\n",
            "  %/Constant_33_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_11_output_0 = Gather[axis = 0](%/Shape_11_output_0, %/Constant_33_output_0)\n",
            "  %onnx::Unsqueeze_451 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_11_output_0 = Unsqueeze(%/Gather_11_output_0, %onnx::Unsqueeze_451)\n",
            "  %/Constant_34_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_35_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_11_output_0 = Concat[axis = 0](%/Unsqueeze_11_output_0, %/Constant_34_output_0, %/Constant_35_output_0)\n",
            "  %/Reshape_11_output_0 = Reshape[allowzero = 0](%/Transpose_11_output_0, %/Concat_11_output_0)\n",
            "  %/Concat_12_output_0 = Concat[axis = 1](%/Reshape_output_0, %/Reshape_2_output_0, %/Reshape_4_output_0, %/Reshape_6_output_0, %/Reshape_8_output_0, %/Reshape_10_output_0)\n",
            "  %/Concat_13_output_0 = Concat[axis = 1](%/Reshape_1_output_0, %/Reshape_3_output_0, %/Reshape_5_output_0, %/Reshape_7_output_0, %/Reshape_9_output_0, %/Reshape_11_output_0)\n",
            "  %scores = Softmax[axis = 2](%/Concat_12_output_0)\n",
            "  %/Constant_36_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_37_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_38_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_39_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_output_0 = Slice(%/Concat_13_output_0, %/Constant_37_output_0, %/Constant_38_output_0, %/Constant_36_output_0, %/Constant_39_output_0)\n",
            "  %/Constant_40_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Mul_output_0 = Mul(%/Slice_output_0, %/Constant_40_output_0)\n",
            "  %/Constant_41_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Mul_1_output_0 = Mul(%/Mul_output_0, %/Constant_41_output_0)\n",
            "  %/Constant_42_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Add_output_0 = Add(%/Mul_1_output_0, %/Constant_42_output_0)\n",
            "  %/Constant_43_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_44_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_45_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_46_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_1_output_0 = Slice(%/Concat_13_output_0, %/Constant_44_output_0, %/Constant_45_output_0, %/Constant_43_output_0, %/Constant_46_output_0)\n",
            "  %/Constant_47_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Mul_2_output_0 = Mul(%/Slice_1_output_0, %/Constant_47_output_0)\n",
            "  %/Exp_output_0 = Exp(%/Mul_2_output_0)\n",
            "  %/Constant_48_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Mul_3_output_0 = Mul(%/Exp_output_0, %/Constant_48_output_0)\n",
            "  %/Concat_14_output_0 = Concat[axis = 2](%/Add_output_0, %/Mul_3_output_0)\n",
            "  %/Constant_49_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_50_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_51_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_52_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_2_output_0 = Slice(%/Concat_14_output_0, %/Constant_50_output_0, %/Constant_51_output_0, %/Constant_49_output_0, %/Constant_52_output_0)\n",
            "  %/Constant_53_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_54_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_55_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_56_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_3_output_0 = Slice(%/Concat_14_output_0, %/Constant_54_output_0, %/Constant_55_output_0, %/Constant_53_output_0, %/Constant_56_output_0)\n",
            "  %/Constant_57_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Div_output_0 = Div(%/Slice_3_output_0, %/Constant_57_output_0)\n",
            "  %/Sub_output_0 = Sub(%/Slice_2_output_0, %/Div_output_0)\n",
            "  %/Add_1_output_0 = Add(%/Slice_2_output_0, %/Div_output_0)\n",
            "  %boxes = Concat[axis = 2](%/Sub_output_0, %/Add_1_output_0)\n",
            "  return %scores, %boxes\n",
            "}\n",
            "(1, 3000, 3)\n",
            "(1, 3000, 4)\n"
          ]
        }
      ],
      "source": [
        "import onnx\n",
        "import onnxruntime\n",
        "\n",
        "onnx_model = onnx.load(model_onnx_path)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "print(onnx.helper.printable_graph(onnx_model.graph))\n",
        "ort_session = onnxruntime.InferenceSession(model_onnx_path)\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "print(ort_outs[0].shape)\n",
        "print(ort_outs[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdmtAA3eNY05"
      },
      "source": [
        "### 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrwKWqMAnMqz",
        "outputId": "ddb9c85c-859c-49ad-a086-fe12d4c8d36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "graph torch_jit (\n",
            "  %input[FLOAT, batch_sizex3x300x300]\n",
            ") initializers (\n",
            "  %extras.0.0.weight[FLOAT, 256x1024x1x1]\n",
            "  %extras.0.0.bias[FLOAT, 256]\n",
            "  %extras.0.2.weight[FLOAT, 512x256x3x3]\n",
            "  %extras.0.2.bias[FLOAT, 512]\n",
            "  %extras.1.0.weight[FLOAT, 128x512x1x1]\n",
            "  %extras.1.0.bias[FLOAT, 128]\n",
            "  %extras.1.2.weight[FLOAT, 256x128x3x3]\n",
            "  %extras.1.2.bias[FLOAT, 256]\n",
            "  %extras.2.0.weight[FLOAT, 128x256x1x1]\n",
            "  %extras.2.0.bias[FLOAT, 128]\n",
            "  %extras.2.2.weight[FLOAT, 256x128x3x3]\n",
            "  %extras.2.2.bias[FLOAT, 256]\n",
            "  %extras.3.0.weight[FLOAT, 128x256x1x1]\n",
            "  %extras.3.0.bias[FLOAT, 128]\n",
            "  %extras.3.2.weight[FLOAT, 256x128x3x3]\n",
            "  %extras.3.2.bias[FLOAT, 256]\n",
            "  %classification_headers.0.weight[FLOAT, 18x512x3x3]\n",
            "  %classification_headers.0.bias[FLOAT, 18]\n",
            "  %classification_headers.1.weight[FLOAT, 18x1024x3x3]\n",
            "  %classification_headers.1.bias[FLOAT, 18]\n",
            "  %classification_headers.2.weight[FLOAT, 18x512x3x3]\n",
            "  %classification_headers.2.bias[FLOAT, 18]\n",
            "  %classification_headers.3.weight[FLOAT, 18x256x3x3]\n",
            "  %classification_headers.3.bias[FLOAT, 18]\n",
            "  %classification_headers.4.weight[FLOAT, 18x256x3x3]\n",
            "  %classification_headers.4.bias[FLOAT, 18]\n",
            "  %classification_headers.5.weight[FLOAT, 18x256x3x3]\n",
            "  %classification_headers.5.bias[FLOAT, 18]\n",
            "  %regression_headers.0.weight[FLOAT, 24x512x3x3]\n",
            "  %regression_headers.0.bias[FLOAT, 24]\n",
            "  %regression_headers.1.weight[FLOAT, 24x1024x3x3]\n",
            "  %regression_headers.1.bias[FLOAT, 24]\n",
            "  %regression_headers.2.weight[FLOAT, 24x512x3x3]\n",
            "  %regression_headers.2.bias[FLOAT, 24]\n",
            "  %regression_headers.3.weight[FLOAT, 24x256x3x3]\n",
            "  %regression_headers.3.bias[FLOAT, 24]\n",
            "  %regression_headers.4.weight[FLOAT, 24x256x3x3]\n",
            "  %regression_headers.4.bias[FLOAT, 24]\n",
            "  %regression_headers.5.weight[FLOAT, 24x256x3x3]\n",
            "  %regression_headers.5.bias[FLOAT, 24]\n",
            "  %onnx::Conv_500[FLOAT, 32x3x3x3]\n",
            "  %onnx::Conv_501[FLOAT, 32]\n",
            "  %onnx::Conv_503[FLOAT, 32x1x3x3]\n",
            "  %onnx::Conv_504[FLOAT, 32]\n",
            "  %onnx::Conv_506[FLOAT, 64x32x1x1]\n",
            "  %onnx::Conv_507[FLOAT, 64]\n",
            "  %onnx::Conv_509[FLOAT, 64x1x3x3]\n",
            "  %onnx::Conv_510[FLOAT, 64]\n",
            "  %onnx::Conv_512[FLOAT, 128x64x1x1]\n",
            "  %onnx::Conv_513[FLOAT, 128]\n",
            "  %onnx::Conv_515[FLOAT, 128x1x3x3]\n",
            "  %onnx::Conv_516[FLOAT, 128]\n",
            "  %onnx::Conv_518[FLOAT, 128x128x1x1]\n",
            "  %onnx::Conv_519[FLOAT, 128]\n",
            "  %onnx::Conv_521[FLOAT, 128x1x3x3]\n",
            "  %onnx::Conv_522[FLOAT, 128]\n",
            "  %onnx::Conv_524[FLOAT, 256x128x1x1]\n",
            "  %onnx::Conv_525[FLOAT, 256]\n",
            "  %onnx::Conv_527[FLOAT, 256x1x3x3]\n",
            "  %onnx::Conv_528[FLOAT, 256]\n",
            "  %onnx::Conv_530[FLOAT, 256x256x1x1]\n",
            "  %onnx::Conv_531[FLOAT, 256]\n",
            "  %onnx::Conv_533[FLOAT, 256x1x3x3]\n",
            "  %onnx::Conv_534[FLOAT, 256]\n",
            "  %onnx::Conv_536[FLOAT, 512x256x1x1]\n",
            "  %onnx::Conv_537[FLOAT, 512]\n",
            "  %onnx::Conv_539[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_540[FLOAT, 512]\n",
            "  %onnx::Conv_542[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_543[FLOAT, 512]\n",
            "  %onnx::Conv_545[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_546[FLOAT, 512]\n",
            "  %onnx::Conv_548[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_549[FLOAT, 512]\n",
            "  %onnx::Conv_551[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_552[FLOAT, 512]\n",
            "  %onnx::Conv_554[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_555[FLOAT, 512]\n",
            "  %onnx::Conv_557[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_558[FLOAT, 512]\n",
            "  %onnx::Conv_560[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_561[FLOAT, 512]\n",
            "  %onnx::Conv_563[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_564[FLOAT, 512]\n",
            "  %onnx::Conv_566[FLOAT, 512x512x1x1]\n",
            "  %onnx::Conv_567[FLOAT, 512]\n",
            "  %onnx::Conv_569[FLOAT, 512x1x3x3]\n",
            "  %onnx::Conv_570[FLOAT, 512]\n",
            "  %onnx::Conv_572[FLOAT, 1024x512x1x1]\n",
            "  %onnx::Conv_573[FLOAT, 1024]\n",
            "  %onnx::Conv_575[FLOAT, 1024x1x3x3]\n",
            "  %onnx::Conv_576[FLOAT, 1024]\n",
            "  %onnx::Conv_578[FLOAT, 1024x1024x1x1]\n",
            "  %onnx::Conv_579[FLOAT, 1024]\n",
            ") {\n",
            "  %/base_net.0/base_net.0.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%input, %onnx::Conv_500, %onnx::Conv_501)\n",
            "  %/base_net.0/base_net.0.2/Relu_output_0 = Relu(%/base_net.0/base_net.0.0/Conv_output_0)\n",
            "  %/base_net.1/base_net.1.0/Conv_output_0 = Conv[dilations = [1, 1], group = 32, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.0/base_net.0.2/Relu_output_0, %onnx::Conv_503, %onnx::Conv_504)\n",
            "  %/base_net.1/base_net.1.2/Relu_output_0 = Relu(%/base_net.1/base_net.1.0/Conv_output_0)\n",
            "  %/base_net.1/base_net.1.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.1/base_net.1.2/Relu_output_0, %onnx::Conv_506, %onnx::Conv_507)\n",
            "  %/base_net.1/base_net.1.5/Relu_output_0 = Relu(%/base_net.1/base_net.1.3/Conv_output_0)\n",
            "  %/base_net.2/base_net.2.0/Conv_output_0 = Conv[dilations = [1, 1], group = 64, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.1/base_net.1.5/Relu_output_0, %onnx::Conv_509, %onnx::Conv_510)\n",
            "  %/base_net.2/base_net.2.2/Relu_output_0 = Relu(%/base_net.2/base_net.2.0/Conv_output_0)\n",
            "  %/base_net.2/base_net.2.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.2/base_net.2.2/Relu_output_0, %onnx::Conv_512, %onnx::Conv_513)\n",
            "  %/base_net.2/base_net.2.5/Relu_output_0 = Relu(%/base_net.2/base_net.2.3/Conv_output_0)\n",
            "  %/base_net.3/base_net.3.0/Conv_output_0 = Conv[dilations = [1, 1], group = 128, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.2/base_net.2.5/Relu_output_0, %onnx::Conv_515, %onnx::Conv_516)\n",
            "  %/base_net.3/base_net.3.2/Relu_output_0 = Relu(%/base_net.3/base_net.3.0/Conv_output_0)\n",
            "  %/base_net.3/base_net.3.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.3/base_net.3.2/Relu_output_0, %onnx::Conv_518, %onnx::Conv_519)\n",
            "  %/base_net.3/base_net.3.5/Relu_output_0 = Relu(%/base_net.3/base_net.3.3/Conv_output_0)\n",
            "  %/base_net.4/base_net.4.0/Conv_output_0 = Conv[dilations = [1, 1], group = 128, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.3/base_net.3.5/Relu_output_0, %onnx::Conv_521, %onnx::Conv_522)\n",
            "  %/base_net.4/base_net.4.2/Relu_output_0 = Relu(%/base_net.4/base_net.4.0/Conv_output_0)\n",
            "  %/base_net.4/base_net.4.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.4/base_net.4.2/Relu_output_0, %onnx::Conv_524, %onnx::Conv_525)\n",
            "  %/base_net.4/base_net.4.5/Relu_output_0 = Relu(%/base_net.4/base_net.4.3/Conv_output_0)\n",
            "  %/base_net.5/base_net.5.0/Conv_output_0 = Conv[dilations = [1, 1], group = 256, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.4/base_net.4.5/Relu_output_0, %onnx::Conv_527, %onnx::Conv_528)\n",
            "  %/base_net.5/base_net.5.2/Relu_output_0 = Relu(%/base_net.5/base_net.5.0/Conv_output_0)\n",
            "  %/base_net.5/base_net.5.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.5/base_net.5.2/Relu_output_0, %onnx::Conv_530, %onnx::Conv_531)\n",
            "  %/base_net.5/base_net.5.5/Relu_output_0 = Relu(%/base_net.5/base_net.5.3/Conv_output_0)\n",
            "  %/base_net.6/base_net.6.0/Conv_output_0 = Conv[dilations = [1, 1], group = 256, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.5/base_net.5.5/Relu_output_0, %onnx::Conv_533, %onnx::Conv_534)\n",
            "  %/base_net.6/base_net.6.2/Relu_output_0 = Relu(%/base_net.6/base_net.6.0/Conv_output_0)\n",
            "  %/base_net.6/base_net.6.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.6/base_net.6.2/Relu_output_0, %onnx::Conv_536, %onnx::Conv_537)\n",
            "  %/base_net.6/base_net.6.5/Relu_output_0 = Relu(%/base_net.6/base_net.6.3/Conv_output_0)\n",
            "  %/base_net.7/base_net.7.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.6/base_net.6.5/Relu_output_0, %onnx::Conv_539, %onnx::Conv_540)\n",
            "  %/base_net.7/base_net.7.2/Relu_output_0 = Relu(%/base_net.7/base_net.7.0/Conv_output_0)\n",
            "  %/base_net.7/base_net.7.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.7/base_net.7.2/Relu_output_0, %onnx::Conv_542, %onnx::Conv_543)\n",
            "  %/base_net.7/base_net.7.5/Relu_output_0 = Relu(%/base_net.7/base_net.7.3/Conv_output_0)\n",
            "  %/base_net.8/base_net.8.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.7/base_net.7.5/Relu_output_0, %onnx::Conv_545, %onnx::Conv_546)\n",
            "  %/base_net.8/base_net.8.2/Relu_output_0 = Relu(%/base_net.8/base_net.8.0/Conv_output_0)\n",
            "  %/base_net.8/base_net.8.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.8/base_net.8.2/Relu_output_0, %onnx::Conv_548, %onnx::Conv_549)\n",
            "  %/base_net.8/base_net.8.5/Relu_output_0 = Relu(%/base_net.8/base_net.8.3/Conv_output_0)\n",
            "  %/base_net.9/base_net.9.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.8/base_net.8.5/Relu_output_0, %onnx::Conv_551, %onnx::Conv_552)\n",
            "  %/base_net.9/base_net.9.2/Relu_output_0 = Relu(%/base_net.9/base_net.9.0/Conv_output_0)\n",
            "  %/base_net.9/base_net.9.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.9/base_net.9.2/Relu_output_0, %onnx::Conv_554, %onnx::Conv_555)\n",
            "  %/base_net.9/base_net.9.5/Relu_output_0 = Relu(%/base_net.9/base_net.9.3/Conv_output_0)\n",
            "  %/base_net.10/base_net.10.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.9/base_net.9.5/Relu_output_0, %onnx::Conv_557, %onnx::Conv_558)\n",
            "  %/base_net.10/base_net.10.2/Relu_output_0 = Relu(%/base_net.10/base_net.10.0/Conv_output_0)\n",
            "  %/base_net.10/base_net.10.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.10/base_net.10.2/Relu_output_0, %onnx::Conv_560, %onnx::Conv_561)\n",
            "  %/base_net.10/base_net.10.5/Relu_output_0 = Relu(%/base_net.10/base_net.10.3/Conv_output_0)\n",
            "  %/base_net.11/base_net.11.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.10/base_net.10.5/Relu_output_0, %onnx::Conv_563, %onnx::Conv_564)\n",
            "  %/base_net.11/base_net.11.2/Relu_output_0 = Relu(%/base_net.11/base_net.11.0/Conv_output_0)\n",
            "  %/base_net.11/base_net.11.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.11/base_net.11.2/Relu_output_0, %onnx::Conv_566, %onnx::Conv_567)\n",
            "  %/base_net.11/base_net.11.5/Relu_output_0 = Relu(%/base_net.11/base_net.11.3/Conv_output_0)\n",
            "  %/classification_headers.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.11/base_net.11.5/Relu_output_0, %classification_headers.0.weight, %classification_headers.0.bias)\n",
            "  %/Transpose_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.0/Conv_output_0)\n",
            "  %/Shape_output_0 = Shape(%/Transpose_output_0)\n",
            "  %/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_output_0 = Gather[axis = 0](%/Shape_output_0, %/Constant_output_0)\n",
            "  %onnx::Unsqueeze_279 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_output_0 = Unsqueeze(%/Gather_output_0, %onnx::Unsqueeze_279)\n",
            "  %/Constant_1_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_2_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_output_0 = Concat[axis = 0](%/Unsqueeze_output_0, %/Constant_1_output_0, %/Constant_2_output_0)\n",
            "  %/Reshape_output_0 = Reshape[allowzero = 0](%/Transpose_output_0, %/Concat_output_0)\n",
            "  %/regression_headers.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.11/base_net.11.5/Relu_output_0, %regression_headers.0.weight, %regression_headers.0.bias)\n",
            "  %/Transpose_1_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.0/Conv_output_0)\n",
            "  %/Shape_1_output_0 = Shape(%/Transpose_1_output_0)\n",
            "  %/Constant_3_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_1_output_0 = Gather[axis = 0](%/Shape_1_output_0, %/Constant_3_output_0)\n",
            "  %onnx::Unsqueeze_293 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_1_output_0 = Unsqueeze(%/Gather_1_output_0, %onnx::Unsqueeze_293)\n",
            "  %/Constant_4_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_5_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_1_output_0 = Concat[axis = 0](%/Unsqueeze_1_output_0, %/Constant_4_output_0, %/Constant_5_output_0)\n",
            "  %/Reshape_1_output_0 = Reshape[allowzero = 0](%/Transpose_1_output_0, %/Concat_1_output_0)\n",
            "  %/base_net.12/base_net.12.0/Conv_output_0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/base_net.11/base_net.11.5/Relu_output_0, %onnx::Conv_569, %onnx::Conv_570)\n",
            "  %/base_net.12/base_net.12.2/Relu_output_0 = Relu(%/base_net.12/base_net.12.0/Conv_output_0)\n",
            "  %/base_net.12/base_net.12.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.12/base_net.12.2/Relu_output_0, %onnx::Conv_572, %onnx::Conv_573)\n",
            "  %/base_net.12/base_net.12.5/Relu_output_0 = Relu(%/base_net.12/base_net.12.3/Conv_output_0)\n",
            "  %/base_net.13/base_net.13.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1024, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.12/base_net.12.5/Relu_output_0, %onnx::Conv_575, %onnx::Conv_576)\n",
            "  %/base_net.13/base_net.13.2/Relu_output_0 = Relu(%/base_net.13/base_net.13.0/Conv_output_0)\n",
            "  %/base_net.13/base_net.13.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.13/base_net.13.2/Relu_output_0, %onnx::Conv_578, %onnx::Conv_579)\n",
            "  %/base_net.13/base_net.13.5/Relu_output_0 = Relu(%/base_net.13/base_net.13.3/Conv_output_0)\n",
            "  %/classification_headers.1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.13/base_net.13.5/Relu_output_0, %classification_headers.1.weight, %classification_headers.1.bias)\n",
            "  %/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.1/Conv_output_0)\n",
            "  %/Shape_2_output_0 = Shape(%/Transpose_2_output_0)\n",
            "  %/Constant_6_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_2_output_0 = Gather[axis = 0](%/Shape_2_output_0, %/Constant_6_output_0)\n",
            "  %onnx::Unsqueeze_318 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_2_output_0 = Unsqueeze(%/Gather_2_output_0, %onnx::Unsqueeze_318)\n",
            "  %/Constant_7_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_8_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_2_output_0 = Concat[axis = 0](%/Unsqueeze_2_output_0, %/Constant_7_output_0, %/Constant_8_output_0)\n",
            "  %/Reshape_2_output_0 = Reshape[allowzero = 0](%/Transpose_2_output_0, %/Concat_2_output_0)\n",
            "  %/regression_headers.1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/base_net.13/base_net.13.5/Relu_output_0, %regression_headers.1.weight, %regression_headers.1.bias)\n",
            "  %/Transpose_3_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.1/Conv_output_0)\n",
            "  %/Shape_3_output_0 = Shape(%/Transpose_3_output_0)\n",
            "  %/Constant_9_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_3_output_0 = Gather[axis = 0](%/Shape_3_output_0, %/Constant_9_output_0)\n",
            "  %onnx::Unsqueeze_331 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_3_output_0 = Unsqueeze(%/Gather_3_output_0, %onnx::Unsqueeze_331)\n",
            "  %/Constant_10_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_11_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_3_output_0 = Concat[axis = 0](%/Unsqueeze_3_output_0, %/Constant_10_output_0, %/Constant_11_output_0)\n",
            "  %/Reshape_3_output_0 = Reshape[allowzero = 0](%/Transpose_3_output_0, %/Concat_3_output_0)\n",
            "  %/extras.0/extras.0.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/base_net.13/base_net.13.5/Relu_output_0, %extras.0.0.weight, %extras.0.0.bias)\n",
            "  %/extras.0/extras.0.1/Relu_output_0 = Relu(%/extras.0/extras.0.0/Conv_output_0)\n",
            "  %/extras.0/extras.0.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.0/extras.0.1/Relu_output_0, %extras.0.2.weight, %extras.0.2.bias)\n",
            "  %/extras.0/extras.0.3/Relu_output_0 = Relu(%/extras.0/extras.0.2/Conv_output_0)\n",
            "  %/classification_headers.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.0/extras.0.3/Relu_output_0, %classification_headers.2.weight, %classification_headers.2.bias)\n",
            "  %/Transpose_4_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.2/Conv_output_0)\n",
            "  %/Shape_4_output_0 = Shape(%/Transpose_4_output_0)\n",
            "  %/Constant_12_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_4_output_0 = Gather[axis = 0](%/Shape_4_output_0, %/Constant_12_output_0)\n",
            "  %onnx::Unsqueeze_348 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_4_output_0 = Unsqueeze(%/Gather_4_output_0, %onnx::Unsqueeze_348)\n",
            "  %/Constant_13_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_14_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_4_output_0 = Concat[axis = 0](%/Unsqueeze_4_output_0, %/Constant_13_output_0, %/Constant_14_output_0)\n",
            "  %/Reshape_4_output_0 = Reshape[allowzero = 0](%/Transpose_4_output_0, %/Concat_4_output_0)\n",
            "  %/regression_headers.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.0/extras.0.3/Relu_output_0, %regression_headers.2.weight, %regression_headers.2.bias)\n",
            "  %/Transpose_5_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.2/Conv_output_0)\n",
            "  %/Shape_5_output_0 = Shape(%/Transpose_5_output_0)\n",
            "  %/Constant_15_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_5_output_0 = Gather[axis = 0](%/Shape_5_output_0, %/Constant_15_output_0)\n",
            "  %onnx::Unsqueeze_361 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_5_output_0 = Unsqueeze(%/Gather_5_output_0, %onnx::Unsqueeze_361)\n",
            "  %/Constant_16_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_17_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_5_output_0 = Concat[axis = 0](%/Unsqueeze_5_output_0, %/Constant_16_output_0, %/Constant_17_output_0)\n",
            "  %/Reshape_5_output_0 = Reshape[allowzero = 0](%/Transpose_5_output_0, %/Concat_5_output_0)\n",
            "  %/extras.1/extras.1.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/extras.0/extras.0.3/Relu_output_0, %extras.1.0.weight, %extras.1.0.bias)\n",
            "  %/extras.1/extras.1.1/Relu_output_0 = Relu(%/extras.1/extras.1.0/Conv_output_0)\n",
            "  %/extras.1/extras.1.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.1/extras.1.1/Relu_output_0, %extras.1.2.weight, %extras.1.2.bias)\n",
            "  %/extras.1/extras.1.3/Relu_output_0 = Relu(%/extras.1/extras.1.2/Conv_output_0)\n",
            "  %/classification_headers.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.1/extras.1.3/Relu_output_0, %classification_headers.3.weight, %classification_headers.3.bias)\n",
            "  %/Transpose_6_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.3/Conv_output_0)\n",
            "  %/Shape_6_output_0 = Shape(%/Transpose_6_output_0)\n",
            "  %/Constant_18_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_6_output_0 = Gather[axis = 0](%/Shape_6_output_0, %/Constant_18_output_0)\n",
            "  %onnx::Unsqueeze_378 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_6_output_0 = Unsqueeze(%/Gather_6_output_0, %onnx::Unsqueeze_378)\n",
            "  %/Constant_19_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_20_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_6_output_0 = Concat[axis = 0](%/Unsqueeze_6_output_0, %/Constant_19_output_0, %/Constant_20_output_0)\n",
            "  %/Reshape_6_output_0 = Reshape[allowzero = 0](%/Transpose_6_output_0, %/Concat_6_output_0)\n",
            "  %/regression_headers.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.1/extras.1.3/Relu_output_0, %regression_headers.3.weight, %regression_headers.3.bias)\n",
            "  %/Transpose_7_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.3/Conv_output_0)\n",
            "  %/Shape_7_output_0 = Shape(%/Transpose_7_output_0)\n",
            "  %/Constant_21_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_7_output_0 = Gather[axis = 0](%/Shape_7_output_0, %/Constant_21_output_0)\n",
            "  %onnx::Unsqueeze_391 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_7_output_0 = Unsqueeze(%/Gather_7_output_0, %onnx::Unsqueeze_391)\n",
            "  %/Constant_22_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_23_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_7_output_0 = Concat[axis = 0](%/Unsqueeze_7_output_0, %/Constant_22_output_0, %/Constant_23_output_0)\n",
            "  %/Reshape_7_output_0 = Reshape[allowzero = 0](%/Transpose_7_output_0, %/Concat_7_output_0)\n",
            "  %/extras.2/extras.2.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/extras.1/extras.1.3/Relu_output_0, %extras.2.0.weight, %extras.2.0.bias)\n",
            "  %/extras.2/extras.2.1/Relu_output_0 = Relu(%/extras.2/extras.2.0/Conv_output_0)\n",
            "  %/extras.2/extras.2.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.2/extras.2.1/Relu_output_0, %extras.2.2.weight, %extras.2.2.bias)\n",
            "  %/extras.2/extras.2.3/Relu_output_0 = Relu(%/extras.2/extras.2.2/Conv_output_0)\n",
            "  %/classification_headers.4/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.2/extras.2.3/Relu_output_0, %classification_headers.4.weight, %classification_headers.4.bias)\n",
            "  %/Transpose_8_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.4/Conv_output_0)\n",
            "  %/Shape_8_output_0 = Shape(%/Transpose_8_output_0)\n",
            "  %/Constant_24_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_8_output_0 = Gather[axis = 0](%/Shape_8_output_0, %/Constant_24_output_0)\n",
            "  %onnx::Unsqueeze_408 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_8_output_0 = Unsqueeze(%/Gather_8_output_0, %onnx::Unsqueeze_408)\n",
            "  %/Constant_25_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_26_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_8_output_0 = Concat[axis = 0](%/Unsqueeze_8_output_0, %/Constant_25_output_0, %/Constant_26_output_0)\n",
            "  %/Reshape_8_output_0 = Reshape[allowzero = 0](%/Transpose_8_output_0, %/Concat_8_output_0)\n",
            "  %/regression_headers.4/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.2/extras.2.3/Relu_output_0, %regression_headers.4.weight, %regression_headers.4.bias)\n",
            "  %/Transpose_9_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.4/Conv_output_0)\n",
            "  %/Shape_9_output_0 = Shape(%/Transpose_9_output_0)\n",
            "  %/Constant_27_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_9_output_0 = Gather[axis = 0](%/Shape_9_output_0, %/Constant_27_output_0)\n",
            "  %onnx::Unsqueeze_421 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_9_output_0 = Unsqueeze(%/Gather_9_output_0, %onnx::Unsqueeze_421)\n",
            "  %/Constant_28_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_29_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_9_output_0 = Concat[axis = 0](%/Unsqueeze_9_output_0, %/Constant_28_output_0, %/Constant_29_output_0)\n",
            "  %/Reshape_9_output_0 = Reshape[allowzero = 0](%/Transpose_9_output_0, %/Concat_9_output_0)\n",
            "  %/extras.3/extras.3.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/extras.2/extras.2.3/Relu_output_0, %extras.3.0.weight, %extras.3.0.bias)\n",
            "  %/extras.3/extras.3.1/Relu_output_0 = Relu(%/extras.3/extras.3.0/Conv_output_0)\n",
            "  %/extras.3/extras.3.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/extras.3/extras.3.1/Relu_output_0, %extras.3.2.weight, %extras.3.2.bias)\n",
            "  %/extras.3/extras.3.3/Relu_output_0 = Relu(%/extras.3/extras.3.2/Conv_output_0)\n",
            "  %/classification_headers.5/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.3/extras.3.3/Relu_output_0, %classification_headers.5.weight, %classification_headers.5.bias)\n",
            "  %/Transpose_10_output_0 = Transpose[perm = [0, 2, 3, 1]](%/classification_headers.5/Conv_output_0)\n",
            "  %/Shape_10_output_0 = Shape(%/Transpose_10_output_0)\n",
            "  %/Constant_30_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_10_output_0 = Gather[axis = 0](%/Shape_10_output_0, %/Constant_30_output_0)\n",
            "  %onnx::Unsqueeze_438 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_10_output_0 = Unsqueeze(%/Gather_10_output_0, %onnx::Unsqueeze_438)\n",
            "  %/Constant_31_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_32_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_10_output_0 = Concat[axis = 0](%/Unsqueeze_10_output_0, %/Constant_31_output_0, %/Constant_32_output_0)\n",
            "  %/Reshape_10_output_0 = Reshape[allowzero = 0](%/Transpose_10_output_0, %/Concat_10_output_0)\n",
            "  %/regression_headers.5/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/extras.3/extras.3.3/Relu_output_0, %regression_headers.5.weight, %regression_headers.5.bias)\n",
            "  %/Transpose_11_output_0 = Transpose[perm = [0, 2, 3, 1]](%/regression_headers.5/Conv_output_0)\n",
            "  %/Shape_11_output_0 = Shape(%/Transpose_11_output_0)\n",
            "  %/Constant_33_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Gather_11_output_0 = Gather[axis = 0](%/Shape_11_output_0, %/Constant_33_output_0)\n",
            "  %onnx::Unsqueeze_451 = Constant[value = <Tensor>]()\n",
            "  %/Unsqueeze_11_output_0 = Unsqueeze(%/Gather_11_output_0, %onnx::Unsqueeze_451)\n",
            "  %/Constant_34_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_35_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Concat_11_output_0 = Concat[axis = 0](%/Unsqueeze_11_output_0, %/Constant_34_output_0, %/Constant_35_output_0)\n",
            "  %/Reshape_11_output_0 = Reshape[allowzero = 0](%/Transpose_11_output_0, %/Concat_11_output_0)\n",
            "  %/Concat_12_output_0 = Concat[axis = 1](%/Reshape_output_0, %/Reshape_2_output_0, %/Reshape_4_output_0, %/Reshape_6_output_0, %/Reshape_8_output_0, %/Reshape_10_output_0)\n",
            "  %/Concat_13_output_0 = Concat[axis = 1](%/Reshape_1_output_0, %/Reshape_3_output_0, %/Reshape_5_output_0, %/Reshape_7_output_0, %/Reshape_9_output_0, %/Reshape_11_output_0)\n",
            "  %scores = Softmax[axis = 2](%/Concat_12_output_0)\n",
            "  %/Constant_36_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_37_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_38_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_39_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_output_0 = Slice(%/Concat_13_output_0, %/Constant_37_output_0, %/Constant_38_output_0, %/Constant_36_output_0, %/Constant_39_output_0)\n",
            "  %/Constant_40_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Mul_output_0 = Mul(%/Slice_output_0, %/Constant_40_output_0)\n",
            "  %/Constant_41_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Mul_1_output_0 = Mul(%/Mul_output_0, %/Constant_41_output_0)\n",
            "  %/Constant_42_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Add_output_0 = Add(%/Mul_1_output_0, %/Constant_42_output_0)\n",
            "  %/Constant_43_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_44_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_45_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_46_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_1_output_0 = Slice(%/Concat_13_output_0, %/Constant_44_output_0, %/Constant_45_output_0, %/Constant_43_output_0, %/Constant_46_output_0)\n",
            "  %/Constant_47_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Mul_2_output_0 = Mul(%/Slice_1_output_0, %/Constant_47_output_0)\n",
            "  %/Exp_output_0 = Exp(%/Mul_2_output_0)\n",
            "  %/Constant_48_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Mul_3_output_0 = Mul(%/Exp_output_0, %/Constant_48_output_0)\n",
            "  %/Concat_14_output_0 = Concat[axis = 2](%/Add_output_0, %/Mul_3_output_0)\n",
            "  %/Constant_49_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_50_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_51_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_52_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_2_output_0 = Slice(%/Concat_14_output_0, %/Constant_50_output_0, %/Constant_51_output_0, %/Constant_49_output_0, %/Constant_52_output_0)\n",
            "  %/Constant_53_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_54_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_55_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Constant_56_output_0 = Constant[value = <Tensor>]()\n",
            "  %/Slice_3_output_0 = Slice(%/Concat_14_output_0, %/Constant_54_output_0, %/Constant_55_output_0, %/Constant_53_output_0, %/Constant_56_output_0)\n",
            "  %/Constant_57_output_0 = Constant[value = <Scalar Tensor []>]()\n",
            "  %/Div_output_0 = Div(%/Slice_3_output_0, %/Constant_57_output_0)\n",
            "  %/Sub_output_0 = Sub(%/Slice_2_output_0, %/Div_output_0)\n",
            "  %/Add_1_output_0 = Add(%/Slice_2_output_0, %/Div_output_0)\n",
            "  %boxes = Concat[axis = 2](%/Sub_output_0, %/Add_1_output_0)\n",
            "  return %scores, %boxes\n",
            "}\n",
            "output shape of ort (1, 3000, 3)\n",
            "output shape of torch (1, 3000, 3)\n",
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ]
        }
      ],
      "source": [
        "import onnx\n",
        "import onnxruntime\n",
        "\n",
        "onnx_model = onnx.load(model_onnx_path)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "print(onnx.helper.printable_graph(onnx_model.graph))\n",
        "ort_session = onnxruntime.InferenceSession(model_onnx_path)\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "\n",
        "# PyTorch output prediction\n",
        "torch_out = net(x)\n",
        "torch_out_np = [to_numpy(o) for o in torch_out]\n",
        "\n",
        "print(\"output shape of ort\", ort_outs[0].shape)\n",
        "print(\"output shape of torch\", torch_out_np[0].shape)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "np.testing.assert_allclose(torch_out_np[0], ort_outs[0], rtol=1e-02, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBIj0cijnwsc"
      },
      "source": [
        "output shape of ort (1, 3000, 3)\n",
        "\n",
        "output shape of torch (1, 3000, 3)\n",
        "\n",
        "Exported model has been tested with ONNXRuntime, and the result looks good!\n",
        "\n",
        "The precision used for matching is determined by the rtol and atol parameters:\n",
        "\n",
        "`rtol=1e-02`: This sets the relative tolerance to 1e-02, which is equivalent to 0.01 or 1%. It means that the relative difference between the corresponding elements of the two arrays should be within 1% of each other.\n",
        "\n",
        "`atol=1e-05`: This sets the absolute tolerance to 1e-05, which is equivalent to 0.00001. It means that the absolute difference between the corresponding elements of the two arrays should be within 0.00001.\n",
        "\n",
        "It uses `abs(a - b) <= atol + rtol * abs(b)` to calculate the difference between the two object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zWUqUbWNY05"
      },
      "source": [
        "### 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYBQx_Oh6Q8H",
        "outputId": "dc9a658b-a025-49df-9293-7eaadf22af40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/zhongyihao/Downloads/DS301 Advance ML/deep-learning/code/pytorch-ssd'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh6-bEHioNoR",
        "outputId": "4c2ef106-18c2-4be1-a788-7ec2f2907b0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[0.99311006 0.00260478 0.00428523]\n",
            "  [0.9951139  0.00106808 0.003818  ]\n",
            "  [0.9907872  0.00311253 0.00610025]\n",
            "  ...\n",
            "  [0.9480198  0.00858595 0.04339429]\n",
            "  [0.9679258  0.00882698 0.02324719]\n",
            "  [0.9450335  0.00878914 0.04617732]]]\n",
            "# of handguns: 0, # of shotguns: 0\n",
            "[[[0.9942662  0.00391159 0.00182216]\n",
            "  [0.9971625  0.00150818 0.00132924]\n",
            "  [0.9937894  0.00386346 0.00234707]\n",
            "  ...\n",
            "  [0.8499492  0.10107069 0.0489802 ]\n",
            "  [0.9336622  0.05180439 0.01453347]\n",
            "  [0.8160332  0.11915151 0.06481532]]]\n",
            "# of handguns: 0, # of shotguns: 0\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import onnx\n",
        "import onnxruntime\n",
        "\n",
        "img_list = ['../data/open_images/train/0002f32727ed756e.jpg',\n",
        "              '../data/open_images/train/000305928f7b43da.jpg']\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"models/mb1-ssd-10.onnx\")\n",
        "\n",
        "# Preprocess and normalize the image\n",
        "def pre(img):\n",
        "    img_data = np.array(img)\n",
        "    img_data = np.transpose(img_data, [2, 0, 1])\n",
        "    img_data = np.expand_dims(img_data, 0)\n",
        "    mean_vec = np.array([0.485, 0.456, 0.406])\n",
        "    stddev_vec = np.array([0.229, 0.224, 0.225])\n",
        "    norm_img_data = np.zeros(img_data.shape).astype('float32')\n",
        "    for i in range(img_data.shape[1]):\n",
        "        norm_img_data[:,i,:,:] = (img_data[:,i,:,:]/255 - mean_vec[i]) / stddev_vec[i]\n",
        "\n",
        "for img_path in img_list:\n",
        "    img = Image.open(img_path)\n",
        "    img.show()\n",
        "\n",
        "    resize = transforms.Resize([300, 300])\n",
        "    img = resize(img)\n",
        "\n",
        "    img_ycbcr = img.convert('YCbCr')\n",
        "    img_y, img_cb, img_cr = img_ycbcr.split()\n",
        "\n",
        "    to_tensor = transforms.ToTensor()\n",
        "    img_y = to_tensor(img_y)\n",
        "    img_y.unsqueeze_(0)\n",
        "\n",
        "    img_3ch = img_y.repeat(1, 3, 1, 1)\n",
        "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_3ch)}\n",
        "    ort_outs = ort_session.run(None, ort_inputs)\n",
        "    print(ort_outs[0])\n",
        "    img_out_y = np.asarray(ort_outs[0])\n",
        "    label = np.argmax(ort_outs[0], axis=-1)\n",
        "    print(f\"# of handguns: {(label == 1).sum ()}, # of shotguns: {(label == 2).sum ()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLzyrGj8oeQO"
      },
      "outputs": [],
      "source": [
        "img_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L')\n",
        "\n",
        "# get the output image follow post-processing step from PyTorch implementation\n",
        "final_img = Image.merge(\n",
        "    \"YCbCr\", [\n",
        "        img_out_y,\n",
        "        img_cb.resize(img_out_y.size, Image.BICUBIC),\n",
        "        img_cr.resize(img_out_y.size, Image.BICUBIC),\n",
        "    ]).convert(\"RGB\")\n",
        "\n",
        "# Save the image\\\n",
        "final_img.save(\"cat_superres_with_ort.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f49hEkY06Q8I"
      },
      "source": [
        "### 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9vsTqdV6Q8I"
      },
      "outputs": [],
      "source": [
        "## Display image with bounding boxes and appropriate class\n",
        "\n",
        "# Parse the list of class labels\n",
        "classes = [line.rstrip('\\n') for line in open('assets/coco_classes.txt')]\n",
        "\n",
        "# Plot the bounding boxes on the image\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(1, figsize=(12,9))\n",
        "ax.imshow(img)\n",
        "\n",
        "resized_width = 300  # we resized the original image, remember ?\n",
        "resized_height = 300\n",
        "num_boxes = 1 # we limit displaying to just 10 boxes to avoid clogging the result image with boxes\n",
        "               # The results are already sorted based on box confidences, so we just pick top N boxes without sorting\n",
        "\n",
        "for c in range(num_boxes):\n",
        "    base_index = c * 4\n",
        "    y1, x1, y2, x2 = bboxes[base_index] * resized_height, bboxes[base_index + 1] * resized_width, bboxes[base_index + 2] * resized_height, bboxes[base_index + 3] * resized_width\n",
        "    color = 'blue'\n",
        "    box_h = (y2 - y1)\n",
        "    box_w = (x2 - x1)\n",
        "    bbox = patches.Rectangle((y1, x1), box_h, box_w, linewidth=2, edgecolor=color, facecolor='none')\n",
        "    ax.add_patch(bbox)\n",
        "    plt.text(y1, x1, s=classes[labels[c] - 1], color='white', verticalalignment='top', bbox={'color': color, 'pad': 0})\n",
        "plt.axis('off')\n",
        "\n",
        "# Save image\n",
        "plt.savefig(\"output/ssd_result.jpg\", bbox_inches='tight', pad_inches=0.0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StuHyld1NY05"
      },
      "source": [
        "## Problem 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZoburbW6Q8I"
      },
      "source": [
        "1\n",
        "\n",
        "In episodic tasks, the agent-environment interaction is broken into discrete episodes that terminate after a certain number of time steps or when the agent reaches a terminal state. Examples include games like chess or Go where there is a clear endpoint.\n",
        "\n",
        "In continuous tasks, the interaction continues without limit. The agent continually interacts with the environment without explicit episodes or termination. An example can an agent controlling a power plant or traffic lights that need to continous operation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdaAfO1M6Q8I"
      },
      "source": [
        "2.\n",
        "\n",
        "Exploration refers to the agent trying new actions to discover strategies that lead to high rewards in the long run. Exploitation means the agent leveraging its current knowledge to choose the best known action to maximize immediate reward.\n",
        "\n",
        "Actors employ $ε$-greedy policies to balance exploration and exploitation. With probability $ε$, the agent selects a random action (exploration). With probability 1-$ε$, it selects the action with the highest estimated value (exploitation).\n",
        "\n",
        "The $ε$ value should follow a schedule, starting high to encourage exploration early in training, then decreasing over time to shift priority to exploitation as the agent gains knowledge. A fixed $ε$ would not allow this strategic shift.\n",
        "\n",
        "Higher $ε$ values bias the agent to explore, while lower values prioritize exploiting current knowledge. Gradually moving from high to low $ε$ during training allows the agent to discover high-value strategies early on, then increasingly leverage that knowledge over time to maximize performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqDG3Mwd6Q8I"
      },
      "source": [
        "3.\n",
        "\n",
        "Deep Q-Learning uses a deep neural network (Q-network) to approximate the action-value function Q(s,a), whereas Q-learning uses a tabular representation. This allows Deep Q-Learning to handle high-dimensional state spaces. Also, Deep Q-Learning uses a separate target network Q' to calculate the target Q-values used in the loss function. The target network's weights are periodically copied from the main Q-network. This stabilizes learning by reducing correlations between the target and current Q-values. Q-learning uses the same Q-function for action selection and Q-value updates.\n",
        "\n",
        "The Deep Q-Learning algorithm in Mnih et al. (2013) page 5 proceeds as follows:\n",
        "\n",
        "Initialize the replay memory D to capacity N. This is where experienced transitions will be stored for later training.\n",
        "Initialize the action-value function Q with random weights. This is the main Q-network that will be learned.\n",
        "\n",
        "For each episode:\n",
        "\n",
        "- Initialize the starting state s_1\n",
        "- For each time step t in the episode:\n",
        "\n",
        "   - With probability ε, select a random action a_t, otherwise select a_t = argmax_a Q(s_t,a) (ε-greedy policy)\n",
        "\n",
        "   - Execute a_t in the emulator and observe the reward r_t and next state s_t+1\n",
        "\n",
        "   - Store the transition (s_t, a_t, r_t+1, s_t+1) in the replay memory D\n",
        "\n",
        "   - Sample a random minibatch of transitions from D\n",
        "   - For each sampled transition (s_j, a_j, r_j+1, s_j+1):\n",
        "\n",
        "      - If s_j+1 is terminal (episode ended), y_j = r_j\n",
        "\n",
        "      - Otherwise, set y_j = r_j + γ * max_a' Q'(s_j+1, a') using the target network\n",
        "\n",
        "\n",
        "   - Perform a gradient descent step on (y_j - Q(s_j, a_j))^2 w.r.t. the Q-network weights\n",
        "\n",
        "- After every C steps, copy the Q-network weights to the target network Q'\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nNvhQBm6Q8I"
      },
      "source": [
        "4.\n",
        "\n",
        "The target Q-network is a important component in Deep Q-Learning that helps stabilize the learning process and improve convergence. In Q-learning, the same Q-function is used to select actions and calculate target Q values for updates, which can lead to instability due to the constantly shifting targets. Also, by doing a separate target network with fixed parameters that are periodically copied from the main Q-network, the target Q values remain more consistent, providing a stable objective for the main Q-network to learn towards. This is important when combined with experience replay, as the fixed target ensures that the Q-values of sampled past transitions remain independent of recent updates to the main Q-network, this kind of breaking correlations and allowing for more efficient learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYVXPi6P6Q8I"
      },
      "source": [
        "5.\n",
        "\n",
        "Experience replay improves the efficiency and stability of the learning process. By storing agent's experiences in a replay buffer and randomly sampling mini-batches from it during training, experience replay breaks the correlations between sequential experiences, allows the agent to learn from past experiences multiple times, and reduces the impact of rare or noisy experiences. This leads to more efficient use of the collected data, faster convergence to the optimal Q-function, and improved stability of the learning process. Also, experience replay can do better exploration by enabling the agent to learn from experiences collected under different policies, discovering some better strategies that might not be immediately apparent with current policy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAVxDm_J6Q8I"
      },
      "source": [
        "6.\n",
        "\n",
        "Prioritized experience replay is an extension of the standard experience replay technique that aims to further improve the efficiency of learning by prioritizing the experiences from which the agent can learn the most. Each experience is assigned a priority value that determines the probability of it being sampled during training. The priority is based on the magnitude of the temporal-difference (TD) error, which measures the difference between the predicted Q-value and the target Q-value for a given experience.\n",
        "\n",
        "The priority $p_i$ for experience $i$ is calculated as:\n",
        "\n",
        "$p_i = |\\delta_i| + \\epsilon$\n",
        "\n",
        "where $|\\delta_i|$ is the absolute value of the TD error for experience $i$, and $\\epsilon$ is a small positive constant to ensure that all experiences have a non-zero probability of being sampled.\n",
        "\n",
        "The TD error $\\delta_i$ is computed as:\n",
        "\n",
        "$\\delta_i = r + \\gamma \\max_{a'} Q(s', a') - Q(s, a)$\n",
        "\n",
        "where $r$ is the immediate reward, $\\gamma$ is the discount factor, $s'$ is the next state, and $a'$ is the action taken in the next state.\n",
        "\n",
        "Experiences with higher TD errors are more informative because they indicate a larger discrepancy between the predicted and target Q-values. By assigning higher priorities to these experiences, prioritized experience replay encourages the agent to focus on the most valuable experiences during training, accelerating the learning process.\n",
        "\n",
        "To sample experiences from the replay buffer, the priorities are first converted into probabilities using the softmax function:\n",
        "\n",
        "$P(i) = \\frac{p_i^{\\alpha}}{\\sum_k p_k^{\\alpha}}$\n",
        "\n",
        "where $\\alpha$ is a hyperparameter that determines the degree of prioritization. A higher value of $\\alpha$ results in stronger prioritization, while $\\alpha = 0$ corresponds to uniform sampling.\n",
        "\n",
        "During training, experiences are sampled from the replay buffer according to their probabilities $P(i)$. The agent then updates the Q-network using the sampled experiences, giving more weight to the experiences with higher priorities. The priorities of the sampled experiences are then updated based on the new TD errors, ensuring that the agent continues to prioritize the most informative experiences throughout the learning process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsbDH02X6Q8I"
      },
      "source": [
        "7.\n",
        "\n",
        "Similarities:\n",
        "\n",
        "Distributed architecture: Both GORILA and Ape-X employ a distributed architecture that separates the learning process into multiple components, for parallel processing and faster learning.\n",
        "\n",
        "Experience replay: Both architectures use experience replay to store and sample past experiences for training. It helps break correlations between sequential experiences, improves data efficiency.\n",
        "\n",
        "Target network: GORILA and Ape-X use a target network to stabilize the learning process. The target network's parameters are periodically updated with the main Q-network's parameters to provide a more stable learning target.\n",
        "\n",
        "Differences:\n",
        "\n",
        "Prioritization: Ape-X employs prioritized experience replay, where experiences are prioritized based on their temporal-difference (TD) error. This allows the agent to focus on the most informative experiences during training. GORILA uses standard experience replay without prioritization.\n",
        "\n",
        "Architecture components: GORILA consists of actors, learners, and a parameter server. Actors generate experiences, learners compute gradients and update the model parameters, and the parameter server maintains the global Q-network parameters. In contrast, Ape-X has actors, a learner, and a replay buffer. Actors generate experiences and store them in the replay buffer, while the learner samples from the replay buffer and updates the model parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTZWqxzCNY05"
      },
      "source": [
        "## Problem 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiiJ27QR6Q8J"
      },
      "source": [
        "1.\n",
        "\n",
        "All four platform support Tensorflow (commonly version 2.XX), Pytorch (commonly version 2.XX), sci-learn (up to v1.1), Keras (via torch 2.0) and XGBoost (up to v1.6). All these packages have the option to downgrade per needed in all four platforms, providing flexibility and customization for client need.\n",
        "\n",
        "For IBM Watson, it also support Caffe and SPSS. It also offers AutoAI, which automates model selection and hyperparameter tuning.\n",
        "\n",
        "For Google Cloud, it centralized all tools in Vertex AI for both tranditional AI (prediction and classification) and LLMs. It provides pre-built Docker images for these frameworks, making it easy to get started with deep learning\n",
        "\n",
        "For Amazon AWS, its machine learning platform is called SageMaker, allowing you to create, train, and deploy models using popular frameworks like TensorFlow, PyTorch, and MXNet. It also support AWS Lambda to fasten and streamline the machine learning process via these ml platform.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMGAGspA6Q8J"
      },
      "source": [
        "2.\n",
        "\n",
        "Amazon AWS: Amazon SageMaker provides GPU instances for training deep learning models. various GPU types, including NVIDIA Tesla V100, P3, and G4 instances.\n",
        "\n",
        "Microsoft Azure: Azure Machine Learning offers GPU support with different types of virtual machines, such as NC-series (NVIDIA Tesla K80), ND-series (NVIDIA Tesla P40), and NV-series (NVIDIA Tesla V100, A100, etc).\n",
        "\n",
        "Google Cloud AI Platform: Google provides GPU support through Compute Engine instances. You can select from NVIDIA Tesla K80, P4, L4, and V100, A100 GPUs.\n",
        "\n",
        "IBM Watson Machine Learning: NV-series (NVIDIA Tesla V100, etc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIEdA70N6Q8J"
      },
      "source": [
        "3.\n",
        "\n",
        "Amazon AWS:\n",
        "\n",
        "Amazon SageMaker: SageMaker provides tools for managing the entire model lifecycle. It supports versioning, model deployment, and monitoring. You can create custom pipelines for data preprocessing, model training, and deployment.\n",
        "\n",
        "Microsoft Azure:\n",
        "\n",
        "Azure Machine Learning: Azure ML Studio offers features for model versioning, deployment, and monitoring. It integrates with Azure DevOps for continuous integration and deployment (CI/CD) workflows. You can create reusable pipelines using Azure ML Pipelines.\n",
        "\n",
        "Google Cloud AI Platform:\n",
        "\n",
        "Google AI Platform: Google provides tools for model versioning, deployment, and monitoring. You can use AI Platform Pipelines to create end-to-end workflows. Additionally, Kubeflow Pipelines can be integrated for more complex scenarios.\n",
        "\n",
        "IBM Watson Machine Learning:\n",
        "\n",
        "IBM’s platform supports model versioning, deployment, and monitoring. It offers model catalogs, deployment spaces, and continuous learning capabilities. You can manage models using Watson Studio and Watson Machine Learning service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZP8hDqZ6Q8J"
      },
      "source": [
        "4.\n",
        "\n",
        "Amazon AWS:\n",
        "\n",
        "Amazon SageMaker:\n",
        "\n",
        "SageMaker provides monitoring capabilities for deployed models. It track metrics, set up alerts, and visualize performance using Amazon CloudWatch. It also supports distributed monitoring for multi-node training jobs.\n",
        "\n",
        "Microsoft Azure:\n",
        "\n",
        "Azure Machine Learning:\n",
        "\n",
        "Azure ML provides monitoring through Azure Monitor. It support collect telemetry data, monitor resource usage (CPU, GPU, memory), and set up alerts. Azure Application Insights can be used for application-level monitoring.\n",
        "\n",
        "Google Cloud AI Platform:\n",
        "\n",
        "Google AI Platform: Google offers monitoring features through Cloud Monitoring. It can track resource utilization, set up alerts, and visualize metrics. Stackdriver can be used for logging and debugging.\n",
        "\n",
        "IBM Watson Machine Learning:\n",
        "\n",
        "IBM’s platform provides monitoring for deployed models. You can track performance metrics, resource usage, and model drift. Watson OpenScale offers additional capabilities for fairness, explainability, and bias detection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6ieHoej6Q8J"
      },
      "source": [
        "5.\n",
        "\n",
        "Amazon AWS (Amazon SageMaker):\n",
        "\n",
        "Accuracy Visualization: Amazon SageMaker provides built-in metrics visualization during training. Someone can monitor accuracy using Amazon CloudWatch metrics or custom metrics defined in the training script. SageMaker also supports real-time visualization of training progress.\n",
        "\n",
        "Throughput Visualization: While throughput metrics are not directly visualized, we can analyze training logs and resource utilization to estimate throughput. SageMaker offers detailed logs for debugging and performance analysis.\n",
        "\n",
        "Microsoft Azure (Azure Machine Learning):\n",
        "\n",
        "Accuracy Visualization: Azure ML Studio allows you to visualize accuracy metrics during training. You are able to track accuracy over epochs and visualize it using charts. Additionally, you can log custom metrics for more detailed analysis.\n",
        "\n",
        "Throughput Visualization: Azure Monitor provides insights into resource usage, including GPU and CPU utilization. By monitoring these metrics during training, you can indirectly see throughput.\n",
        "\n",
        "Google Cloud AI Platform:\n",
        "\n",
        "Accuracy Visualization: Google AI Platform supports TensorFlow, which includes TensorBoard for visualizing accuracy and other metrics during training. Track accuracy, loss, and other relevant metrics.\n",
        "\n",
        "Throughput Visualization: Similar to Azure, Google Cloud Monitoring provides resource utilization metrics. By analyzing GPU and CPU usage, you can see throughput.\n",
        "\n",
        "IBM Watson Machine Learning:\n",
        "\n",
        "Accuracy Visualization: IBM Watson Studio integrates with Jupyter notebooks, allowing you to visualize accuracy metrics during training. Create custom plots and track model performance.\n",
        "\n",
        "Throughput Visualization: While Watson Studio doesn’t offer direct throughput visualization, we can analyze training logs and resource usage to see throughput patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0xAkmM56Q8J"
      },
      "source": [
        "6.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ni0X7sN6Q8J"
      },
      "source": [
        "Suppose we want to train a deep learning model for image classification using the popular ResNet-50 architecture. Our training job description will include the following common fields for all 4 platforms:\n",
        "\n",
        "**Job Name:** A unique identifier for the training job.\n",
        "\n",
        "**Experiment Name:** Organizes the job within the ML platform (e.g., Azure ML Studio’s experiments).\n",
        "\n",
        "**Description:** Optional text describing the purpose or details of the job.\n",
        "\n",
        "**Timeout:** Specifies the maximum allowed duration for the training job.\n",
        "\n",
        "**Tags:** Optional tags for organization and metadata.\n",
        "\n",
        "See below yaml, please noted that sometimes Azure allows you to use JSON format training script. The specific format depends on the platform, but the data fields and configuration are specified as above.\n",
        "\n",
        "https://learn.microsoft.com/en-us/azure/machine-learning/how-to-train-with-ui?view=azureml-api-2\n",
        "\n",
        "https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml_dlaas_working_with_new_models.html?context=cpdaas\n",
        "\n",
        "https://resources.workable.com/machine-learning-engineer-job-description\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/prepare-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAId_RBw6Q8J"
      },
      "source": [
        "````yaml\n",
        "job.yml\n",
        "\n",
        "\n",
        "job_name: resnet50-training-job\n",
        "experiment_name: image-classification-experiment\n",
        "description: Training ResNet-50 for image classification\n",
        "timeout_hours: 8\n",
        "compute_instance: cloud_platform_east_v1234\n",
        "compute_cluster: username_1221\n",
        "tags:\n",
        "  - deep-learning\n",
        "  - image-classification\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUHx_AzG6Q8J"
      },
      "source": [
        "In all platforms, we specify the job name, experiment name, description, timeout, and optional tags. The actual training script, input data, and other specifics would be added based on the specific platform’s requirements. Each platform may have additional fields or variations like data pipeline config, data strorage config, logging, post-training monitoring etc.\n",
        "\n",
        "Common structure is as follow\n",
        "\n",
        "```tree\n",
        ".\n",
        "├── job.yml (training job config file)\n",
        "├── data\n",
        "└── src\n",
        "    └── main.py\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0b_mZgtYjLaO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "My Custom Env",
      "language": "python",
      "name": "pytorch_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}